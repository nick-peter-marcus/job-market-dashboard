{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning of Job Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning Part 1:**\n",
    "\n",
    "First, the Location, Company Name, Job Titles, and Seniority Level are cleaned. Those columns will then be used to detect duplicates.\n",
    "\n",
    "\n",
    "**Removal of Duplicates:**\n",
    "\n",
    "The dataframe will be scanned for duplicated rows in multiple steps:\n",
    "1. Drop rows that are duplicates based on all columns.\n",
    "2. Drop rows that show duplicated values in a selection of columns.\n",
    "3. Compare written job descriptions, flagging and dropping listings that show substantial similarity.\n",
    "\n",
    "\n",
    "**Cleaning Part 2:**\n",
    "\n",
    "After having removed duplicated listings, the following cleaning steps will be performed:\n",
    "- Job Titles: titles will be categorized into 10 groups with the help of ChatGPT.\n",
    "- Number of Days Online: The number of days a job ad has been online will be grouped.\n",
    "- Tech Stack: Technologies will be defined and extracted if mentioned in job description.\n",
    "- Geodata: Based on the cleaned location column, latitude and longitude of the individual locations will be added.\n",
    "- Long format: the final dataframe will additionally be stored in a long format allowing for filtering of mentioned tech stack and job types in a streamlit dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1625 entries, 0 to 1624\n",
      "Data columns (total 21 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   title                        1625 non-null   object \n",
      " 1   company                      1625 non-null   object \n",
      " 2   location                     1625 non-null   object \n",
      " 3   salary                       22 non-null     object \n",
      " 4   seniority_level              796 non-null    object \n",
      " 5   date_posted                  1147 non-null   object \n",
      " 6   date_accessed                1625 non-null   object \n",
      " 7   days_online                  1147 non-null   float64\n",
      " 8   number_applicants            796 non-null    float64\n",
      " 9   job_type_Vollzeit            1625 non-null   int64  \n",
      " 10  job_type_Teilzeit            1625 non-null   int64  \n",
      " 11  job_type_Festanstellung      1625 non-null   int64  \n",
      " 12  job_type_BefristeterVertrag  1625 non-null   int64  \n",
      " 13  job_type_Homeoffice          1625 non-null   int64  \n",
      " 14  job_type_FreieMitarbeit      1625 non-null   int64  \n",
      " 15  job_type_Traineeprogramm     1625 non-null   int64  \n",
      " 16  job_type_Berufsausbildung    1625 non-null   int64  \n",
      " 17  job_type_Praktikum           1625 non-null   int64  \n",
      " 18  job_type_Werkstudent         1625 non-null   int64  \n",
      " 19  job_description_anonymized   1625 non-null   object \n",
      " 20  source_id                    1625 non-null   int64  \n",
      "dtypes: float64(2), int64(11), object(8)\n",
      "memory usage: 266.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Read file\n",
    "file_name = \"job_data_raw_anonymized.csv\"\n",
    "df = pd.read_csv(file_name)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location\n",
       "Berlin                       241\n",
       "München                      147\n",
       "Deutschland                   91\n",
       "Hamburg                       76\n",
       " Berlin                       72\n",
       "                            ... \n",
       " Bad Homburg vor der Höhe      1\n",
       " Straße                        1\n",
       "Bremerhaven                    1\n",
       " Wuppertal                     1\n",
       "Münchberg                      1\n",
       "Name: count, Length: 302, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"location\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location\n",
       "Berlin               324\n",
       "München              200\n",
       "Hamburg              110\n",
       "Deutschland           96\n",
       "Frankfurt am Main     87\n",
       "                    ... \n",
       "Penzberg               1\n",
       "Büren                  1\n",
       "Gießen                 1\n",
       "Buch                   1\n",
       "Münchberg              1\n",
       "Name: count, Length: 236, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean white space\n",
    "df[\"location\"] = df[\"location\"].str.strip()\n",
    "df[\"location\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Aachen',\n",
       "       'Aachen, Bonn, Dortmund, Düsseldorf, Essen, Frankfurt, Hannover, Köln, Münster, Paderborn, Siegen',\n",
       "       'Aalen', 'Ahrensburg', 'Arnstorf', 'Aschheim', 'Attenkirchen',\n",
       "       'Augsburg',\n",
       "       'Augsburg, Karlsruhe, Koblenz, München, Nürnberg, Saarbrücken, Stuttgart, Ulm, Walldorf',\n",
       "       'Bad Berleburg', 'Bad Ems', 'Bad Gandersheim', 'Bad Homburg',\n",
       "       'Bad Homburg vor der Höhe', 'Bad Nauheim', 'Bad Salzuflen',\n",
       "       'Baden-Württemberg', 'Bargteheide', 'Bayern', 'Bayreuth',\n",
       "       'Bensheim', 'Bergisch Gladbach', 'Berlin', 'Berlin-Kreuzberg',\n",
       "       'Biberach', 'Biberach an der Riß', 'Bielefeld', 'Bochum', 'Bonn',\n",
       "       'Braunschweig', 'Bremen', 'Bremen, Oldenburg', 'Bremerhaven',\n",
       "       'Buch', 'Burgdorf', 'Burghausen', 'Böblingen', 'Büren',\n",
       "       'Clausthal-Zellerfeld', 'Coburg', 'Coesfeld', 'Coesfeld-Lette',\n",
       "       'Damme', 'Darmstadt', 'Detmold', 'Deutschland', 'Dorsten',\n",
       "       'Dortmund', 'Dresden', 'Duisburg', 'Düsseldorf',\n",
       "       'Düsseldorf, Paderborn', 'Ebermannstadt', 'Einbeck', 'Erlangen',\n",
       "       'Esch', 'Eschborn', 'Essen', 'Ettlingen', 'Fellbach',\n",
       "       'Fischach, Augsburg, Freising, München, Wachau, Dresden',\n",
       "       'Frankfurt', 'Frankfurt am Main', 'Frankfurt am Main, München',\n",
       "       'Freiburg', 'Freiburg im Breisgau', 'Fürth', 'Garching',\n",
       "       'Gerlingen', 'Gießen', 'Gladbeck', 'Gotha', 'Grafing bei München',\n",
       "       'Großenlüder', 'Großwallstadt', 'Grünheide', 'Grünwald',\n",
       "       'Gunzenhausen', 'Görlitz', 'Göttingen', 'Gütersloh', 'Hamburg',\n",
       "       'Hamburg, Köln',\n",
       "       'Hamburg, München, Ulm, Donauwörth, Friedrichshafen, Manching',\n",
       "       'Hameln', 'Hanau', 'Hannover',\n",
       "       'Hannover-Braunschweig-Göttingen-Wolfsburg Region', 'Harsewinkel',\n",
       "       'Hechingen', 'Heidelberg', 'Heidenheim', 'Heilbronn', 'Hessen',\n",
       "       'Hoisdorf', 'Holm', 'Homeoffice', 'Hürth', 'Ilmenau', 'Ilsenburg',\n",
       "       'Immenstadt', 'Ingelfingen', 'Ingolstadt', 'Innsbruck', 'Jena',\n",
       "       'Jena, Oberkochen, Roßdorf', 'Jülich', 'Karlsruhe', 'Kassel',\n",
       "       'Kempten', 'Kiel', 'Kirchentellinsfurt', 'Koblenz', 'Konstanz',\n",
       "       'Kornwestheim', 'Krailling', 'Krefeld', 'Kronberg', 'Kulmbach',\n",
       "       'Köln', 'Köln, Düsseldorf', 'Königstein im Taunus', 'Künsebeck',\n",
       "       'Lampertheim', 'Langenhagen', 'Langenselbold', 'Leimen', 'Leipzig',\n",
       "       'Lingen', 'Ludwigshafen', 'Ludwigshafen am Rhein', 'Luxembourg',\n",
       "       'Lübbecke', 'Lübeck', 'Lüneburg', 'Mailand', 'Maintal', 'Mainz',\n",
       "       'Mannheim', 'Mannheim, Fürth', 'Marburg an der Lahn',\n",
       "       'Martinsried', 'Minden', 'Monheim am Rhein', 'Munich',\n",
       "       'Mühlheim am Main', 'Mülheim an der Ruhr', 'Münchberg', 'München',\n",
       "       'München, Tübingen', 'Münster', 'Neuenstadt am Kocher',\n",
       "       'Neuherberg', 'Neukölln', 'Neuried', 'Neuss', 'Neuwied',\n",
       "       'Norderstedt', 'Nordrhein-Westfalen', 'Nördlingen', 'Nürnberg',\n",
       "       'Nürnberg, München', 'Oberkochen', 'Oberschleißheim',\n",
       "       'Obersontheim', 'Obertshausen', 'Offenbach', 'Offenburg',\n",
       "       'Offingen', 'Oldenburg', 'Osnabrück', 'Osnabrück, Saarbrücken',\n",
       "       'Ostseebad Kühlungsborn', 'Ottobrunn', 'Paderborn', 'Penzberg',\n",
       "       'Planegg', 'Potsdam', 'Puchheim', 'Regensburg', 'Remscheid',\n",
       "       'Rheda-Wiedenbrück', 'Rodgau', 'Rosenberg', 'Rosenheim', 'Rust',\n",
       "       'Saarbrücken', 'Salzgitter', 'Sankt Augustin', 'Saterland',\n",
       "       'Schenefeld', 'Schrobenhausen', 'Schwabmünchen', 'Schwalbach',\n",
       "       'Schwarzenbruck', 'Schweinfurt', 'Schwäbisch Gmünd',\n",
       "       'Seligenstadt', 'Siegburg', 'Siegen', 'Sindelfingen', 'Solingen',\n",
       "       'St. Leon-Rot,', 'Starnberg', 'Stephanskirchen', 'Straubing',\n",
       "       'Straße', 'Stuttgart', 'Stuttgart, Esslingen, Sindelfingen',\n",
       "       'Stuttgart, Frankfurt am Main', 'Stuttgart, Hamburg', 'Sulzbach',\n",
       "       'Taufkirchen', 'Tettnang', 'Traunreut', 'Trittau', 'Tübingen',\n",
       "       'Ulm', 'Unterföhring', 'Unterschleißheim', 'Urbar', 'Vallendar',\n",
       "       'Verl', 'Weeze', 'Weikersheim', 'Weil am Rhein', 'Weinheim',\n",
       "       'Wesel', 'Westerstede', 'Wiesbaden', 'Winnenden', 'Wolfsburg',\n",
       "       'Wuppertal', 'Würzburg', 'Zeuthen', 'Zweibrücken'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(df[\"location\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1300                                    Nürnberg, München\n",
       "1302                                    Bremen, Oldenburg\n",
       "1310                         Stuttgart, Frankfurt am Main\n",
       "1337                               Osnabrück, Saarbrücken\n",
       "1370                           Frankfurt am Main, München\n",
       "1372                                Düsseldorf, Paderborn\n",
       "1382                                        St. Leon-Rot,\n",
       "1388                                        Hamburg, Köln\n",
       "1398                                      Mannheim, Fürth\n",
       "1460                                   Stuttgart, Hamburg\n",
       "1483                   Stuttgart, Esslingen, Sindelfingen\n",
       "1505    Hamburg, München, Ulm, Donauwörth, Friedrichsh...\n",
       "1527                                     Köln, Düsseldorf\n",
       "1532    Fischach, Augsburg, Freising, München, Wachau,...\n",
       "1557                                    München, Tübingen\n",
       "1578    Augsburg, Karlsruhe, Koblenz, München, Nürnber...\n",
       "1579    Aachen, Bonn, Dortmund, Düsseldorf, Essen, Fra...\n",
       "1585                            Jena, Oberkochen, Roßdorf\n",
       "Name: location, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show listings with more than one location\n",
    "df.loc[df[\"location\"].str.contains(\",\"), \"location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1300             Nürnberg\n",
       "1302               Bremen\n",
       "1310            Stuttgart\n",
       "1337            Osnabrück\n",
       "1370    Frankfurt am Main\n",
       "1372           Düsseldorf\n",
       "1382         St. Leon-Rot\n",
       "1388              Hamburg\n",
       "1398             Mannheim\n",
       "1460            Stuttgart\n",
       "1483            Stuttgart\n",
       "1505              Hamburg\n",
       "1527                 Köln\n",
       "1532             Fischach\n",
       "1557              München\n",
       "1578             Augsburg\n",
       "1579               Aachen\n",
       "1585                 Jena\n",
       "Name: location, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For simplicity, use first location mentioned\n",
    "# Create regular expression removing all characters after a comma\n",
    "my_regex = r\"(,).*$\"\n",
    "\n",
    "# Test regex\n",
    "df.loc[df[\"location\"].str.contains(\",\"), \"location\"].str.replace(my_regex, \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Aachen', 'Aalen', 'Ahrensburg', 'Arnstorf', 'Aschheim',\n",
       "       'Attenkirchen', 'Augsburg', 'Bad Berleburg', 'Bad Ems',\n",
       "       'Bad Gandersheim', 'Bad Homburg', 'Bad Homburg vor der Höhe',\n",
       "       'Bad Nauheim', 'Bad Salzuflen', 'Baden-Württemberg', 'Bargteheide',\n",
       "       'Bayern', 'Bayreuth', 'Bensheim', 'Bergisch Gladbach', 'Berlin',\n",
       "       'Berlin-Kreuzberg', 'Biberach', 'Biberach an der Riß', 'Bielefeld',\n",
       "       'Bochum', 'Bonn', 'Braunschweig', 'Bremen', 'Bremerhaven', 'Buch',\n",
       "       'Burgdorf', 'Burghausen', 'Böblingen', 'Büren',\n",
       "       'Clausthal-Zellerfeld', 'Coburg', 'Coesfeld', 'Coesfeld-Lette',\n",
       "       'Damme', 'Darmstadt', 'Detmold', 'Deutschland', 'Dorsten',\n",
       "       'Dortmund', 'Dresden', 'Duisburg', 'Düsseldorf', 'Ebermannstadt',\n",
       "       'Einbeck', 'Erlangen', 'Esch', 'Eschborn', 'Essen', 'Ettlingen',\n",
       "       'Fellbach', 'Fischach', 'Frankfurt', 'Frankfurt am Main',\n",
       "       'Freiburg', 'Freiburg im Breisgau', 'Fürth', 'Garching',\n",
       "       'Gerlingen', 'Gießen', 'Gladbeck', 'Gotha', 'Grafing bei München',\n",
       "       'Großenlüder', 'Großwallstadt', 'Grünheide', 'Grünwald',\n",
       "       'Gunzenhausen', 'Görlitz', 'Göttingen', 'Gütersloh', 'Hamburg',\n",
       "       'Hameln', 'Hanau', 'Hannover',\n",
       "       'Hannover-Braunschweig-Göttingen-Wolfsburg Region', 'Harsewinkel',\n",
       "       'Hechingen', 'Heidelberg', 'Heidenheim', 'Heilbronn', 'Hessen',\n",
       "       'Hoisdorf', 'Holm', 'Homeoffice', 'Hürth', 'Ilmenau', 'Ilsenburg',\n",
       "       'Immenstadt', 'Ingelfingen', 'Ingolstadt', 'Innsbruck', 'Jena',\n",
       "       'Jülich', 'Karlsruhe', 'Kassel', 'Kempten', 'Kiel',\n",
       "       'Kirchentellinsfurt', 'Koblenz', 'Konstanz', 'Kornwestheim',\n",
       "       'Krailling', 'Krefeld', 'Kronberg', 'Kulmbach', 'Köln',\n",
       "       'Königstein im Taunus', 'Künsebeck', 'Lampertheim', 'Langenhagen',\n",
       "       'Langenselbold', 'Leimen', 'Leipzig', 'Lingen', 'Ludwigshafen',\n",
       "       'Ludwigshafen am Rhein', 'Luxembourg', 'Lübbecke', 'Lübeck',\n",
       "       'Lüneburg', 'Mailand', 'Maintal', 'Mainz', 'Mannheim',\n",
       "       'Marburg an der Lahn', 'Martinsried', 'Minden', 'Monheim am Rhein',\n",
       "       'Munich', 'Mühlheim am Main', 'Mülheim an der Ruhr', 'Münchberg',\n",
       "       'München', 'Münster', 'Neuenstadt am Kocher', 'Neuherberg',\n",
       "       'Neukölln', 'Neuried', 'Neuss', 'Neuwied', 'Norderstedt',\n",
       "       'Nordrhein-Westfalen', 'Nördlingen', 'Nürnberg', 'Oberkochen',\n",
       "       'Oberschleißheim', 'Obersontheim', 'Obertshausen', 'Offenbach',\n",
       "       'Offenburg', 'Offingen', 'Oldenburg', 'Osnabrück',\n",
       "       'Ostseebad Kühlungsborn', 'Ottobrunn', 'Paderborn', 'Penzberg',\n",
       "       'Planegg', 'Potsdam', 'Puchheim', 'Regensburg', 'Remscheid',\n",
       "       'Rheda-Wiedenbrück', 'Rodgau', 'Rosenberg', 'Rosenheim', 'Rust',\n",
       "       'Saarbrücken', 'Salzgitter', 'Sankt Augustin', 'Saterland',\n",
       "       'Schenefeld', 'Schrobenhausen', 'Schwabmünchen', 'Schwalbach',\n",
       "       'Schwarzenbruck', 'Schweinfurt', 'Schwäbisch Gmünd',\n",
       "       'Seligenstadt', 'Siegburg', 'Siegen', 'Sindelfingen', 'Solingen',\n",
       "       'St. Leon-Rot', 'Starnberg', 'Stephanskirchen', 'Straubing',\n",
       "       'Straße', 'Stuttgart', 'Sulzbach', 'Taufkirchen', 'Tettnang',\n",
       "       'Traunreut', 'Trittau', 'Tübingen', 'Ulm', 'Unterföhring',\n",
       "       'Unterschleißheim', 'Urbar', 'Vallendar', 'Verl', 'Weeze',\n",
       "       'Weikersheim', 'Weil am Rhein', 'Weinheim', 'Wesel', 'Westerstede',\n",
       "       'Wiesbaden', 'Winnenden', 'Wolfsburg', 'Wuppertal', 'Würzburg',\n",
       "       'Zeuthen', 'Zweibrücken'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply regex\n",
    "my_regex = r\"(,).*$\"\n",
    "df[\"location_clean\"] = df[\"location\"].str.replace(my_regex, \"\", regex=True)\n",
    "np.sort(df[\"location_clean\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Aachen', 'Aalen', 'Ahrensburg', 'Arnstorf', 'Aschheim',\n",
       "       'Attenkirchen', 'Augsburg', 'Bad Berleburg', 'Bad Ems',\n",
       "       'Bad Gandersheim', 'Bad Homburg', 'Bad Homburg vor der Höhe',\n",
       "       'Bad Nauheim', 'Bad Salzuflen', 'Baden-Württemberg', 'Bargteheide',\n",
       "       'Bayern', 'Bayreuth', 'Bensheim', 'Bergisch Gladbach', 'Berlin',\n",
       "       'Biberach an der Riß', 'Bielefeld', 'Bochum', 'Bonn',\n",
       "       'Braunschweig', 'Bremen', 'Bremerhaven', 'Buch', 'Burgdorf',\n",
       "       'Burghausen', 'Böblingen', 'Büren', 'Clausthal-Zellerfeld',\n",
       "       'Coburg', 'Coesfeld', 'Coesfeld-Lette', 'Damme', 'Darmstadt',\n",
       "       'Detmold', 'Deutschland', 'Dorsten', 'Dortmund', 'Dresden',\n",
       "       'Duisburg', 'Düsseldorf', 'Ebermannstadt', 'Einbeck', 'Erlangen',\n",
       "       'Esch', 'Eschborn', 'Essen', 'Ettlingen', 'Fellbach', 'Fischach',\n",
       "       'Frankfurt', 'Frankfurt am Main', 'Freiburg',\n",
       "       'Freiburg im Breisgau', 'Fürth', 'Garching', 'Gerlingen', 'Gießen',\n",
       "       'Gladbeck', 'Gotha', 'Grafing bei München', 'Großenlüder',\n",
       "       'Großwallstadt', 'Grünheide', 'Grünwald', 'Gunzenhausen',\n",
       "       'Görlitz', 'Göttingen', 'Gütersloh', 'Hamburg', 'Hameln', 'Hanau',\n",
       "       'Hannover', 'Harsewinkel', 'Hechingen', 'Heidelberg', 'Heidenheim',\n",
       "       'Heilbronn', 'Hessen', 'Hoisdorf', 'Holm', 'Hürth', 'Ilmenau',\n",
       "       'Ilsenburg', 'Immenstadt', 'Ingelfingen', 'Ingolstadt',\n",
       "       'Innsbruck', 'Jena', 'Jülich', 'Karlsruhe', 'Kassel', 'Kempten',\n",
       "       'Kiel', 'Kirchentellinsfurt', 'Koblenz', 'Konstanz',\n",
       "       'Kornwestheim', 'Krailling', 'Krefeld', 'Kronberg', 'Kulmbach',\n",
       "       'Köln', 'Königstein im Taunus', 'Künsebeck', 'Lampertheim',\n",
       "       'Langenhagen', 'Langenselbold', 'Leimen', 'Leipzig', 'Lingen',\n",
       "       'Ludwigshafen', 'Luxembourg', 'Lübbecke', 'Lübeck', 'Lüneburg',\n",
       "       'Mailand', 'Maintal', 'Mainz', 'Mannheim', 'Marburg an der Lahn',\n",
       "       'Martinsried', 'Minden', 'Monheim am Rhein', 'Mühlheim am Main',\n",
       "       'Mülheim an der Ruhr', 'Münchberg', 'München', 'Münster',\n",
       "       'Neuenstadt am Kocher', 'Neuherberg', 'Neuried', 'Neuss',\n",
       "       'Neuwied', 'Norderstedt', 'Nordrhein-Westfalen', 'Nördlingen',\n",
       "       'Nürnberg', 'Oberkochen', 'Oberschleißheim', 'Obersontheim',\n",
       "       'Obertshausen', 'Offenbach', 'Offenburg', 'Offingen', 'Oldenburg',\n",
       "       'Osnabrück', 'Ostseebad Kühlungsborn', 'Ottobrunn', 'Paderborn',\n",
       "       'Penzberg', 'Planegg', 'Potsdam', 'Puchheim', 'Regensburg',\n",
       "       'Remscheid', 'Rheda-Wiedenbrück', 'Rodgau', 'Rosenberg',\n",
       "       'Rosenheim', 'Rust', 'Saarbrücken', 'Salzgitter', 'Sankt Augustin',\n",
       "       'Saterland', 'Schenefeld', 'Schrobenhausen', 'Schwabmünchen',\n",
       "       'Schwalbach', 'Schwarzenbruck', 'Schweinfurt', 'Schwäbisch Gmünd',\n",
       "       'Seligenstadt', 'Siegburg', 'Siegen', 'Sindelfingen', 'Solingen',\n",
       "       'St. Leon-Rot', 'Starnberg', 'Stephanskirchen', 'Straubing',\n",
       "       'Straße', 'Stuttgart', 'Sulzbach', 'Taufkirchen', 'Tettnang',\n",
       "       'Traunreut', 'Trittau', 'Tübingen', 'Ulm', 'Unterföhring',\n",
       "       'Unterschleißheim', 'Urbar', 'Vallendar', 'Verl', 'Weeze',\n",
       "       'Weikersheim', 'Weil am Rhein', 'Weinheim', 'Wesel', 'Westerstede',\n",
       "       'Wiesbaden', 'Winnenden', 'Wolfsburg', 'Wuppertal', 'Würzburg',\n",
       "       'Zeuthen', 'Zweibrücken'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some locations need extra attention\n",
    "location_dict = {\n",
    "    \"Biberach\": \"Biberach an der Riß\",\n",
    "    \"Hannover-Braunschweig-Göttingen-Wolfsburg Region\": \"Hannover\",\n",
    "    \"Ludwigshafen am Rhein\": \"Ludwigshafen\",\n",
    "    \"Berlin-Kreuzberg\": \"Berlin\",\n",
    "    \"Neukölln\": \"Berlin\",\n",
    "    \"Munich\": \"München\",\n",
    "    \"Homeoffice\": \"Deutschland\",\n",
    "}\n",
    "\n",
    "for old_location, new_location in location_dict.items():\n",
    "    df.loc[df[\"location_clean\"] == old_location, \"location_clean\"] = new_location\n",
    "\n",
    "np.sort(df[\"location_clean\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location_clean\n",
       "Berlin               326\n",
       "München              212\n",
       "Hamburg              112\n",
       "Deutschland          109\n",
       "Frankfurt am Main     88\n",
       "                    ... \n",
       "Penzberg               1\n",
       "Büren                  1\n",
       "Gießen                 1\n",
       "Urbar                  1\n",
       "Münchberg              1\n",
       "Name: count, Length: 213, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"location_clean\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1&1 Mail & Media Applications SE',\n",
       " '1KOMMA5°',\n",
       " '1Komma5° GmbH',\n",
       " '1komma6 - Multimediale Dienstleistungen GmbH',\n",
       " '1x2 Technologies GmbH',\n",
       " '4.screen GmbH',\n",
       " '4screen',\n",
       " 'ABB',\n",
       " 'ABOUT YOU',\n",
       " 'ABOUT YOU AG & Co. KG',\n",
       " 'ACCURE Battery Intelligence',\n",
       " 'ACONEXT',\n",
       " 'ACONEXT Stuttgart GmbH',\n",
       " 'ADAC',\n",
       " 'ADAC Allgemeiner Deutscher Automobil Club',\n",
       " 'ADEAL Systems GmbH',\n",
       " 'ADG Apotheken-Dienstleistungsgesellschaft mbH',\n",
       " 'ADM',\n",
       " 'AI Futures',\n",
       " 'AI.Associates GmbH',\n",
       " 'AITAD GmbH',\n",
       " 'AL Solutions',\n",
       " 'ALACRiS Theranostics GmbH',\n",
       " 'ALDI Einkauf SE & Co. oHG',\n",
       " 'ALDI SÜD',\n",
       " 'ALTEN Consulting Services GmbH',\n",
       " 'ALTEN Germany',\n",
       " 'AMAI GmbH',\n",
       " 'AMD',\n",
       " 'AOK Bayern - Die Gesundheitskasse',\n",
       " 'ATH Altonaer-Technologie-Holding GmbH',\n",
       " 'ATLAS ELEKTRONIK GmbH',\n",
       " 'ATLAS MARIDAN ApS',\n",
       " 'ATOSS Software AG',\n",
       " 'AUTO1 Group',\n",
       " 'AVAT Automation GmbH',\n",
       " 'AWS EMEA SARL (Germany Branch)',\n",
       " 'AXULUS',\n",
       " 'AbbVie',\n",
       " 'AbbVie Deutschland GmbH & Co. KG',\n",
       " 'Accenture',\n",
       " 'Aerzener Maschinenfabrik',\n",
       " 'Aignostics',\n",
       " 'Ailio GmbH',\n",
       " 'Akkodis',\n",
       " 'Aklass Solutions',\n",
       " 'Albatross AI',\n",
       " 'Alcedis - a HUMA company',\n",
       " 'Alexander Thamm GmbH',\n",
       " 'Alfred-Wegener-Institut für Polar- und...',\n",
       " 'Algea Care',\n",
       " 'Alithea Bio',\n",
       " 'AlixPartners',\n",
       " 'Allgeier Public',\n",
       " 'Allianz',\n",
       " 'Allianz Digital Health GmbH',\n",
       " 'Allianz Versicherungs-AG',\n",
       " 'Allos Hof-Manufaktur GmbH',\n",
       " 'Almedia',\n",
       " 'Amazon',\n",
       " 'Amazon Development Center Germany GmbH',\n",
       " 'Amazon Development Center Germany GmbH - C92',\n",
       " 'Amazon Europe Core',\n",
       " 'Amazon Web Services (AWS)',\n",
       " 'Amazon Web Services Development Center Germany...',\n",
       " 'Amfileon AG',\n",
       " 'Ammerländer Versicherung VVaG',\n",
       " 'Amprion GmbH',\n",
       " 'Amundi',\n",
       " 'Amundi Deutschland GmbH',\n",
       " 'Analytik Jena GmbH+Co. KG',\n",
       " 'AppLike GmbH',\n",
       " 'Appinio',\n",
       " 'Aptiv',\n",
       " 'Arete AG',\n",
       " 'Ariadne',\n",
       " 'Artivion EMEA',\n",
       " 'Arvato',\n",
       " 'Arvato Systems',\n",
       " 'Arvato Systems Digital GmbH',\n",
       " 'Ascendis Pharma',\n",
       " 'Asklepios Service IT GmbH',\n",
       " 'Atruvia AG',\n",
       " 'AudaCity Capital Management',\n",
       " 'Audible',\n",
       " 'Ausbildung.de',\n",
       " 'Autonomous Teaming Solutions',\n",
       " 'Avo Intelligence',\n",
       " 'Axel Springer',\n",
       " 'Axel Springer National Media & Tech GmbH & Co. KG',\n",
       " 'BARMER',\n",
       " 'BASF',\n",
       " 'BASF SE',\n",
       " 'BAUER Group',\n",
       " 'BCG X',\n",
       " 'BI Pharma GmbH&Co.KG',\n",
       " 'BI Vetmedica GmbH',\n",
       " 'BID Bayerischer Inkasso Dienst GmbH',\n",
       " 'BIKAR-METALLE GmbH',\n",
       " 'BIOTRONIK Corporate Services SE',\n",
       " 'BIOTYPE GmbH',\n",
       " 'BITA',\n",
       " 'BMW',\n",
       " 'BMW Group',\n",
       " 'BN Automation AG',\n",
       " 'BNP Paribas Personal Investors',\n",
       " 'BRIGHT Testing GmbH',\n",
       " 'BRUSS Sealing Systems GmbH',\n",
       " 'BUDNI Handels- und Service GmbH & Co. KG',\n",
       " 'BWF Group',\n",
       " 'BWorks HR Professional',\n",
       " 'BYK Additives',\n",
       " 'BYK-Chemie GmbH',\n",
       " 'Babbel GmbH',\n",
       " 'Baker Tilly',\n",
       " 'Barbaricum',\n",
       " 'Baumlink',\n",
       " 'BayWa r.e. Solar Trade Holding GmbH',\n",
       " 'Bayer',\n",
       " 'Bayerisches Landesamt für Gesundheit und Lebensmittelsicherheit',\n",
       " 'Bayerisches Landesamt für Statistik',\n",
       " 'Beam AI',\n",
       " 'BearingPoint',\n",
       " 'Bechtle GmbH Bremen',\n",
       " 'Bechtle GmbH IT-Systemhaus Bremen',\n",
       " 'Behrend e.K.',\n",
       " 'Beiersdorf',\n",
       " 'Beiersdorf Shared Services',\n",
       " 'Bergfreunde GmbH',\n",
       " 'Berliner Wasserbetriebe',\n",
       " 'Bertrandt AG',\n",
       " 'Binance',\n",
       " 'BioNTech SE',\n",
       " 'Biomarker Services GmbH',\n",
       " 'Blacklane',\n",
       " 'BlueOak Advertising GmbH',\n",
       " 'BluePrint Executive Search',\n",
       " 'BlueThrone',\n",
       " 'Boehringer Ingelheim',\n",
       " 'Bolt',\n",
       " 'Booz Allen',\n",
       " 'Booz Allen Hamilton',\n",
       " 'Bosch',\n",
       " 'Bosch Gruppe',\n",
       " 'Boston Consulting Group',\n",
       " 'Branch Tech',\n",
       " 'Breuninger',\n",
       " 'BridgingIT GmbH',\n",
       " 'Bring! Labs AG',\n",
       " 'Brunel',\n",
       " 'Bundesagentur für Arbeit',\n",
       " 'C. Melchers GmbH & Co. KG',\n",
       " 'CANCOM SE',\n",
       " 'CBM Christoffel-Blindenmission Christian Blind Mission e.V.',\n",
       " 'CBTW',\n",
       " 'CDP',\n",
       " 'CEEZER',\n",
       " 'CGI',\n",
       " 'CHECK24',\n",
       " 'CHECK24 Vergleichsportal',\n",
       " 'CHEFS CULINAR',\n",
       " 'CHEFS CULINAR GmbH & Co. KG',\n",
       " 'CIDEON Software & Services GmbH & Co. KG',\n",
       " 'CLAAS KGaA mbH',\n",
       " 'CONET',\n",
       " 'CONNECTMETA.AI',\n",
       " 'COREcruitment Ltd',\n",
       " 'CRELUX GmbH',\n",
       " 'CSL Behring',\n",
       " 'CUJU',\n",
       " 'Cambrium',\n",
       " 'Capgemini',\n",
       " 'Capgemini Deutschland',\n",
       " 'Capgemini Invent',\n",
       " 'CarOnSale',\n",
       " 'Carhartt WIP (Work In Progress)',\n",
       " 'Carl Zeiss IQS Software R&D Center',\n",
       " 'Celonis',\n",
       " 'Centric Software',\n",
       " 'Certivity',\n",
       " 'Chaozhou Three-circle Group Co., Ltd.',\n",
       " 'Cherry Ventures',\n",
       " 'Cherry Ventures Management GmbH',\n",
       " 'Choco',\n",
       " 'Choco Communications GmbH',\n",
       " 'Christ&Company Consulting GmbH',\n",
       " 'Ciklo Talent',\n",
       " 'Cimt ag',\n",
       " 'Cinemo',\n",
       " 'Cint',\n",
       " 'Clariness',\n",
       " 'Climatiq',\n",
       " 'Cloover',\n",
       " 'Cobrainer',\n",
       " 'Cofinity-X',\n",
       " 'Cofinpro AG',\n",
       " 'Cognitivo GmbH',\n",
       " 'Collaboration Betters The World GmbH',\n",
       " 'Coltech',\n",
       " 'Comma Soft',\n",
       " 'Comma Soft AG',\n",
       " 'Comparus GmbH',\n",
       " 'CompuGroup Medical',\n",
       " 'CompuGroup Medical Deutschland AG',\n",
       " 'CompuGroup Medical SE & Co. KGaA',\n",
       " 'CompuSafe Data Systems AG',\n",
       " 'Computer Futures',\n",
       " 'Computomics',\n",
       " 'Control Expert GmbH',\n",
       " 'Convit GmbH',\n",
       " 'Convolut',\n",
       " 'Coriolis Pharma Research GmbH',\n",
       " 'Cosuno',\n",
       " 'Cozero',\n",
       " 'Crayon',\n",
       " 'Crealytics',\n",
       " 'Creditplus Bank AG',\n",
       " 'CrowdStrike',\n",
       " 'CureVac',\n",
       " 'Cyber Valley',\n",
       " 'Cytiva',\n",
       " 'DADAJ',\n",
       " 'DAHAG Rechtsservices AG',\n",
       " 'DAMEDIC GmbH',\n",
       " 'DATASEC information factory',\n",
       " 'DATEV eG',\n",
       " 'DEVnet',\n",
       " 'DEVnet Holding',\n",
       " 'DFB',\n",
       " 'DHL Consulting GmbH',\n",
       " 'DIN Solutions GmbH',\n",
       " 'DOUGLAS',\n",
       " 'DR. JOHANNES HEIDENHAIN GmbH',\n",
       " 'DYMATRIX',\n",
       " 'DZ BANK AG',\n",
       " 'Daiichi Sankyo Europe',\n",
       " 'Data-Talent GmbH',\n",
       " 'DataCamp',\n",
       " 'DataCraft',\n",
       " 'DataMonkey',\n",
       " 'Datamics',\n",
       " 'DeepRec.ai',\n",
       " 'Deichmann',\n",
       " 'Deichmann SE',\n",
       " 'Delivery Hero',\n",
       " 'Deloitte',\n",
       " 'Deloitte GmbH',\n",
       " 'Deltia',\n",
       " 'Dennemeyer',\n",
       " 'Deutsche Apotheker- und Ärztebank eG - apoBank',\n",
       " 'Deutsche Bank',\n",
       " 'Deutsche Bundesbank',\n",
       " 'Deutsche Kreditbank AG (DKB)',\n",
       " 'Deutsche Rentenversicherung Bund',\n",
       " 'Deutsches Elektronen-Synchrotron DESY',\n",
       " 'Deutsches Krebsforschungszentrum',\n",
       " 'Devoteam I Google Cloud Partner',\n",
       " 'DiMOS Operations GmbH',\n",
       " 'DigiTech Search',\n",
       " 'Digital Charging Solutions GmbH',\n",
       " 'DigitalTwin Technology GmbH',\n",
       " 'Digitaltreiber UG',\n",
       " 'Digitl',\n",
       " 'Discover International',\n",
       " 'Doctolib',\n",
       " 'Dohle Handelsgruppe Holding GmbH & Co. KG',\n",
       " 'Dr. Kurt Wolff GmbH & Co. KG',\n",
       " 'Dr. Wolff Group',\n",
       " 'Drees & Sommer SE',\n",
       " 'Dräger',\n",
       " 'Drägerwerk AG & Co. KGaA',\n",
       " 'E.ON Digital Technology GmbH',\n",
       " 'ECE',\n",
       " 'ECE Group GmbH & Co. KG',\n",
       " 'ECMWF',\n",
       " 'EGYM GmbH',\n",
       " 'EGYM | DACH',\n",
       " 'EIDU',\n",
       " 'EIDU GmbH',\n",
       " 'EPM Scientific',\n",
       " 'ERC System',\n",
       " 'ERDMANN-Softwaregesellschaft mbH',\n",
       " 'ERGO Group',\n",
       " 'ES-Tec GmbH',\n",
       " 'ESL FACEIT Group - EFG',\n",
       " 'ESQlabs GmbH',\n",
       " 'EWE TEL GmbH',\n",
       " 'EY',\n",
       " 'Ebenbuild',\n",
       " 'Eggersmann - Gruppe',\n",
       " 'Eggersmann Gruppe',\n",
       " 'Ehrenmüller GmbH',\n",
       " 'ElevenLabs',\n",
       " 'Embassy of the United States of America',\n",
       " 'Emma – The Sleep Company',\n",
       " 'Empion',\n",
       " 'EnBW Energie Baden-Württemberg AG',\n",
       " 'Encavis AG',\n",
       " 'EnergyEffizienz GmbH',\n",
       " 'Enjins',\n",
       " 'Enpal',\n",
       " 'Enpal Dragon GmbH',\n",
       " 'Entrix',\n",
       " 'Entrix GmbH',\n",
       " 'Enzo',\n",
       " 'Enzo Tech Group',\n",
       " 'Ergotopia',\n",
       " \"Ernsting's Family GMBH & CO. KG\",\n",
       " 'Ernsting’s family',\n",
       " 'Etribes',\n",
       " 'Europa Park GmbH & Co Mack KG.',\n",
       " 'Europa-Park Erlebnis-Resort',\n",
       " 'Europa-Park GmbH & Co Mack KG',\n",
       " 'European Centre for Medium-Range Weather Forecasts',\n",
       " 'European Tech Recruit',\n",
       " 'European X-Ray Free-Electron Laser Facility GmbH',\n",
       " 'Eversion Technologies',\n",
       " 'Evonik',\n",
       " 'Exact Sciences Corporation',\n",
       " 'ExoMatter',\n",
       " 'Expatrio',\n",
       " 'Expleo',\n",
       " 'Expleo Group',\n",
       " 'FERCHAU GmbH',\n",
       " 'FINN',\n",
       " 'FLYERALARM Bit Labs GmbH',\n",
       " 'FOM University of Applied Sciences for Economics and Management',\n",
       " 'FORRS Partners GmbH',\n",
       " 'Few&Far',\n",
       " 'Fiber Experts Deutschland GmbH',\n",
       " 'Finanz-DATA GmbH',\n",
       " 'Finanzamt Kassel',\n",
       " 'Finanzguru',\n",
       " 'Fincon Reply GmbH',\n",
       " 'Fit Analytics',\n",
       " 'Flexa',\n",
       " 'Flink',\n",
       " 'Flip',\n",
       " 'Floortex Europe Ltd.',\n",
       " 'Flughafen Hannover Langenhagen GmbH',\n",
       " 'Forschungszentrum Jülich GmbH',\n",
       " 'Forvis Mazars GmbH & Co. KG',\n",
       " 'Forward-earth',\n",
       " 'FoxBase GmbH',\n",
       " 'Franz & Wach Personalservice GmbH',\n",
       " 'Fraunhofer FIT',\n",
       " 'Fraunhofer-Institute for Microelectronic Circuits and Systems',\n",
       " 'Freie Universität Berlin',\n",
       " 'Friedrich-Schiller-Universität Jena',\n",
       " 'Fusion Consulting',\n",
       " 'Futurae Technologies AG',\n",
       " 'Futurised GmbH',\n",
       " 'GAF AG',\n",
       " 'GARANT Holding GmbH',\n",
       " 'GASCADE Gastransport GmbH',\n",
       " 'GEMA - Gesellschaft für musik. Aufführungs- und mechan. Vervielfältigungsrechte',\n",
       " 'GEMÜ Group',\n",
       " 'GENERALI DEUTSCHLAND AG',\n",
       " 'GHARAGE',\n",
       " 'GIM Gesellschaft für innovative Marktforschung mbH',\n",
       " 'GSI Helmholtzzentrum für Schwerionenforschung',\n",
       " 'GSK',\n",
       " 'GWQ ServicePlus AG',\n",
       " 'Gebr. Heinemann SE & Co. KG',\n",
       " 'Gen Re',\n",
       " 'Generali Deutschland AG',\n",
       " 'German Aerospace Center (DLR)',\n",
       " 'Gesellschaft für musikalische Aufführungs- und...',\n",
       " 'GetML Research',\n",
       " 'GetYourGuide',\n",
       " 'Getriebebau NORD GmbH & Co. KG',\n",
       " 'Gießerei-Institut der RWTH Aachen',\n",
       " 'Gigs',\n",
       " 'GlassDollar',\n",
       " 'Global Energy Interconnection Research Institute Europe GmbH',\n",
       " 'Global Market Solutions - Germany',\n",
       " 'Global University Systems',\n",
       " 'Gnosis',\n",
       " 'Goldner GmbH',\n",
       " 'Google',\n",
       " 'Green Energy Origin (GEO)',\n",
       " 'Green Fusion',\n",
       " 'Green Fusion GmbH',\n",
       " 'Green Value Management Ltd.',\n",
       " 'GreenPocket GmbH',\n",
       " 'Greenbootcamps GmbH',\n",
       " 'Grimme Landmaschinenfabrik',\n",
       " 'Grimme Landmaschinenfabrik GmbH & Co. KG',\n",
       " 'Grohe AG',\n",
       " 'Groß Business Group GmbH',\n",
       " 'Grünenthal',\n",
       " 'HAGIUS',\n",
       " 'HAPEKO Deutschland GmbH',\n",
       " 'HAUSGOLD | talocasa GmbH',\n",
       " 'HDI AG',\n",
       " 'HIT Handelsgruppe GmbH & Co. KG',\n",
       " 'HMS Analytical Software GmbH',\n",
       " 'HMS Analytical Software | Consulting & End-to-End Solutions for Data Science & Analytics',\n",
       " 'HP',\n",
       " 'HR UNIVERSAL GmbH',\n",
       " 'HUK-COBURG',\n",
       " 'HUK-COBURG Versicherungsgruppe',\n",
       " 'Hamburg University of Technology',\n",
       " 'Hamlyn Williams',\n",
       " 'Handelsblatt',\n",
       " 'Hannover Re',\n",
       " 'Hannover Rück SE',\n",
       " 'HanseMerkur',\n",
       " 'Harvey Nash',\n",
       " 'Hashlist',\n",
       " 'Haufe Group SE',\n",
       " 'Havas Group',\n",
       " 'Hawk',\n",
       " 'Hays – Working for your tomorrow',\n",
       " 'Heidelberg Materials AG',\n",
       " 'Heidelberg University',\n",
       " 'Hellowork Consultants',\n",
       " 'Helmholtz Zentrum München',\n",
       " 'Helpling',\n",
       " 'Henkel',\n",
       " 'Hetzner',\n",
       " 'Highberg MediaMinds',\n",
       " 'Highlander Solutions',\n",
       " 'Hit Handelsgruppe GmbH & Co. KG',\n",
       " 'Hochschule Kaiserslautern',\n",
       " 'Hopmann Marketing Analytics GmbH',\n",
       " 'Hopmann | Marketing Analytics Inh. Jörg Hopmann',\n",
       " 'Horváth',\n",
       " 'Hottgenroth Gruppe',\n",
       " 'Hyundai Motor Deutschland GmbH',\n",
       " 'Händlerbund',\n",
       " 'IABG',\n",
       " 'IBA',\n",
       " 'IBA Dosimetry GmbH',\n",
       " 'ICIS Tschach Solution',\n",
       " 'IK Partners',\n",
       " 'ING',\n",
       " 'ING Deutschland',\n",
       " 'IOTIS GmbH',\n",
       " 'IPPEN.MEDIA',\n",
       " 'ISS Software GmbH',\n",
       " 'IT International Mobility',\n",
       " 'IT-P Information Technology-Partner GmbH',\n",
       " 'IT-Service GmbH',\n",
       " 'IT4IPM GmbH',\n",
       " 'IUNA AI',\n",
       " 'IfTA GmbH',\n",
       " 'Ilsenburger Grobblech GmbH',\n",
       " 'Impala Search',\n",
       " 'Incari Development Platform',\n",
       " 'Indivumed GmbH',\n",
       " 'Infineon Technologies',\n",
       " 'Infraserv Höchst',\n",
       " 'Innomotics',\n",
       " 'Instaffo',\n",
       " 'Instapro Group',\n",
       " 'Institut für Medizinische Informatik',\n",
       " 'Intapp',\n",
       " 'IntegrityNext',\n",
       " 'InterEx Group',\n",
       " 'InterJob® GmbH',\n",
       " 'InterWorks',\n",
       " 'Interhyp Gruppe',\n",
       " 'Invia Travel Germany GmbH',\n",
       " 'Ippen Digital',\n",
       " 'Ipsos',\n",
       " 'Iron EagleX, Inc.',\n",
       " 'J. RETTENMAIER & SÖHNE GmbH + Co KG',\n",
       " 'J. Rettenmaier & Söhne GmbH + Co. KG.',\n",
       " 'JAAI | JUST ADD AI GmbH',\n",
       " 'JET Services Marketing GmbH & Co. KG',\n",
       " 'JSS ASSOCIATES',\n",
       " 'JUST ADD AI GmbH',\n",
       " 'Jina AI',\n",
       " 'Johnson & Johnson',\n",
       " 'Just Eat Takeaway.com',\n",
       " 'KI performance GmbH',\n",
       " 'KLA',\n",
       " 'KOSATEC Computer GmbH',\n",
       " 'KPMG AG Wirtschaftsprüfungsgesellschaft',\n",
       " 'KWS Group',\n",
       " 'Kassenzahnärztliche Vereinigung Hessen - Körperschaft des öffentlichen Rechts',\n",
       " 'Kayzen',\n",
       " 'Key-Work Consulting GmbH',\n",
       " 'Kienbaum Consultants International GmbH - Zentrale',\n",
       " 'Klang Games',\n",
       " 'Klim',\n",
       " 'Klinik für Allgemein-, Viszeral- und...',\n",
       " 'Knuddels',\n",
       " 'Knuddels GmbH & Co. KG',\n",
       " 'Konfuzio',\n",
       " 'Korro AI',\n",
       " 'Kreativstorm',\n",
       " 'Kärcher',\n",
       " 'LANCH',\n",
       " 'LGC Axolabs',\n",
       " 'LILT',\n",
       " 'Laboremus GmbH',\n",
       " 'Ladgov Corporation',\n",
       " 'Landeshauptstadt Stuttgart',\n",
       " 'Landeskrankenhilfe V.V.a.G.',\n",
       " 'Landkreis Bodenseekreis',\n",
       " 'Lang Service GmbH',\n",
       " 'Lehmann + Pioneers Digital GmbH',\n",
       " 'Leibniz Institut für Astrophysik',\n",
       " 'Leibniz-Institut für Analytische Wissenschaften -...',\n",
       " 'Leibniz-Institut für Analytische Wissenschaften -ISAS - e.V.',\n",
       " 'Leibniz-Institut für Astrophysik Potsdam',\n",
       " 'Leibniz-Institut für Naturstoff- Forschung u. Infektionsbiologie e.V.',\n",
       " 'Leibniz-Institut für Naturstoff-Forschung und...',\n",
       " 'Leibniz-Institute of Atmospheric Physics',\n",
       " 'Leipfinger-Bader',\n",
       " 'Leipzig University',\n",
       " 'LexisNexis',\n",
       " 'LexisNexis GmbH',\n",
       " 'Lexware',\n",
       " 'Libra',\n",
       " 'Liebherr Group',\n",
       " 'Liebherr-Hausgeräte Ochsenhausen GmbH',\n",
       " 'Lieferando',\n",
       " 'Life Science Nord',\n",
       " 'Lindner Group',\n",
       " 'Lipotype GmbH',\n",
       " 'Lloyds Bank GmbH',\n",
       " 'Logic Hire Solutions LTD',\n",
       " 'Lonza',\n",
       " 'Lotum',\n",
       " 'Lotum GmbH',\n",
       " 'Lotum media GmbH',\n",
       " 'Lufthansa Technik',\n",
       " 'Luminary Group',\n",
       " 'Lumino',\n",
       " 'Lunit',\n",
       " 'Lunit Cancer Screening',\n",
       " 'Löwenstein Medical SE & Co. KG',\n",
       " 'M&M Software GmbH',\n",
       " 'MAINGAU Energie GmbH',\n",
       " 'MAM Gruppe',\n",
       " 'MAN Truck & Bus Group',\n",
       " 'MARKT-PILOT',\n",
       " 'MED-EL Medical Electronics',\n",
       " 'MEDIFOX DAN GmbH',\n",
       " 'MHP – A Porsche Company',\n",
       " 'MICE Portal GmbH',\n",
       " 'ML6 | Your partner in AI',\n",
       " 'MLL Münchner Leukämielabor GmbH',\n",
       " 'MPA Pharma GmbH',\n",
       " 'MPB',\n",
       " 'MTU Aero Engines',\n",
       " 'MVGM Deutschland',\n",
       " 'MVGM International',\n",
       " 'MVV Trading GmbH',\n",
       " 'MVZ Düsseldorf-Centrum GbR',\n",
       " 'MVZ Martinsried GmbH',\n",
       " 'Machine Learning Reply GmbH',\n",
       " 'Mainwebsolutions',\n",
       " 'Makersite GmbH',\n",
       " \"Marc O'Polo\",\n",
       " 'Markant Gruppe',\n",
       " 'Masentó Group',\n",
       " 'Masterschool',\n",
       " 'Materna Information & Communications SE',\n",
       " 'Max Planck Computing and Data Facility (MPCDF)',\n",
       " 'Max Planck Digital Library',\n",
       " 'Max Planck Institute for Chemical Energy Conversion',\n",
       " 'Max-Planck-Institut für Biologie Tübingen',\n",
       " 'Max-Planck-Institut für Kolloid- und...',\n",
       " 'Max-Planck-Institut für Meteorologie',\n",
       " 'Mechanics of Materials',\n",
       " 'MediSync AI',\n",
       " 'Mediaplus Group',\n",
       " 'Mediaplus Gruppe',\n",
       " 'Medpace',\n",
       " 'Medscape',\n",
       " 'Melchers',\n",
       " 'MeloTech',\n",
       " 'Melotech',\n",
       " 'Mendel Verlag GmbH & Co.KG',\n",
       " 'Merantix Capital',\n",
       " 'Mercedes-Benz AG',\n",
       " 'Mercedes-Benz Tech Innovation',\n",
       " 'Merck Group',\n",
       " 'Merck Healthcare',\n",
       " 'Merz Therapeutics',\n",
       " 'Meta',\n",
       " 'Meyerthole Siems Kohlruss Gesellschaft für...',\n",
       " 'Michael Bauer Research GmbH',\n",
       " 'Midea Group',\n",
       " 'Milldent GmbH',\n",
       " 'Miltenyi Biotec',\n",
       " 'Mindfuel',\n",
       " 'Mindpeak GmbH',\n",
       " 'MobiLab Solutions',\n",
       " 'Mondelēz International',\n",
       " 'Morpheus Talent Solutions',\n",
       " 'Munich Re',\n",
       " 'München',\n",
       " 'NEEW Ventures',\n",
       " 'NETCONOMY GmbH',\n",
       " 'NOWEDA Apothekergenossenschaft eG',\n",
       " 'Nanogami',\n",
       " 'NeoPredics AG',\n",
       " 'Nestlé',\n",
       " 'Net Services S.à.r.l.',\n",
       " 'Netlight',\n",
       " 'New Yorker',\n",
       " 'NexWafe',\n",
       " 'Nextcoder Softwareentwicklungs UG',\n",
       " 'NielsenIQ',\n",
       " 'Nokia',\n",
       " 'Nomad Atomics',\n",
       " 'NorCom Information Technology GmbH & Co. KGaA',\n",
       " 'Nordmann, Rassmann GmbH',\n",
       " 'Norgine',\n",
       " 'Novo AI',\n",
       " 'Nucs AI',\n",
       " 'Nuromedia GmbH',\n",
       " 'Nuvisan GmbH',\n",
       " 'OBI Group Holding SE & Co. KGaA',\n",
       " 'OLX',\n",
       " 'OMMAX GmbH',\n",
       " 'OPITZ CONSULTING Deutschland GmbH',\n",
       " 'OUTFITTERY',\n",
       " 'OXG Glasfaser GmbH',\n",
       " 'OYAK ANKER Bank GmbH',\n",
       " 'Olympus EMEA',\n",
       " 'Omio',\n",
       " 'Optronics, System Technologies and Image...',\n",
       " 'Orange Cyberdefense',\n",
       " 'Orange Quarter',\n",
       " 'Orbem',\n",
       " 'Orbem GmbH',\n",
       " 'Otto (GmbH & Co KG)',\n",
       " 'Otto Group data.works',\n",
       " 'Outdooractive',\n",
       " 'PAIR Finance',\n",
       " 'PARI Firmengruppe',\n",
       " 'PAUL HARTMANN AG',\n",
       " 'PAYBACK',\n",
       " 'PIMCO Prime Real Estate',\n",
       " 'PLAN D',\n",
       " 'PREVENTIO GmbH',\n",
       " 'PROLYTIC',\n",
       " 'PSI Software',\n",
       " 'Pair Finance GmbH',\n",
       " 'Parker B Associates',\n",
       " 'ParshipMeet Group',\n",
       " 'PartSpace',\n",
       " 'Partex',\n",
       " 'Pass App',\n",
       " 'Peek & Cloppenburg B.V. & Co. KG',\n",
       " 'Peek & Cloppenburg* B.V. & Co. KG, Düsseldorf',\n",
       " 'Pexon Consulting GmbH',\n",
       " 'Pfizer',\n",
       " 'Pflegewegweiser GmbH',\n",
       " 'Phoenix Medical',\n",
       " 'Pivot Search',\n",
       " 'Pivotal',\n",
       " 'Planet A Foods GmbH',\n",
       " 'PolarAnalytics',\n",
       " 'Polyteia',\n",
       " 'Porsche Consulting',\n",
       " 'PowerCo',\n",
       " 'Predium',\n",
       " 'Predium Technology GmbH',\n",
       " 'Preventio',\n",
       " 'Preventio GmbH',\n",
       " 'Primal State Performance GmbH',\n",
       " 'ProCredit Holding',\n",
       " 'ProSiebenSat.1 Tech & Services GmbH',\n",
       " 'Process& GmbH',\n",
       " 'Processand',\n",
       " 'Procter & Gamble',\n",
       " 'Professional Scientists GmbH & Co. KG',\n",
       " 'Project A',\n",
       " 'Projektträger Jülich (PtJ)',\n",
       " 'Property Finder',\n",
       " 'Protection One GmbH',\n",
       " 'Proteros biostructures GmbH',\n",
       " 'Provide',\n",
       " 'Publicis Media Germany',\n",
       " 'Puls',\n",
       " 'PwC Germany',\n",
       " 'PŸUR | Tele Columbus',\n",
       " 'Q ENERGY',\n",
       " 'QIMIA GmbH',\n",
       " 'QPLIX GmbH',\n",
       " 'Qimia GmbH',\n",
       " 'Qruise',\n",
       " 'Quantagonia',\n",
       " 'Quantistry',\n",
       " 'QuantumBlack, AI by McKinsey',\n",
       " 'QuoData',\n",
       " 'Quotacom',\n",
       " 'R+V Allgemeine Versicherung AG',\n",
       " 'REMATIQ',\n",
       " 'REWE Group',\n",
       " 'REWE digital',\n",
       " 'RHEINISCHE POST Medien GmbH',\n",
       " 'RISK IDENT',\n",
       " 'RJC Group',\n",
       " 'RMS. Der Audiovermarkter.',\n",
       " 'ROLAND Rechtsschutz-Versicherungs-AG',\n",
       " 'RSight®',\n",
       " 'RWTH Aachen',\n",
       " 'RWTH Aachen University',\n",
       " 'Rabot Energy',\n",
       " 'Railpool',\n",
       " 'Railpool GmbH',\n",
       " 'Ratbacher GmbH',\n",
       " 'Ratepay GmbH',\n",
       " 'Rausgegangen',\n",
       " 'Razor Group',\n",
       " 'Re7 Capital',\n",
       " 'Rechenzentrum der Finanzverwaltung des Landes Nordrhein Westfalen',\n",
       " 'Remobi',\n",
       " 'Reply',\n",
       " 'RevenueCat',\n",
       " 'Rewire',\n",
       " 'Rheinmetall Aviation Services GmbH',\n",
       " 'Rheinmetall Electronics GmbH',\n",
       " 'Rheinmetall Technology Center GmbH',\n",
       " 'Rhesis AI',\n",
       " 'Risk Research GmbH',\n",
       " 'Risk Solutions',\n",
       " 'Ritter GmbH',\n",
       " 'Riverty',\n",
       " 'Robotron Datenbank-Software GmbH',\n",
       " 'Roche',\n",
       " 'Rohde & Schwarz',\n",
       " 'RoomPriceGenie',\n",
       " 'Rosenxt Group',\n",
       " 'S-Payment GmbH - Ein Unternehmen der DSV-Gruppe',\n",
       " 'SAP',\n",
       " 'SAP Fioneer',\n",
       " 'SAP SE',\n",
       " 'SCALEUP.agency',\n",
       " 'SCHOTT AG',\n",
       " 'SCHWARM Technologies Inc.',\n",
       " 'SII Deutschland GmbH',\n",
       " 'SINTEC Informatik GmbH',\n",
       " 'SKM Group',\n",
       " 'SKOPOS',\n",
       " 'SLAY',\n",
       " 'SMA Development GmbH',\n",
       " 'SOKA-Bau',\n",
       " 'SR2 | Socially Responsible Recruitment | Certified B Corporation™',\n",
       " 'STATWORX GmbH',\n",
       " 'STI GmbH',\n",
       " 'STYLINK Social Media GmbH',\n",
       " 'SThree',\n",
       " 'SVA System Vertrieb Alexander GmbH',\n",
       " 'SWK Energie GmbH',\n",
       " 'SafeAD',\n",
       " 'SafeDriver Group',\n",
       " 'Sanofi',\n",
       " 'Scalefree',\n",
       " 'Scheer Group',\n",
       " 'Schickler Unternehmensberatung GmbH',\n",
       " 'Schluchseewerk Aktiengesellschaft',\n",
       " 'Schmitt Engineering',\n",
       " 'Seer Inc.',\n",
       " 'SellerX',\n",
       " 'Senacor Technologies AG',\n",
       " 'Sentient Foundation',\n",
       " 'Shopify',\n",
       " 'Siegwerk Druckfarben AG & Co. KGaA',\n",
       " 'Skeleton Technologies',\n",
       " 'Skill Farm',\n",
       " 'Skills Alliance',\n",
       " 'Skillspark AB',\n",
       " 'Social Match - We are hiring!',\n",
       " 'Societe Generale',\n",
       " 'SoftServe',\n",
       " 'Solera',\n",
       " 'Sono Motors',\n",
       " 'Sopra Steria',\n",
       " 'Source Group International',\n",
       " 'Sparkasse Bremen AG',\n",
       " 'Sparkassen Rating und Risikosysteme GmbH',\n",
       " 'Sphera',\n",
       " 'Staburo GmbH',\n",
       " 'Stadler Signalling Deutschland GmbH',\n",
       " 'Stadt Köln',\n",
       " 'Stadtsparkasse Gladbeck',\n",
       " 'Stadtwerke Verkehrsgesellschaft Frankfurt am Main',\n",
       " 'Starkflow',\n",
       " 'Statista',\n",
       " 'Statista GmbH',\n",
       " 'Steadforce',\n",
       " 'Stimme Mediengruppe',\n",
       " 'Storyblok',\n",
       " 'Strategion GmbH',\n",
       " 'Strativ Group',\n",
       " 'StriveNest',\n",
       " 'Studyflix',\n",
       " 'Städtisches Klinikum Karlsruhe gGmbH',\n",
       " 'Surge Group',\n",
       " 'Swiss Re',\n",
       " 'Synamic Technologies UG',\n",
       " 'Syngenta',\n",
       " 'SÜDKURIER GmbH Medienhaus',\n",
       " 'TARGOBANK',\n",
       " 'TELUS Digital',\n",
       " 'TERAKI GmbH',\n",
       " 'TERRITORY MEDIA',\n",
       " 'THRYVE',\n",
       " 'TMM AG',\n",
       " 'TOP TECHNOLOGIES CONSULTING GmbH',\n",
       " 'TRKKN',\n",
       " 'TRON',\n",
       " 'TRUSTEQ GmbH',\n",
       " 'Table.Briefings',\n",
       " 'Tacto',\n",
       " 'Targobank AG',\n",
       " 'Targomo',\n",
       " 'Tchibo',\n",
       " 'TeamViewer',\n",
       " 'TecAlliance',\n",
       " 'Tecan Software Competence Center GmbH',\n",
       " 'Tecan Trading AG',\n",
       " 'Techniker Krankenkasse',\n",
       " 'Technische Informationsbibliothek (TIB)',\n",
       " 'Technische Universität Clausthal',\n",
       " 'Technische Universität Ilmenau',\n",
       " 'Technology & Strategy',\n",
       " 'Teckentrup GmbH & Co. KG',\n",
       " 'Temu',\n",
       " 'Tenthpin',\n",
       " 'Teraki',\n",
       " 'Tesla',\n",
       " 'Tesla Automation GmbH',\n",
       " 'Tether.io',\n",
       " 'TetraScience',\n",
       " 'The Creative Club',\n",
       " 'The Product Guys',\n",
       " 'Theion GmbH',\n",
       " 'Theo Förch GmbH & Co. KG',\n",
       " 'Thermo Fisher Scientific',\n",
       " 'Thomann.io',\n",
       " 'Thyssengas',\n",
       " 'Thyssengas GmbH',\n",
       " 'TieTalent',\n",
       " 'Tinybird',\n",
       " 'Tomorrow University of Applied Sciences',\n",
       " 'Tourlane GmbH',\n",
       " 'Trakken GmbH',\n",
       " 'TransnetBW GmbH',\n",
       " 'Transparent Hiring',\n",
       " 'Trelleborg Sealing Solutions Germany GmbH',\n",
       " 'TriNetX',\n",
       " 'Triathlon Group',\n",
       " 'Tris Technology',\n",
       " 'Truemetrics',\n",
       " 'Trust In SODA',\n",
       " 'Trust Wallet',\n",
       " 'TÜV SÜD',\n",
       " 'TÜV SÜD Digital Service GmbH',\n",
       " 'UCG United Consulting Group GmbH',\n",
       " 'UKSH',\n",
       " 'UNITY Consulting & Innovation',\n",
       " 'US Commander, Naval Information Warfare Systems...',\n",
       " 'UTILIGENCE GmbH',\n",
       " 'Ucaneo',\n",
       " 'Uelzener Allgemeine Versicherungs-Gesellschaft a.G.',\n",
       " 'Union Investment',\n",
       " 'University Hospital Schleswig-Holstein (UKSH)',\n",
       " 'University of Bayreuth',\n",
       " 'University of Hamburg',\n",
       " 'Universitätsklinikum Münster',\n",
       " 'Universitätsklinikum Würzburg',\n",
       " 'Unternehmensgruppe Theo Müller GmbH & Co. KG',\n",
       " 'Upvest',\n",
       " 'VALUEZON',\n",
       " 'VARTA Micro Production GmbH',\n",
       " 'VBN GmbH',\n",
       " 'VHV Gruppe',\n",
       " 'VKB',\n",
       " 'VLS Versicherungslogistik GmbH',\n",
       " 'VOLKSWOHL BUND LEBENSVERSICHERUNG a.G.',\n",
       " 'VOLKSWOHL BUND Lebensversicherung a. G.',\n",
       " 'VP Verbund Pflegehilfe GmbH',\n",
       " 'VTG',\n",
       " 'Vaillant Group Business Services GmbH',\n",
       " 'Vaisto Solutions',\n",
       " 'ValueWorks GmbH',\n",
       " 'ValueWorks.ai',\n",
       " 'Vanguard Automation GmbH',\n",
       " 'Vay',\n",
       " 'Verve',\n",
       " 'ViGeneron GmbH',\n",
       " 'VidLab7 GmbH',\n",
       " 'Vinted',\n",
       " 'Visa',\n",
       " 'VisionAI',\n",
       " 'Vivid Money',\n",
       " 'Vollcom Digital',\n",
       " 'VÆRIDION',\n",
       " 'WDR',\n",
       " 'WEBER GmbH',\n",
       " 'WIBU Gruppe',\n",
       " 'WM Gruppe',\n",
       " 'Wacker Chemie AG',\n",
       " 'Wargaming',\n",
       " 'Wave Mobile Money',\n",
       " 'WeSort.AI GmbH',\n",
       " 'WeSort.Ai GmbH',\n",
       " 'Wego Systembaustoffe GmbH',\n",
       " 'Wemolo',\n",
       " 'Wentronic',\n",
       " 'Wentronic GmbH',\n",
       " 'Wirtschaftsrat der CDU e.V.',\n",
       " 'With love and data GmbH',\n",
       " 'Wolt',\n",
       " 'Wooga',\n",
       " 'Workaround GmbH',\n",
       " 'World Food Programme',\n",
       " 'Württembergische Versicherung Aktiengesellschaft',\n",
       " 'XIBIX Solutions GmbH',\n",
       " 'XPENG',\n",
       " 'Xplain Data GmbH',\n",
       " 'Xsolla',\n",
       " 'YO IT CONSULTING',\n",
       " 'Yeah! Global',\n",
       " 'Yukawa Exponential GmbH',\n",
       " 'ZABEL',\n",
       " 'ZAUBAR',\n",
       " 'ZEAL Network SE',\n",
       " 'ZEISS',\n",
       " 'ZEISS Group',\n",
       " 'ZEIT Verlagsgruppe',\n",
       " 'ZENJOB',\n",
       " 'Zalando',\n",
       " 'Zander Labs',\n",
       " 'Zattoo',\n",
       " 'Zendr',\n",
       " 'Zero to One Search | Recruitment Agency',\n",
       " 'Zertificon',\n",
       " 'Zertificon Solutions GmbH',\n",
       " 'Zurich Insurance',\n",
       " 'abat North America',\n",
       " 'accantec group',\n",
       " 'adesso SE',\n",
       " 'ainovi GmbH',\n",
       " 'apploft. GmbH',\n",
       " 'areto consulting gmbh',\n",
       " 'atmio',\n",
       " 'audibene',\n",
       " 'audibene GmbH',\n",
       " 'auxmoney GmbH',\n",
       " 'bcmed GmbH',\n",
       " 'bravobike GmbH',\n",
       " 'camPoint AG',\n",
       " 'cavalis',\n",
       " 'coac GmbH',\n",
       " 'companion Strategieberatung GmbH',\n",
       " 'constellr GmbH',\n",
       " 'cosnova',\n",
       " 'creditshelf Aktiengesellschaft',\n",
       " 'credium',\n",
       " 'curexus GmbH',\n",
       " 'datasolut GmbH',\n",
       " 'deltra Business Software GmbH & Co. KG',\n",
       " 'developrec',\n",
       " 'dexter health',\n",
       " 'dida',\n",
       " 'dltHub',\n",
       " 'e2n',\n",
       " 'eWolff GmbH',\n",
       " 'elunic AG',\n",
       " 'enercity AG',\n",
       " 'engAIge GmbH',\n",
       " 'eoda GmbH',\n",
       " 'evidanza AG',\n",
       " 'eyeo',\n",
       " 'fair parken GmbH',\n",
       " 'flaschenpost SE',\n",
       " 'freenet DLS GmbH',\n",
       " 'g2 Recruitment',\n",
       " 'greenventory',\n",
       " 'grey engineering GmbH',\n",
       " 'handz.on GmbH',\n",
       " 'hansetherm',\n",
       " 'home24 SE',\n",
       " 'initions GmbH',\n",
       " 'innnow',\n",
       " 'inovex GmbH',\n",
       " 'item Industrietechnik GmbH',\n",
       " 'iwoca',\n",
       " 'join.com',\n",
       " 'kapa.ai',\n",
       " 'karriere tutor GmbH',\n",
       " 'kiresult',\n",
       " 'konversionsKRAFT',\n",
       " 'mbiomics GmbH',\n",
       " 'meinestadt.de',\n",
       " 'msg systems ag',\n",
       " 'mymuesli AG',\n",
       " 'natif.ai',\n",
       " 'nebumind GmbH',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore unique company names\n",
    "np.sort(df[\"company\"].unique()).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to consolidate company names, the column will undergo several steps of cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>company_clean_ish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Enzo Tech Group</td>\n",
       "      <td>Enzo Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>MAM Gruppe</td>\n",
       "      <td>MAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>IOTIS GmbH</td>\n",
       "      <td>IOTIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>elunic AG</td>\n",
       "      <td>elunic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Source Group International</td>\n",
       "      <td>Source International</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       company     company_clean_ish\n",
       "30             Enzo Tech Group             Enzo Tech\n",
       "34                  MAM Gruppe                   MAM\n",
       "46                  IOTIS GmbH                 IOTIS\n",
       "47                   elunic AG                elunic\n",
       "48  Source Group International  Source International"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, remove common legal terms describing the type of company\n",
    "df[\"company_clean_ish\"] = df[\"company\"]\n",
    "\n",
    "replace_strings = [\n",
    "    \"GmbH\",\n",
    "    \"GMBH\",\n",
    "    \"AG\",\n",
    "    \"a.G.\",\n",
    "    \"a. G.\",\n",
    "    \"KGaA\",\n",
    "    \"Co KG\",\n",
    "    \"Co. KG\",\n",
    "    \"CO. KG\",\n",
    "    \"Co Mack KG\",\n",
    "    \"Deutschland\",\n",
    "    \"Gruppe\",\n",
    "    \"Group\",\n",
    "    \"Holding\",\n",
    "    \"B.V.\",\n",
    "    \"SE\",\n",
    "    \"DACH\"\n",
    "]\n",
    "\n",
    "for s in replace_strings:\n",
    "    string = f\" {s}\" # add blank in order to not replace e.g. AG in the middle of a sentence.\n",
    "    df[\"company_clean_ish\"] = df[\"company_clean_ish\"].str.replace(string, \"\")\n",
    "\n",
    "df.loc[df[\"company\"] != df[\"company_clean_ish\"], [\"company\", \"company_clean_ish\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>company_clean_ish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global Market Solutions - Germany</td>\n",
       "      <td>Global Market Solutions   Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vent.io</td>\n",
       "      <td>vent io</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HUK-COBURG</td>\n",
       "      <td>HUK COBURG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CONNECTMETA.AI</td>\n",
       "      <td>CONNECTMETA AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SR2 | Socially Responsible Recruitment | Certi...</td>\n",
       "      <td>SR2   Socially Responsible Recruitment   Certi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              company   \n",
       "2                   Global Market Solutions - Germany  \\\n",
       "4                                             vent.io   \n",
       "7                                          HUK-COBURG   \n",
       "13                                     CONNECTMETA.AI   \n",
       "18  SR2 | Socially Responsible Recruitment | Certi...   \n",
       "\n",
       "                                    company_clean_ish  \n",
       "2                   Global Market Solutions   Germany  \n",
       "4                                             vent io  \n",
       "7                                          HUK COBURG  \n",
       "13                                     CONNECTMETA AI  \n",
       "18  SR2   Socially Responsible Recruitment   Certi...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all non-word charachters; keep blanks\n",
    "df[\"company_clean_ish\"] = df[\"company_clean_ish\"].str.replace(\"[^a-zA-Z0-9\\s]\", \" \", regex=True)\n",
    "\n",
    "# show datapoints that have changed:\n",
    "df.loc[df[\"company\"] != df[\"company_clean_ish\"], [\"company\", \"company_clean_ish\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove leading/trailing blanks\n",
    "df[\"company_clean_ish\"] = df[\"company_clean_ish\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform company names to upper \n",
    "df[\"company_clean_ish\"] = df[\"company_clean_ish\"].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 1 MAIL   MEDIA APPLICATIONS',\n",
       " '1KOMMA5',\n",
       " '1KOMMA6   MULTIMEDIALE DIENSTLEISTUNGEN',\n",
       " '1X2 TECHNOLOGIES',\n",
       " '4 SCREEN',\n",
       " '4SCREEN',\n",
       " 'ABAT NORTH AMERICA',\n",
       " 'ABB',\n",
       " 'ABBVIE',\n",
       " 'ABOUT YOU',\n",
       " 'ACCANTEC GROUP',\n",
       " 'ACCENTURE',\n",
       " 'ACCURE BATTERY INTELLIGENCE',\n",
       " 'ACONEXT',\n",
       " 'ACONEXT STUTTGART',\n",
       " 'ADAC',\n",
       " 'ADAC ALLGEMEINER DEUTSCHER AUTOMOBIL CLUB',\n",
       " 'ADEAL SYSTEMS',\n",
       " 'ADESSO',\n",
       " 'ADG APOTHEKEN DIENSTLEISTUNGSGESELLSCHAFT MBH',\n",
       " 'ADM',\n",
       " 'AERZENER MASCHINENFABRIK',\n",
       " 'AI ASSOCIATES',\n",
       " 'AI FUTURES',\n",
       " 'AIGNOSTICS',\n",
       " 'AILIO',\n",
       " 'AINOVI',\n",
       " 'AITAD',\n",
       " 'AKKODIS',\n",
       " 'AKLASS SOLUTIONS',\n",
       " 'AL SOLUTIONS',\n",
       " 'ALACRIS THERANOSTICS',\n",
       " 'ALBATROSS AI',\n",
       " 'ALCEDIS   A HUMA COMPANY',\n",
       " 'ALDI EINKAUF   CO  OHG',\n",
       " 'ALDI S D',\n",
       " 'ALEXANDER THAMM',\n",
       " 'ALFRED WEGENER INSTITUT F R POLAR  UND',\n",
       " 'ALGEA CARE',\n",
       " 'ALITHEA BIO',\n",
       " 'ALIXPARTNERS',\n",
       " 'ALLGEIER PUBLIC',\n",
       " 'ALLIANZ',\n",
       " 'ALLIANZ DIGITAL HEALTH',\n",
       " 'ALLIANZ VERSICHERUNGS AG',\n",
       " 'ALLOS HOF MANUFAKTUR',\n",
       " 'ALMEDIA',\n",
       " 'ALTEN CONSULTING SERVICES',\n",
       " 'ALTEN GERMANY',\n",
       " 'AMAI',\n",
       " 'AMAZON',\n",
       " 'AMAZON DEVELOPMENT CENTER GERMANY',\n",
       " 'AMAZON DEVELOPMENT CENTER GERMANY   C92',\n",
       " 'AMAZON EUROPE CORE',\n",
       " 'AMAZON WEB SERVICES  AWS',\n",
       " 'AMAZON WEB SERVICES DEVELOPMENT CENTER GERMANY',\n",
       " 'AMD',\n",
       " 'AMFILEON',\n",
       " 'AMMERL NDER VERSICHERUNG VVAG',\n",
       " 'AMPRION',\n",
       " 'AMUNDI',\n",
       " 'ANALYTIK JENA CO  KG',\n",
       " 'AOK BAYERN   DIE GESUNDHEITSKASSE',\n",
       " 'APPINIO',\n",
       " 'APPLIKE',\n",
       " 'APPLOFT',\n",
       " 'APTIV',\n",
       " 'ARETE',\n",
       " 'ARETO CONSULTING GMBH',\n",
       " 'ARIADNE',\n",
       " 'ARTIVION EMEA',\n",
       " 'ARVATO',\n",
       " 'ARVATO SYSTEMS',\n",
       " 'ARVATO SYSTEMS DIGITAL',\n",
       " 'ASCENDIS PHARMA',\n",
       " 'ASKLEPIOS SERVICE IT',\n",
       " 'ATH ALTONAER TECHNOLOGIE HOLDING',\n",
       " 'ATLAS ELEKTRONIK',\n",
       " 'ATLAS MARIDAN APS',\n",
       " 'ATMIO',\n",
       " 'ATOSS SOFTWARE',\n",
       " 'ATRUVIA',\n",
       " 'AUDACITY CAPITAL MANAGEMENT',\n",
       " 'AUDIBENE',\n",
       " 'AUDIBLE',\n",
       " 'AUSBILDUNG DE',\n",
       " 'AUTO1',\n",
       " 'AUTONOMOUS TEAMING SOLUTIONS',\n",
       " 'AUXMONEY',\n",
       " 'AVAT AUTOMATION',\n",
       " 'AVO INTELLIGENCE',\n",
       " 'AWS EMEA SARL  GERMANY BRANCH',\n",
       " 'AXEL SPRINGER',\n",
       " 'AXEL SPRINGER NATIONAL MEDIA   TECH',\n",
       " 'AXULUS',\n",
       " 'BABBEL',\n",
       " 'BAKER TILLY',\n",
       " 'BARBARICUM',\n",
       " 'BARMER',\n",
       " 'BASF',\n",
       " 'BAUER',\n",
       " 'BAUMLINK',\n",
       " 'BAYER',\n",
       " 'BAYERISCHES LANDESAMT F R GESUNDHEIT UND LEBENSMITTELSICHERHEIT',\n",
       " 'BAYERISCHES LANDESAMT F R STATISTIK',\n",
       " 'BAYWA R E  SOLAR TRADE',\n",
       " 'BCG X',\n",
       " 'BCMED',\n",
       " 'BEAM AI',\n",
       " 'BEARINGPOINT',\n",
       " 'BECHTLE BREMEN',\n",
       " 'BECHTLE IT SYSTEMHAUS BREMEN',\n",
       " 'BEHREND E K',\n",
       " 'BEIERSDORF',\n",
       " 'BEIERSDORF SHARED SERVICES',\n",
       " 'BERGFREUNDE',\n",
       " 'BERLINER WASSERBETRIEBE',\n",
       " 'BERTRANDT',\n",
       " 'BI PHARMA CO KG',\n",
       " 'BI VETMEDICA',\n",
       " 'BID BAYERISCHER INKASSO DIENST',\n",
       " 'BIKAR METALLE',\n",
       " 'BINANCE',\n",
       " 'BIOMARKER SERVICES',\n",
       " 'BIONTECH',\n",
       " 'BIOTRONIK CORPORATE SERVICES',\n",
       " 'BIOTYPE',\n",
       " 'BITA',\n",
       " 'BLACKLANE',\n",
       " 'BLUEOAK ADVERTISING',\n",
       " 'BLUEPRINT EXECUTIVE SEARCH',\n",
       " 'BLUETHRONE',\n",
       " 'BMW',\n",
       " 'BN AUTOMATION',\n",
       " 'BNP PARIBAS PERSONAL INVESTORS',\n",
       " 'BOEHRINGER INGELHEIM',\n",
       " 'BOLT',\n",
       " 'BOOZ ALLEN',\n",
       " 'BOOZ ALLEN HAMILTON',\n",
       " 'BOSCH',\n",
       " 'BOSTON CONSULTING',\n",
       " 'BRANCH TECH',\n",
       " 'BRAVOBIKE',\n",
       " 'BREUNINGER',\n",
       " 'BRIDGINGIT',\n",
       " 'BRIGHT TESTING',\n",
       " 'BRING  LABS',\n",
       " 'BRUNEL',\n",
       " 'BRUSS SEALING SYSTEMS',\n",
       " 'BUDNI HANDELS  UND SERVICE',\n",
       " 'BUNDESAGENTUR F R ARBEIT',\n",
       " 'BWF',\n",
       " 'BWORKS HR PROFESSIONAL',\n",
       " 'BYK ADDITIVES',\n",
       " 'BYK CHEMIE',\n",
       " 'C  MELCHERS',\n",
       " 'CAMBRIUM',\n",
       " 'CAMPOINT',\n",
       " 'CANCOM',\n",
       " 'CAPGEMINI',\n",
       " 'CAPGEMINI INVENT',\n",
       " 'CARHARTT WIP  WORK IN PROGRESS',\n",
       " 'CARL ZEISS IQS SOFTWARE R D CENTER',\n",
       " 'CARONSALE',\n",
       " 'CAVALIS',\n",
       " 'CBM CHRISTOFFEL BLINDENMISSION CHRISTIAN BLIND MISSION E V',\n",
       " 'CBTW',\n",
       " 'CDP',\n",
       " 'CEEZER',\n",
       " 'CELONIS',\n",
       " 'CENTRIC SOFTWARE',\n",
       " 'CERTIVITY',\n",
       " 'CGI',\n",
       " 'CHAOZHOU THREE CIRCLE CO   LTD',\n",
       " 'CHECK24',\n",
       " 'CHECK24 VERGLEICHSPORTAL',\n",
       " 'CHEFS CULINAR',\n",
       " 'CHERRY VENTURES',\n",
       " 'CHERRY VENTURES MANAGEMENT',\n",
       " 'CHOCO',\n",
       " 'CHOCO COMMUNICATIONS',\n",
       " 'CHRIST COMPANY CONSULTING',\n",
       " 'CIDEON SOFTWARE   SERVICES',\n",
       " 'CIKLO TALENT',\n",
       " 'CIMT AG',\n",
       " 'CINEMO',\n",
       " 'CINT',\n",
       " 'CLAAS MBH',\n",
       " 'CLARINESS',\n",
       " 'CLIMATIQ',\n",
       " 'CLOOVER',\n",
       " 'COAC',\n",
       " 'COBRAINER',\n",
       " 'COFINITY X',\n",
       " 'COFINPRO',\n",
       " 'COGNITIVO',\n",
       " 'COLLABORATION BETTERS THE WORLD',\n",
       " 'COLTECH',\n",
       " 'COMMA SOFT',\n",
       " 'COMPANION STRATEGIEBERATUNG',\n",
       " 'COMPARUS',\n",
       " 'COMPUGROUP MEDICAL',\n",
       " 'COMPUGROUP MEDICAL   CO',\n",
       " 'COMPUSAFE DATA SYSTEMS',\n",
       " 'COMPUTER FUTURES',\n",
       " 'COMPUTOMICS',\n",
       " 'CONET',\n",
       " 'CONNECTMETA AI',\n",
       " 'CONSTELLR',\n",
       " 'CONTROL EXPERT',\n",
       " 'CONVIT',\n",
       " 'CONVOLUT',\n",
       " 'CORECRUITMENT LTD',\n",
       " 'CORIOLIS PHARMA RESEARCH',\n",
       " 'COSNOVA',\n",
       " 'COSUNO',\n",
       " 'COZERO',\n",
       " 'CRAYON',\n",
       " 'CREALYTICS',\n",
       " 'CREDITPLUS BANK',\n",
       " 'CREDITSHELF AKTIENGESELLSCHAFT',\n",
       " 'CREDIUM',\n",
       " 'CRELUX',\n",
       " 'CROWDSTRIKE',\n",
       " 'CSL BEHRING',\n",
       " 'CUJU',\n",
       " 'CUREVAC',\n",
       " 'CUREXUS',\n",
       " 'CYBER VALLEY',\n",
       " 'CYTIVA',\n",
       " 'DADAJ',\n",
       " 'DAHAG RECHTSSERVICES',\n",
       " 'DAIICHI SANKYO EUROPE',\n",
       " 'DAMEDIC',\n",
       " 'DATA TALENT',\n",
       " 'DATACAMP',\n",
       " 'DATACRAFT',\n",
       " 'DATAMICS',\n",
       " 'DATAMONKEY',\n",
       " 'DATASEC INFORMATION FACTORY',\n",
       " 'DATASOLUT',\n",
       " 'DATEV EG',\n",
       " 'DEEPREC AI',\n",
       " 'DEICHMANN',\n",
       " 'DELIVERY HERO',\n",
       " 'DELOITTE',\n",
       " 'DELTIA',\n",
       " 'DELTRA BUSINESS SOFTWARE',\n",
       " 'DENNEMEYER',\n",
       " 'DEUTSCHE APOTHEKER  UND  RZTEBANK EG   APOBANK',\n",
       " 'DEUTSCHE BANK',\n",
       " 'DEUTSCHE BUNDESBANK',\n",
       " 'DEUTSCHE KREDITBANK  DKB',\n",
       " 'DEUTSCHE RENTENVERSICHERUNG BUND',\n",
       " 'DEUTSCHES ELEKTRONEN SYNCHROTRON DESY',\n",
       " 'DEUTSCHES KREBSFORSCHUNGSZENTRUM',\n",
       " 'DEVELOPREC',\n",
       " 'DEVNET',\n",
       " 'DEVOTEAM I GOOGLE CLOUD PARTNER',\n",
       " 'DEXTER HEALTH',\n",
       " 'DFB',\n",
       " 'DHL CONSULTING',\n",
       " 'DIDA',\n",
       " 'DIGITAL CHARGING SOLUTIONS',\n",
       " 'DIGITALTREIBER UG',\n",
       " 'DIGITALTWIN TECHNOLOGY',\n",
       " 'DIGITECH SEARCH',\n",
       " 'DIGITL',\n",
       " 'DIMOS OPERATIONS',\n",
       " 'DIN SOLUTIONS',\n",
       " 'DISCOVER INTERNATIONAL',\n",
       " 'DLTHUB',\n",
       " 'DOCTOLIB',\n",
       " 'DOHLE HANDELSGRUPPE',\n",
       " 'DOUGLAS',\n",
       " 'DR  JOHANNES HEIDENHAIN',\n",
       " 'DR  KURT WOLFF',\n",
       " 'DR  WOLFF',\n",
       " 'DR GER',\n",
       " 'DR GERWERK   CO',\n",
       " 'DREES   SOMMER',\n",
       " 'DYMATRIX',\n",
       " 'DZ BANK',\n",
       " 'E ON DIGITAL TECHNOLOGY',\n",
       " 'E2N',\n",
       " 'EBENBUILD',\n",
       " 'ECE',\n",
       " 'ECMWF',\n",
       " 'EGGERSMANN',\n",
       " 'EGYM',\n",
       " 'EHRENM LLER',\n",
       " 'EIDU',\n",
       " 'ELEVENLABS',\n",
       " 'ELUNIC',\n",
       " 'EMBASSY OF THE UNITED STATES OF AMERICA',\n",
       " 'EMMA   THE SLEEP COMPANY',\n",
       " 'EMPION',\n",
       " 'ENBW ENERGIE BADEN W RTTEMBERG',\n",
       " 'ENCAVIS',\n",
       " 'ENERCITY',\n",
       " 'ENERGYEFFIZIENZ',\n",
       " 'ENGAIGE',\n",
       " 'ENJINS',\n",
       " 'ENPAL',\n",
       " 'ENPAL DRAGON',\n",
       " 'ENTRIX',\n",
       " 'ENZO',\n",
       " 'ENZO TECH',\n",
       " 'EODA',\n",
       " 'EPM SCIENTIFIC',\n",
       " 'ERC SYSTEM',\n",
       " 'ERDMANN SOFTWAREGESELLSCHAFT MBH',\n",
       " 'ERGO',\n",
       " 'ERGOTOPIA',\n",
       " 'ERNSTING S FAMILY',\n",
       " 'ES TEC',\n",
       " 'ESL FACEIT   EFG',\n",
       " 'ESQLABS',\n",
       " 'ETRIBES',\n",
       " 'EUROPA PARK',\n",
       " 'EUROPA PARK ERLEBNIS RESORT',\n",
       " 'EUROPEAN CENTRE FOR MEDIUM RANGE WEATHER FORECASTS',\n",
       " 'EUROPEAN TECH RECRUIT',\n",
       " 'EUROPEAN X RAY FREE ELECTRON LASER FACILITY',\n",
       " 'EVERSION TECHNOLOGIES',\n",
       " 'EVIDANZA',\n",
       " 'EVONIK',\n",
       " 'EWE TEL',\n",
       " 'EWOLFF',\n",
       " 'EXACT SCIENCES CORPORATION',\n",
       " 'EXOMATTER',\n",
       " 'EXPATRIO',\n",
       " 'EXPLEO',\n",
       " 'EY',\n",
       " 'EYEO',\n",
       " 'FAIR PARKEN',\n",
       " 'FERCHAU',\n",
       " 'FEW FAR',\n",
       " 'FIBER EXPERTS',\n",
       " 'FINANZ DATA',\n",
       " 'FINANZAMT KASSEL',\n",
       " 'FINANZGURU',\n",
       " 'FINCON REPLY',\n",
       " 'FINN',\n",
       " 'FIT ANALYTICS',\n",
       " 'FLASCHENPOST',\n",
       " 'FLEXA',\n",
       " 'FLINK',\n",
       " 'FLIP',\n",
       " 'FLOORTEX EUROPE LTD',\n",
       " 'FLUGHAFEN HANNOVER LANGENHAGEN',\n",
       " 'FLYERALARM BIT LABS',\n",
       " 'FOM UNIVERSITY OF APPLIED SCIENCES FOR ECONOMICS AND MANAGEMENT',\n",
       " 'FORRS PARTNERS',\n",
       " 'FORSCHUNGSZENTRUM J LICH',\n",
       " 'FORVIS MAZARS',\n",
       " 'FORWARD EARTH',\n",
       " 'FOXBASE',\n",
       " 'FRANZ   WACH PERSONALSERVICE',\n",
       " 'FRAUNHOFER FIT',\n",
       " 'FRAUNHOFER INSTITUTE FOR MICROELECTRONIC CIRCUITS AND SYSTEMS',\n",
       " 'FREENET DLS',\n",
       " 'FREIE UNIVERSIT T BERLIN',\n",
       " 'FRIEDRICH SCHILLER UNIVERSIT T JENA',\n",
       " 'FUSION CONSULTING',\n",
       " 'FUTURAE TECHNOLOGIES',\n",
       " 'FUTURISED',\n",
       " 'G2 RECRUITMENT',\n",
       " 'GAF',\n",
       " 'GARANT',\n",
       " 'GASCADE GASTRANSPORT',\n",
       " 'GEBR  HEINEMANN',\n",
       " 'GEM',\n",
       " 'GEMA   GESELLSCHAFT F R MUSIK  AUFF HRUNGS  UND MECHAN  VERVIELF LTIGUNGSRECHTE',\n",
       " 'GEN RE',\n",
       " 'GENERALI',\n",
       " 'GENERALI DEUTSCHLAND',\n",
       " 'GERMAN AEROSPACE CENTER  DLR',\n",
       " 'GESELLSCHAFT F R MUSIKALISCHE AUFF HRUNGS  UND',\n",
       " 'GETML RESEARCH',\n",
       " 'GETRIEBEBAU NORD',\n",
       " 'GETYOURGUIDE',\n",
       " 'GHARAGE',\n",
       " 'GIE EREI INSTITUT DER RWTH AACHEN',\n",
       " 'GIGS',\n",
       " 'GIM GESELLSCHAFT F R INNOVATIVE MARKTFORSCHUNG MBH',\n",
       " 'GLASSDOLLAR',\n",
       " 'GLOBAL ENERGY INTERCONNECTION RESEARCH INSTITUTE EUROPE',\n",
       " 'GLOBAL MARKET SOLUTIONS   GERMANY',\n",
       " 'GLOBAL UNIVERSITY SYSTEMS',\n",
       " 'GNOSIS',\n",
       " 'GOLDNER',\n",
       " 'GOOGLE',\n",
       " 'GR NENTHAL',\n",
       " 'GREEN ENERGY ORIGIN  GEO',\n",
       " 'GREEN FUSION',\n",
       " 'GREEN VALUE MANAGEMENT LTD',\n",
       " 'GREENBOOTCAMPS',\n",
       " 'GREENPOCKET',\n",
       " 'GREENVENTORY',\n",
       " 'GREY ENGINEERING',\n",
       " 'GRIMME LANDMASCHINENFABRIK',\n",
       " 'GRO  BUSINESS',\n",
       " 'GROHE',\n",
       " 'GSI HELMHOLTZZENTRUM F R SCHWERIONENFORSCHUNG',\n",
       " 'GSK',\n",
       " 'GWQ SERVICEPLUS',\n",
       " 'H NDLERBUND',\n",
       " 'HAGIUS',\n",
       " 'HAMBURG UNIVERSITY OF TECHNOLOGY',\n",
       " 'HAMLYN WILLIAMS',\n",
       " 'HANDELSBLATT',\n",
       " 'HANDZ ON',\n",
       " 'HANNOVER R CK',\n",
       " 'HANNOVER RE',\n",
       " 'HANSEMERKUR',\n",
       " 'HANSETHERM',\n",
       " 'HAPEKO',\n",
       " 'HARVEY NASH',\n",
       " 'HASHLIST',\n",
       " 'HAUFE',\n",
       " 'HAUSGOLD   TALOCASA',\n",
       " 'HAVAS',\n",
       " 'HAWK',\n",
       " 'HAYS   WORKING FOR YOUR TOMORROW',\n",
       " 'HDI',\n",
       " 'HEIDELBERG MATERIALS',\n",
       " 'HEIDELBERG UNIVERSITY',\n",
       " 'HELLOWORK CONSULTANTS',\n",
       " 'HELMHOLTZ ZENTRUM M NCHEN',\n",
       " 'HELPLING',\n",
       " 'HENKEL',\n",
       " 'HETZNER',\n",
       " 'HIGHBERG MEDIAMINDS',\n",
       " 'HIGHLANDER SOLUTIONS',\n",
       " 'HIT HANDELSGRUPPE',\n",
       " 'HMS ANALYTICAL SOFTWARE',\n",
       " 'HMS ANALYTICAL SOFTWARE   CONSULTING   END TO END SOLUTIONS FOR DATA SCIENCE   ANALYTICS',\n",
       " 'HOCHSCHULE KAISERSLAUTERN',\n",
       " 'HOME24',\n",
       " 'HOPMANN   MARKETING ANALYTICS INH  J RG HOPMANN',\n",
       " 'HOPMANN MARKETING ANALYTICS',\n",
       " 'HORV TH',\n",
       " 'HOTTGENROTH',\n",
       " 'HP',\n",
       " 'HR UNIVERSAL',\n",
       " 'HUK COBURG',\n",
       " 'HUK COBURG VERSICHERUNGSGRUPPE',\n",
       " 'HYUNDAI MOTOR',\n",
       " 'IABG',\n",
       " 'IBA',\n",
       " 'IBA DOSIMETRY',\n",
       " 'ICIS TSCHACH SOLUTION',\n",
       " 'IFTA',\n",
       " 'IK PARTNERS',\n",
       " 'ILSENBURGER GROBBLECH',\n",
       " 'IMPALA SEARCH',\n",
       " 'INCARI DEVELOPMENT PLATFORM',\n",
       " 'INDIVUMED',\n",
       " 'INFINEON TECHNOLOGIES',\n",
       " 'INFRASERV H CHST',\n",
       " 'ING',\n",
       " 'INITIONS',\n",
       " 'INNNOW',\n",
       " 'INNOMOTICS',\n",
       " 'INOVEX',\n",
       " 'INSTAFFO',\n",
       " 'INSTAPRO',\n",
       " 'INSTITUT F R MEDIZINISCHE INFORMATIK',\n",
       " 'INTAPP',\n",
       " 'INTEGRITYNEXT',\n",
       " 'INTEREX',\n",
       " 'INTERHYP',\n",
       " 'INTERJOB',\n",
       " 'INTERWORKS',\n",
       " 'INVIA TRAVEL GERMANY',\n",
       " 'IOTIS',\n",
       " 'IPPEN DIGITAL',\n",
       " 'IPPEN MEDIA',\n",
       " 'IPSOS',\n",
       " 'IRON EAGLEX  INC',\n",
       " 'ISS SOFTWARE',\n",
       " 'IT INTERNATIONAL MOBILITY',\n",
       " 'IT P INFORMATION TECHNOLOGY PARTNER',\n",
       " 'IT SERVICE',\n",
       " 'IT4IPM',\n",
       " 'ITEM INDUSTRIETECHNIK',\n",
       " 'IUNA AI',\n",
       " 'IWOCA',\n",
       " 'J  RETTENMAIER   S HNE',\n",
       " 'JAAI   JUST ADD AI',\n",
       " 'JET SERVICES MARKETING',\n",
       " 'JINA AI',\n",
       " 'JOHNSON   JOHNSON',\n",
       " 'JOIN COM',\n",
       " 'JSS ASSOCIATES',\n",
       " 'JUST ADD AI',\n",
       " 'JUST EAT TAKEAWAY COM',\n",
       " 'K RCHER',\n",
       " 'KAPA AI',\n",
       " 'KARRIERE TUTOR',\n",
       " 'KASSENZAHN RZTLICHE VEREINIGUNG HESSEN   K RPERSCHAFT DES  FFENTLICHEN RECHTS',\n",
       " 'KAYZEN',\n",
       " 'KEY WORK CONSULTING',\n",
       " 'KI PERFORMANCE',\n",
       " 'KIENBAUM CONSULTANTS INTERNATIONAL   ZENTRALE',\n",
       " 'KIRESULT',\n",
       " 'KLA',\n",
       " 'KLANG GAMES',\n",
       " 'KLIM',\n",
       " 'KLINIK F R ALLGEMEIN   VISZERAL  UND',\n",
       " 'KNUDDELS',\n",
       " 'KONFUZIO',\n",
       " 'KONVERSIONSKRAFT',\n",
       " 'KORRO AI',\n",
       " 'KOSATEC COMPUTER',\n",
       " 'KPMG WIRTSCHAFTSPR FUNGSGESELLSCHAFT',\n",
       " 'KREATIVSTORM',\n",
       " 'KWS',\n",
       " 'L WENSTEIN MEDICAL',\n",
       " 'LABOREMUS',\n",
       " 'LADGOV CORPORATION',\n",
       " 'LANCH',\n",
       " 'LANDESHAUPTSTADT STUTTGART',\n",
       " 'LANDESKRANKENHILFE V V A G',\n",
       " 'LANDKREIS BODENSEEKREIS',\n",
       " 'LANG SERVICE',\n",
       " 'LEHMANN   PIONEERS DIGITAL',\n",
       " 'LEIBNIZ INSTITUT F R ANALYTISCHE WISSENSCHAFTEN',\n",
       " 'LEIBNIZ INSTITUT F R ANALYTISCHE WISSENSCHAFTEN  ISAS   E V',\n",
       " 'LEIBNIZ INSTITUT F R ASTROPHYSIK',\n",
       " 'LEIBNIZ INSTITUT F R ASTROPHYSIK POTSDAM',\n",
       " 'LEIBNIZ INSTITUT F R NATURSTOFF  FORSCHUNG U  INFEKTIONSBIOLOGIE E V',\n",
       " 'LEIBNIZ INSTITUT F R NATURSTOFF FORSCHUNG UND',\n",
       " 'LEIBNIZ INSTITUTE OF ATMOSPHERIC PHYSICS',\n",
       " 'LEIPFINGER BADER',\n",
       " 'LEIPZIG UNIVERSITY',\n",
       " 'LEXISNEXIS',\n",
       " 'LEXWARE',\n",
       " 'LGC AXOLABS',\n",
       " 'LIBRA',\n",
       " 'LIEBHERR',\n",
       " 'LIEBHERR HAUSGER TE OCHSENHAUSEN',\n",
       " 'LIEFERANDO',\n",
       " 'LIFE SCIENCE NORD',\n",
       " 'LILT',\n",
       " 'LINDNER',\n",
       " 'LIPOTYPE',\n",
       " 'LLOYDS BANK',\n",
       " 'LOGIC HIRE SOLUTIONS LTD',\n",
       " 'LONZA',\n",
       " 'LOTUM',\n",
       " 'LOTUM MEDIA',\n",
       " 'LUFTHANSA TECHNIK',\n",
       " 'LUMINARY',\n",
       " 'LUMINO',\n",
       " 'LUNIT',\n",
       " 'LUNIT CANCER SCREENING',\n",
       " 'M M SOFTWARE',\n",
       " 'M NCHEN',\n",
       " 'MACHINE LEARNING REPLY',\n",
       " 'MAINGAU ENERGIE',\n",
       " 'MAINWEBSOLUTIONS',\n",
       " 'MAKERSITE',\n",
       " 'MAM',\n",
       " 'MAN TRUCK   BUS',\n",
       " 'MARC O POLO',\n",
       " 'MARKANT',\n",
       " 'MARKT PILOT',\n",
       " 'MASENT',\n",
       " 'MASTERSCHOOL',\n",
       " 'MATERNA INFORMATION   COMMUNICATIONS',\n",
       " 'MAX PLANCK COMPUTING AND DATA FACILITY  MPCDF',\n",
       " 'MAX PLANCK DIGITAL LIBRARY',\n",
       " 'MAX PLANCK INSTITUT F R BIOLOGIE T BINGEN',\n",
       " 'MAX PLANCK INSTITUT F R KOLLOID  UND',\n",
       " 'MAX PLANCK INSTITUT F R METEOROLOGIE',\n",
       " 'MAX PLANCK INSTITUTE FOR CHEMICAL ENERGY CONVERSION',\n",
       " 'MBIOMICS',\n",
       " 'MECHANICS OF MATERIALS',\n",
       " 'MED EL MEDICAL ELECTRONICS',\n",
       " 'MEDIAPLUS',\n",
       " 'MEDIFOX DAN',\n",
       " 'MEDISYNC AI',\n",
       " 'MEDPACE',\n",
       " 'MEDSCAPE',\n",
       " 'MEINESTADT DE',\n",
       " 'MELCHERS',\n",
       " 'MELOTECH',\n",
       " 'MENDEL VERLAG   CO KG',\n",
       " 'MERANTIX CAPITAL',\n",
       " 'MERCEDES BENZ',\n",
       " 'MERCEDES BENZ TECH INNOVATION',\n",
       " 'MERCK',\n",
       " 'MERCK HEALTHCARE',\n",
       " 'MERZ THERAPEUTICS',\n",
       " 'META',\n",
       " 'MEYERTHOLE SIEMS KOHLRUSS GESELLSCHAFT F R',\n",
       " 'MHP   A PORSCHE COMPANY',\n",
       " 'MICE PORTAL',\n",
       " 'MICHAEL BAUER RESEARCH',\n",
       " 'MIDEA',\n",
       " 'MILLDENT',\n",
       " 'MILTENYI BIOTEC',\n",
       " 'MINDFUEL',\n",
       " 'MINDPEAK',\n",
       " 'ML6   YOUR PARTNER IN AI',\n",
       " 'MLL M NCHNER LEUK MIELABOR',\n",
       " 'MOBILAB SOLUTIONS',\n",
       " 'MONDEL Z INTERNATIONAL',\n",
       " 'MORPHEUS TALENT SOLUTIONS',\n",
       " 'MPA PHARMA',\n",
       " 'MPB',\n",
       " 'MSG SYSTEMS AG',\n",
       " 'MTU AERO ENGINES',\n",
       " 'MUNICH RE',\n",
       " 'MVGM',\n",
       " 'MVGM INTERNATIONAL',\n",
       " 'MVV TRADING',\n",
       " 'MVZ D SSELDORF CENTRUM GBR',\n",
       " 'MVZ MARTINSRIED',\n",
       " 'MYMUESLI',\n",
       " 'NANOGAMI',\n",
       " 'NATIF AI',\n",
       " 'NEBUMIND',\n",
       " 'NEEW VENTURES',\n",
       " 'NEOPREDICS',\n",
       " 'NEROU',\n",
       " 'NESTL',\n",
       " 'NET SERVICES S   R L',\n",
       " 'NETCONOMY',\n",
       " 'NETLIGHT',\n",
       " 'NETTREK',\n",
       " 'NETTREK UND',\n",
       " 'NEUEFISCHE',\n",
       " 'NEURAFLOW',\n",
       " 'NEW YORKER',\n",
       " 'NEXMART',\n",
       " 'NEXTCODER SOFTWAREENTWICKLUNGS UG',\n",
       " 'NEXWAFE',\n",
       " 'NIELSENIQ',\n",
       " 'NOKIA',\n",
       " 'NOMAD ATOMICS',\n",
       " 'NORCOM INFORMATION TECHNOLOGY   CO',\n",
       " 'NORDMANN  RASSMANN',\n",
       " 'NORGINE',\n",
       " 'NOVENTIVE   IP SECURELY PROTECTED',\n",
       " 'NOVO AI',\n",
       " 'NOWEDA APOTHEKERGENOSSENSCHAFT EG',\n",
       " 'NUCS AI',\n",
       " 'NUROMEDIA',\n",
       " 'NUVISAN',\n",
       " 'OBI   CO',\n",
       " 'OLX',\n",
       " 'OLYMPUS EMEA',\n",
       " 'OMIO',\n",
       " 'OMMAX',\n",
       " 'ONE   F VE',\n",
       " 'OPITZ CONSULTING',\n",
       " 'OPTRONICS  SYSTEM TECHNOLOGIES AND IMAGE',\n",
       " 'ORANGE CYBERDEFENSE',\n",
       " 'ORANGE QUARTER',\n",
       " 'ORBEM',\n",
       " 'OSMA',\n",
       " 'OTTO  GMBH',\n",
       " 'OTTO DATA WORKS',\n",
       " 'OUTDOORACTIVE',\n",
       " 'OUTFITTERY',\n",
       " 'OXG GLASFASER',\n",
       " 'OYAK ANKER BANK',\n",
       " 'P UR   TELE COLUMBUS',\n",
       " 'PACEMAKER',\n",
       " 'PAIQO',\n",
       " 'PAIR FINANCE',\n",
       " 'PARCIT',\n",
       " 'PARETOS',\n",
       " 'PARI FIRMENGRUPPE',\n",
       " 'PARKER B ASSOCIATES',\n",
       " 'PARSHIPMEET',\n",
       " 'PARTEX',\n",
       " 'PARTSPACE',\n",
       " 'PASS APP',\n",
       " 'PAUL HARTMANN',\n",
       " 'PAYBACK',\n",
       " 'PAYMENTTOOLS',\n",
       " 'PEEK   CLOPPENBURG',\n",
       " 'PEEK   CLOPPENBURG     D SSELDORF',\n",
       " 'PERTO',\n",
       " 'PEXON CONSULTING',\n",
       " 'PFIZER',\n",
       " 'PFLEGEWEGWEISER',\n",
       " 'PHOENIX MEDICAL',\n",
       " 'PIMCO PRIME REAL ESTATE',\n",
       " 'PIVOT SEARCH',\n",
       " 'PIVOTAL',\n",
       " 'PLAN D',\n",
       " 'PLANET A FOODS',\n",
       " 'PMONE',\n",
       " 'POLARANALYTICS',\n",
       " 'POLYTEIA',\n",
       " 'PORSCHE CONSULTING',\n",
       " 'POWERCO',\n",
       " 'PREDIUM',\n",
       " 'PREDIUM TECHNOLOGY',\n",
       " 'PRENODE',\n",
       " 'PREVENTIO',\n",
       " 'PRIMAL STATE PERFORMANCE',\n",
       " 'PROCESS',\n",
       " 'PROCESSAND',\n",
       " 'PROCREDIT',\n",
       " 'PROCTER   GAMBLE',\n",
       " 'PROFESSIONAL SCIENTISTS',\n",
       " 'PROJECT A',\n",
       " 'PROJEKTTR GER J LICH  PTJ',\n",
       " 'PROLYTIC',\n",
       " 'PROPERTY FINDER',\n",
       " 'PROSIEBENSAT 1 TECH   SERVICES',\n",
       " 'PROTECTION ONE',\n",
       " 'PROTEROS BIOSTRUCTURES',\n",
       " 'PROVIDE',\n",
       " 'PSI SOFTWARE',\n",
       " 'PUBLICIS MEDIA GERMANY',\n",
       " 'PULS',\n",
       " 'PWC GERMANY',\n",
       " 'Q ENERGY',\n",
       " 'QIMIA',\n",
       " 'QPLIX',\n",
       " 'QRUISE',\n",
       " 'QUANTAGONIA',\n",
       " 'QUANTISTRY',\n",
       " 'QUANTUMBLACK  AI BY MCKINSEY',\n",
       " 'QUODATA',\n",
       " 'QUOTACOM',\n",
       " 'R V ALLGEMEINE VERSICHERUNG',\n",
       " 'RABOT ENERGY',\n",
       " 'RAILPOOL',\n",
       " 'RATBACHER',\n",
       " 'RATEPAY',\n",
       " 'RAUSGEGANGEN',\n",
       " 'RAZOR',\n",
       " 'RE7 CAPITAL',\n",
       " 'RECHENZENTRUM DER FINANZVERWALTUNG DES LANDES NORDRHEIN WESTFALEN',\n",
       " 'REMATIQ',\n",
       " 'REMOBI',\n",
       " 'REPLY',\n",
       " 'REVENUECAT',\n",
       " 'REWE',\n",
       " 'REWE DIGITAL',\n",
       " 'REWIRE',\n",
       " 'RHEINDATA',\n",
       " 'RHEINISCHE POST MEDIEN',\n",
       " 'RHEINMETALL AVIATION SERVICES',\n",
       " 'RHEINMETALL ELECTRONICS',\n",
       " 'RHEINMETALL TECHNOLOGY CENTER',\n",
       " 'RHESIS AI',\n",
       " 'RISK IDENT',\n",
       " 'RISK RESEARCH',\n",
       " 'RISK SOLUTIONS',\n",
       " 'RITTER',\n",
       " 'RIVERTY',\n",
       " 'RJC',\n",
       " 'RMS  DER AUDIOVERMARKTER',\n",
       " 'ROBOMINDS',\n",
       " 'ROBOTRON DATENBANK SOFTWARE',\n",
       " 'ROCHE',\n",
       " 'ROHDE   SCHWARZ',\n",
       " 'ROLAND RECHTSSCHUTZ VERSICHERUNGS AG',\n",
       " 'ROOMPRICEGENIE',\n",
       " 'ROOSI',\n",
       " 'ROSENXT',\n",
       " 'RSIGHT',\n",
       " 'RWTH AACHEN',\n",
       " 'RWTH AACHEN UNIVERSITY',\n",
       " 'S DKURIER MEDIENHAUS',\n",
       " 'S PAYMENT   EIN UNTERNEHMEN DER DSV GRUPPE',\n",
       " 'SACHCONTROL',\n",
       " 'SAFEAD',\n",
       " 'SAFEDRIVER',\n",
       " 'SANOFI',\n",
       " 'SAP',\n",
       " 'SAP FIONEER',\n",
       " 'SCALEFREE',\n",
       " 'SCALEUP AGENCY',\n",
       " 'SCHEER',\n",
       " 'SCHICKLER UNTERNEHMENSBERATUNG',\n",
       " 'SCHLUCHSEEWERK AKTIENGESELLSCHAFT',\n",
       " 'SCHMITT ENGINEERING',\n",
       " 'SCHOTT',\n",
       " 'SCHWARM TECHNOLOGIES INC',\n",
       " 'SCIENEERS',\n",
       " 'SECA SERVICES',\n",
       " 'SEER INC',\n",
       " 'SELLERX',\n",
       " 'SENACOR TECHNOLOGIES',\n",
       " 'SENTIENT FOUNDATION',\n",
       " 'SEVDESK',\n",
       " 'SHOPIFY',\n",
       " 'SIEGWERK DRUCKFARBEN   CO',\n",
       " 'SII',\n",
       " 'SIKWEL',\n",
       " 'SIMPLY X',\n",
       " 'SINTEC INFORMATIK',\n",
       " 'SKELETON TECHNOLOGIES',\n",
       " 'SKILL FARM',\n",
       " 'SKILLS ALLIANCE',\n",
       " 'SKILLSPARK AB',\n",
       " 'SKM',\n",
       " 'SKOPOS',\n",
       " 'SLAY',\n",
       " 'SMA DEVELOPMENT',\n",
       " 'SMARTLAB INNOVATIONSGESELLSCHAFT MBH',\n",
       " 'SOCIAL MATCH   WE ARE HIRING',\n",
       " 'SOCIETE GENERALE',\n",
       " 'SOFTSERVE',\n",
       " 'SOKA BAU',\n",
       " 'SOLERA',\n",
       " 'SOLUTE GMBH',\n",
       " 'SONO MOTORS',\n",
       " 'SOPRA STERIA',\n",
       " 'SOURCE INTERNATIONAL',\n",
       " 'SPARKASSE BREMEN',\n",
       " 'SPARKASSEN RATING UND RISIKOSYSTEME',\n",
       " 'SPHERA',\n",
       " 'SR2   SOCIALLY RESPONSIBLE RECRUITMENT   CERTIFIED B CORPORATION',\n",
       " 'ST DTISCHES KLINIKUM KARLSRUHE GGMBH',\n",
       " 'STABURO',\n",
       " 'STADLER SIGNALLING',\n",
       " 'STADT K LN',\n",
       " 'STADTSPARKASSE GLADBECK',\n",
       " 'STADTWERKE VERKEHRSGESELLSCHAFT FRANKFURT AM MAIN',\n",
       " 'STARKFLOW',\n",
       " 'STATISTA',\n",
       " 'STATWORX',\n",
       " 'STEADFORCE',\n",
       " 'STENON',\n",
       " 'STHREE',\n",
       " 'STI',\n",
       " 'STIMME MEDIENGRUPPE',\n",
       " 'STORYBLOK',\n",
       " 'STRATEGION',\n",
       " 'STRATIV',\n",
       " 'STRIVENEST',\n",
       " 'STUDYFLIX',\n",
       " 'STYLINK SOCIAL MEDIA',\n",
       " 'SUPER AI',\n",
       " 'SURGE',\n",
       " 'SVA SYSTEM VERTRIEB ALEXANDER',\n",
       " 'SWISS RE',\n",
       " 'SWK ENERGIE',\n",
       " 'SYNAMIC TECHNOLOGIES UG',\n",
       " 'SYNGENTA',\n",
       " 'T V S D',\n",
       " 'T V S D DIGITAL SERVICE',\n",
       " 'TABLE BRIEFINGS',\n",
       " 'TACTO',\n",
       " 'TAOD CONSULTING',\n",
       " 'TARGOBANK',\n",
       " 'TARGOMO',\n",
       " 'TCHIBO',\n",
       " 'TEAMVIEWER',\n",
       " 'TECALLIANCE',\n",
       " 'TECAN SOFTWARE COMPETENCE CENTER',\n",
       " 'TECAN TRADING',\n",
       " 'TECHNIKER KRANKENKASSE',\n",
       " 'TECHNISCHE INFORMATIONSBIBLIOTHEK  TIB',\n",
       " 'TECHNISCHE UNIVERSIT T CLAUSTHAL',\n",
       " 'TECHNISCHE UNIVERSIT T ILMENAU',\n",
       " 'TECHNOLOGY   STRATEGY',\n",
       " 'TECKENTRUP',\n",
       " 'TELUS DIGITAL',\n",
       " 'TEMU',\n",
       " 'TENTHPIN',\n",
       " 'TERAKI',\n",
       " 'TERRITORY MEDIA',\n",
       " 'TESLA',\n",
       " 'TESLA AUTOMATION',\n",
       " 'TETHER IO',\n",
       " 'TETRASCIENCE',\n",
       " 'THE CREATIVE CLUB',\n",
       " 'THE PRODUCT GUYS',\n",
       " 'THEION',\n",
       " 'THEO F RCH',\n",
       " 'THERMO FISHER SCIENTIFIC',\n",
       " 'THINKRED WEST',\n",
       " 'THOMANN IO',\n",
       " 'THRYVE',\n",
       " 'THYSSENGAS',\n",
       " 'THYSSENKRUPP',\n",
       " 'TIETALENT',\n",
       " 'TINYBIRD',\n",
       " 'TMM',\n",
       " 'TOMORROW UNIVERSITY OF APPLIED SCIENCES',\n",
       " 'TOOZ TECHNOLOGIES',\n",
       " 'TOP TECHNOLOGIES CONSULTING',\n",
       " 'TOURLANE',\n",
       " 'TRAKKEN',\n",
       " 'TRANS O FLEX',\n",
       " 'TRANSNETBW',\n",
       " 'TRANSPARENT HIRING',\n",
       " 'TRELLEBORG SEALING SOLUTIONS GERMANY',\n",
       " 'TRIATHLON',\n",
       " 'TRINETX',\n",
       " 'TRIS TECHNOLOGY',\n",
       " 'TRIVAGO',\n",
       " 'TRKKN',\n",
       " 'TRON',\n",
       " 'TRUEMETRICS',\n",
       " 'TRUST IN SODA',\n",
       " 'TRUST WALLET',\n",
       " 'TRUSTEQ',\n",
       " 'TWOMYNDS',\n",
       " 'UCANEO',\n",
       " 'UCG UNITED CONSULTING',\n",
       " 'UELZENER ALLGEMEINE VERSICHERUNGS GESELLSCHAFT',\n",
       " 'UKSH',\n",
       " 'UNION INVESTMENT',\n",
       " 'UNITY CONSULTING   INNOVATION',\n",
       " 'UNIVERSIT TSKLINIKUM M NSTER',\n",
       " 'UNIVERSIT TSKLINIKUM W RZBURG',\n",
       " 'UNIVERSITY HOSPITAL SCHLESWIG HOLSTEIN  UKSH',\n",
       " 'UNIVERSITY OF BAYREUTH',\n",
       " 'UNIVERSITY OF HAMBURG',\n",
       " 'UNTERNEHMENSGRUPPE THEO M LLER',\n",
       " 'UPVEST',\n",
       " 'US COMMANDER  NAVAL INFORMATION WARFARE SYSTEMS',\n",
       " 'UTILIGENCE',\n",
       " 'V RIDION',\n",
       " 'VAILLANT BUSINESS SERVICES',\n",
       " 'VAISTO SOLUTIONS',\n",
       " 'VALANTIC DIGITAL FINANCE',\n",
       " 'VALANTIC SOFTWARE   TECHNOLOGY INNOVATIONS',\n",
       " 'VALUEWORKS',\n",
       " 'VALUEWORKS AI',\n",
       " 'VALUEZON',\n",
       " 'VANGUARD AUTOMATION',\n",
       " 'VARTA MICRO PRODUCTION',\n",
       " 'VAY',\n",
       " 'VBN',\n",
       " 'VENT IO',\n",
       " 'VERVE',\n",
       " 'VHV',\n",
       " 'VIDLAB7',\n",
       " 'VIGENERON',\n",
       " 'VIMATEC',\n",
       " 'VINTED',\n",
       " 'VIRTUAL7',\n",
       " 'VISA',\n",
       " 'VISIONAI',\n",
       " 'VIVID MONEY',\n",
       " 'VKB',\n",
       " 'VLS VERSICHERUNGSLOGISTIK',\n",
       " 'VOLKSWOHL BUND LEBENSVERSICHERUNG',\n",
       " 'VOLLCOM DIGITAL',\n",
       " 'VP VERBUND PFLEGEHILFE',\n",
       " 'VTG',\n",
       " 'W RTTEMBERGISCHE VERSICHERUNG AKTIENGESELLSCHAFT',\n",
       " 'WACKER CHEMIE',\n",
       " 'WARGAMING',\n",
       " 'WAVE MOBILE MONEY',\n",
       " 'WDR',\n",
       " 'WEBER',\n",
       " 'WEGO SYSTEMBAUSTOFFE',\n",
       " 'WEMOLO',\n",
       " 'WENTRONIC',\n",
       " 'WESORT AI',\n",
       " 'WIBU',\n",
       " 'WIRTSCHAFTSRAT DER CDU E V',\n",
       " 'WITH LOVE AND DATA',\n",
       " 'WM',\n",
       " 'WOLT',\n",
       " 'WOOGA',\n",
       " 'WORKAROUND',\n",
       " 'WORKIDENTITY',\n",
       " 'WORLD FOOD PROGRAMME',\n",
       " 'XIBIX SOLUTIONS',\n",
       " 'XPENG',\n",
       " 'XPLAIN DATA',\n",
       " 'XSOLLA',\n",
       " 'YEAH  GLOBAL',\n",
       " 'YO IT CONSULTING',\n",
       " 'YUKAWA EXPONENTIAL',\n",
       " 'ZABEL',\n",
       " 'ZALANDO',\n",
       " 'ZANDER LABS',\n",
       " 'ZATTOO',\n",
       " 'ZAUBAR',\n",
       " 'ZEAL NETWORK',\n",
       " 'ZEISS',\n",
       " 'ZEIT VERLAGSGRUPPE',\n",
       " 'ZENDR',\n",
       " 'ZENJOB',\n",
       " 'ZERO TO ONE SEARCH   RECRUITMENT AGENCY',\n",
       " 'ZERTIFICON',\n",
       " 'ZERTIFICON SOLUTIONS',\n",
       " 'ZURICH INSURANCE',\n",
       " 'ZVOOVE']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check unique list of company names to find spellings of company names that can be combined.\n",
    "np.sort(df[\"company_clean_ish\"].unique()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>title</th>\n",
       "      <th>source_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Zertificon Solutions GmbH</td>\n",
       "      <td>Neukölln</td>\n",
       "      <td>Data Analyst (m/f/d) in IT security company</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>Zertificon</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Analyst (m/f/d) in IT security company</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        company  location   \n",
       "398   Zertificon Solutions GmbH  Neukölln  \\\n",
       "1152                 Zertificon    Berlin   \n",
       "\n",
       "                                            title  source_id  \n",
       "398   Data Analyst (m/f/d) in IT security company          1  \n",
       "1152  Data Analyst (m/f/d) in IT security company          2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check some names\n",
    "df.loc[df[\"company\"].str.upper().str.contains(\"ZERTIFICON\"), [\"company\", \"location\", \"title\", \"source_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of (parts of) company names that occure, and the name we want to replace it with.\n",
    "\n",
    "company_dict = {\n",
    "'4SCREEN': '4 SCREEN',\n",
    "'ACONEXT': 'ACONEXT', #'ACONEXT STUTTGART'\n",
    "'ADAC': 'ADAC', #'ADAC ALLGEMEINER DEUTSCHER AUTOMOBIL CLUB',\n",
    "'AXEL SPRINGER': 'AXEL SPRINGER', #'AXEL SPRINGER NATIONAL MEDIA  TECH',\n",
    "'BECHTLE BREMEN': 'BECHTLE ITSYSTEMHAUS BREMEN',\n",
    "'BOOZ ALLEN': 'BOOZ ALLEN',\n",
    "'CHECK24': 'CHECK24', # 'CHECK24 VERGLEICHSPORTAL',\n",
    "'CHERRY VENTURES': 'CHERRY VENTURES', # 'CHERRY VENTURES MANAGEMENT'\n",
    "'CHOCO': 'CHOCO COMMUNICATIONS',\n",
    "'ENPAL': 'ENPAL', #'ENPAL DRAGON',\n",
    "'HOPMANN': 'HOPMANN MARKETING ANALYTICS', # 'HOPMANN   MARKETING ANALYTICS INH  J RG HOPMANN',\n",
    "'HUK COBURG': 'HUK COBURG', #'HUK COBURG VERSICHERUNGSGRUPPE',\n",
    "'LEIBNIZ INSTITUT F R ANALYTISCHE WISSENSCHAFTEN': 'LEIBNIZ INSTITUT F R ANALYTISCHE WISSENSCHAFTEN',\n",
    "'LEIBNIZ INSTITUT F R ASTROPHYSIK': 'LEIBNIZ INSTITUT F R ASTROPHYSIK', # 'LEIBNIZ INSTITUT F R ASTROPHYSIK POTSDAM',\n",
    "'LEIBNIZ INSTITUT F R NATURSTOFF': 'LEIBNIZ INSTITUT F R NATURSTOFF FORSCHUNG UND INFEKTIONSBIOLOGIE E V',\n",
    "'LOTUM': 'LOTUM', # 'LOTUM MEDIA'\n",
    "'LUNIT': 'LUNIT', #'LUNIT CANCER SCREENING'\n",
    "'MVGM':  'MVGM', # 'MVGM INTERNATIONAL'\n",
    "'NETTREK': 'NETTREK', #'NETTREK UND'\n",
    "'CLOPPENBURG': 'PEEK CLOPPENBURG', # 'PEEK   CLOPPENBURG     D SSELDORF'\n",
    "'PREDIUM': 'PREDIUM TECHNOLOGY',\n",
    "'PROCESS': 'PROCESSAND',\n",
    "'T V S D': 'T V S D', # TÜV SÜD; 'T V S D DIGITAL SERVICE'\n",
    "'VALUEWORKS': 'VALUEWORKS AI',\n",
    "'ZERTIFICON': 'ZERTIFICON', # 'ZERTIFICON SOLUTIONS'\n",
    "}\n",
    "\n",
    "for contains_string, replace_string in company_dict.items():\n",
    "    df.loc[df[\"company_clean_ish\"].str.upper().str.contains(contains_string), [\"company_clean_ish\"]] = replace_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 1 MAIL   MEDIA APPLICATIONS',\n",
       " '1KOMMA5',\n",
       " '1KOMMA6   MULTIMEDIALE DIENSTLEISTUNGEN',\n",
       " '1X2 TECHNOLOGIES',\n",
       " '4 SCREEN',\n",
       " 'ABAT NORTH AMERICA',\n",
       " 'ABB',\n",
       " 'ABBVIE',\n",
       " 'ABOUT YOU',\n",
       " 'ACCANTEC GROUP',\n",
       " 'ACCENTURE',\n",
       " 'ACCURE BATTERY INTELLIGENCE',\n",
       " 'ACONEXT',\n",
       " 'ADAC',\n",
       " 'ADEAL SYSTEMS',\n",
       " 'ADESSO',\n",
       " 'ADG APOTHEKEN DIENSTLEISTUNGSGESELLSCHAFT MBH',\n",
       " 'ADM',\n",
       " 'AERZENER MASCHINENFABRIK',\n",
       " 'AI ASSOCIATES',\n",
       " 'AI FUTURES',\n",
       " 'AIGNOSTICS',\n",
       " 'AILIO',\n",
       " 'AINOVI',\n",
       " 'AITAD',\n",
       " 'AKKODIS',\n",
       " 'AKLASS SOLUTIONS',\n",
       " 'AL SOLUTIONS',\n",
       " 'ALACRIS THERANOSTICS',\n",
       " 'ALBATROSS AI',\n",
       " 'ALCEDIS   A HUMA COMPANY',\n",
       " 'ALDI EINKAUF   CO  OHG',\n",
       " 'ALDI S D',\n",
       " 'ALEXANDER THAMM',\n",
       " 'ALFRED WEGENER INSTITUT F R POLAR  UND',\n",
       " 'ALGEA CARE',\n",
       " 'ALITHEA BIO',\n",
       " 'ALIXPARTNERS',\n",
       " 'ALLGEIER PUBLIC',\n",
       " 'ALLIANZ',\n",
       " 'ALLIANZ DIGITAL HEALTH',\n",
       " 'ALLIANZ VERSICHERUNGS AG',\n",
       " 'ALLOS HOF MANUFAKTUR',\n",
       " 'ALMEDIA',\n",
       " 'ALTEN CONSULTING SERVICES',\n",
       " 'ALTEN GERMANY',\n",
       " 'AMAI',\n",
       " 'AMAZON',\n",
       " 'AMAZON DEVELOPMENT CENTER GERMANY',\n",
       " 'AMAZON DEVELOPMENT CENTER GERMANY   C92',\n",
       " 'AMAZON EUROPE CORE',\n",
       " 'AMAZON WEB SERVICES  AWS',\n",
       " 'AMAZON WEB SERVICES DEVELOPMENT CENTER GERMANY',\n",
       " 'AMD',\n",
       " 'AMFILEON',\n",
       " 'AMMERL NDER VERSICHERUNG VVAG',\n",
       " 'AMPRION',\n",
       " 'AMUNDI',\n",
       " 'ANALYTIK JENA CO  KG',\n",
       " 'AOK BAYERN   DIE GESUNDHEITSKASSE',\n",
       " 'APPINIO',\n",
       " 'APPLIKE',\n",
       " 'APPLOFT',\n",
       " 'APTIV',\n",
       " 'ARETE',\n",
       " 'ARETO CONSULTING GMBH',\n",
       " 'ARIADNE',\n",
       " 'ARTIVION EMEA',\n",
       " 'ARVATO',\n",
       " 'ARVATO SYSTEMS',\n",
       " 'ARVATO SYSTEMS DIGITAL',\n",
       " 'ASCENDIS PHARMA',\n",
       " 'ASKLEPIOS SERVICE IT',\n",
       " 'ATH ALTONAER TECHNOLOGIE HOLDING',\n",
       " 'ATLAS ELEKTRONIK',\n",
       " 'ATLAS MARIDAN APS',\n",
       " 'ATMIO',\n",
       " 'ATOSS SOFTWARE',\n",
       " 'ATRUVIA',\n",
       " 'AUDACITY CAPITAL MANAGEMENT',\n",
       " 'AUDIBENE',\n",
       " 'AUDIBLE',\n",
       " 'AUSBILDUNG DE',\n",
       " 'AUTO1',\n",
       " 'AUTONOMOUS TEAMING SOLUTIONS',\n",
       " 'AUXMONEY',\n",
       " 'AVAT AUTOMATION',\n",
       " 'AVO INTELLIGENCE',\n",
       " 'AWS EMEA SARL  GERMANY BRANCH',\n",
       " 'AXEL SPRINGER',\n",
       " 'AXULUS',\n",
       " 'BABBEL',\n",
       " 'BAKER TILLY',\n",
       " 'BARBARICUM',\n",
       " 'BARMER',\n",
       " 'BASF',\n",
       " 'BAUER',\n",
       " 'BAUMLINK',\n",
       " 'BAYER',\n",
       " 'BAYERISCHES LANDESAMT F R GESUNDHEIT UND LEBENSMITTELSICHERHEIT',\n",
       " 'BAYERISCHES LANDESAMT F R STATISTIK',\n",
       " 'BAYWA R E  SOLAR TRADE',\n",
       " 'BCG X',\n",
       " 'BCMED',\n",
       " 'BEAM AI',\n",
       " 'BEARINGPOINT',\n",
       " 'BECHTLE IT SYSTEMHAUS BREMEN',\n",
       " 'BECHTLE ITSYSTEMHAUS BREMEN',\n",
       " 'BEHREND E K',\n",
       " 'BEIERSDORF',\n",
       " 'BEIERSDORF SHARED SERVICES',\n",
       " 'BERGFREUNDE',\n",
       " 'BERLINER WASSERBETRIEBE',\n",
       " 'BERTRANDT',\n",
       " 'BI PHARMA CO KG',\n",
       " 'BI VETMEDICA',\n",
       " 'BID BAYERISCHER INKASSO DIENST',\n",
       " 'BIKAR METALLE',\n",
       " 'BINANCE',\n",
       " 'BIOMARKER SERVICES',\n",
       " 'BIONTECH',\n",
       " 'BIOTRONIK CORPORATE SERVICES',\n",
       " 'BIOTYPE',\n",
       " 'BITA',\n",
       " 'BLACKLANE',\n",
       " 'BLUEOAK ADVERTISING',\n",
       " 'BLUEPRINT EXECUTIVE SEARCH',\n",
       " 'BLUETHRONE',\n",
       " 'BMW',\n",
       " 'BN AUTOMATION',\n",
       " 'BNP PARIBAS PERSONAL INVESTORS',\n",
       " 'BOEHRINGER INGELHEIM',\n",
       " 'BOLT',\n",
       " 'BOOZ ALLEN',\n",
       " 'BOSCH',\n",
       " 'BOSTON CONSULTING',\n",
       " 'BRANCH TECH',\n",
       " 'BRAVOBIKE',\n",
       " 'BREUNINGER',\n",
       " 'BRIDGINGIT',\n",
       " 'BRIGHT TESTING',\n",
       " 'BRING  LABS',\n",
       " 'BRUNEL',\n",
       " 'BRUSS SEALING SYSTEMS',\n",
       " 'BUDNI HANDELS  UND SERVICE',\n",
       " 'BUNDESAGENTUR F R ARBEIT',\n",
       " 'BWF',\n",
       " 'BWORKS HR PROFESSIONAL',\n",
       " 'BYK ADDITIVES',\n",
       " 'BYK CHEMIE',\n",
       " 'C  MELCHERS',\n",
       " 'CAMBRIUM',\n",
       " 'CAMPOINT',\n",
       " 'CANCOM',\n",
       " 'CAPGEMINI',\n",
       " 'CAPGEMINI INVENT',\n",
       " 'CARHARTT WIP  WORK IN PROGRESS',\n",
       " 'CARL ZEISS IQS SOFTWARE R D CENTER',\n",
       " 'CARONSALE',\n",
       " 'CAVALIS',\n",
       " 'CBM CHRISTOFFEL BLINDENMISSION CHRISTIAN BLIND MISSION E V',\n",
       " 'CBTW',\n",
       " 'CDP',\n",
       " 'CEEZER',\n",
       " 'CELONIS',\n",
       " 'CENTRIC SOFTWARE',\n",
       " 'CERTIVITY',\n",
       " 'CGI',\n",
       " 'CHAOZHOU THREE CIRCLE CO   LTD',\n",
       " 'CHECK24',\n",
       " 'CHEFS CULINAR',\n",
       " 'CHERRY VENTURES',\n",
       " 'CHOCO COMMUNICATIONS',\n",
       " 'CHRIST COMPANY CONSULTING',\n",
       " 'CIDEON SOFTWARE   SERVICES',\n",
       " 'CIKLO TALENT',\n",
       " 'CIMT AG',\n",
       " 'CINEMO',\n",
       " 'CINT',\n",
       " 'CLAAS MBH',\n",
       " 'CLARINESS',\n",
       " 'CLIMATIQ',\n",
       " 'CLOOVER',\n",
       " 'COAC',\n",
       " 'COBRAINER',\n",
       " 'COFINITY X',\n",
       " 'COFINPRO',\n",
       " 'COGNITIVO',\n",
       " 'COLLABORATION BETTERS THE WORLD',\n",
       " 'COLTECH',\n",
       " 'COMMA SOFT',\n",
       " 'COMPANION STRATEGIEBERATUNG',\n",
       " 'COMPARUS',\n",
       " 'COMPUGROUP MEDICAL',\n",
       " 'COMPUGROUP MEDICAL   CO',\n",
       " 'COMPUSAFE DATA SYSTEMS',\n",
       " 'COMPUTER FUTURES',\n",
       " 'COMPUTOMICS',\n",
       " 'CONET',\n",
       " 'CONNECTMETA AI',\n",
       " 'CONSTELLR',\n",
       " 'CONTROL EXPERT',\n",
       " 'CONVIT',\n",
       " 'CONVOLUT',\n",
       " 'CORECRUITMENT LTD',\n",
       " 'CORIOLIS PHARMA RESEARCH',\n",
       " 'COSNOVA',\n",
       " 'COSUNO',\n",
       " 'COZERO',\n",
       " 'CRAYON',\n",
       " 'CREALYTICS',\n",
       " 'CREDITPLUS BANK',\n",
       " 'CREDITSHELF AKTIENGESELLSCHAFT',\n",
       " 'CREDIUM',\n",
       " 'CRELUX',\n",
       " 'CROWDSTRIKE',\n",
       " 'CSL BEHRING',\n",
       " 'CUJU',\n",
       " 'CUREVAC',\n",
       " 'CUREXUS',\n",
       " 'CYBER VALLEY',\n",
       " 'CYTIVA',\n",
       " 'DADAJ',\n",
       " 'DAHAG RECHTSSERVICES',\n",
       " 'DAIICHI SANKYO EUROPE',\n",
       " 'DAMEDIC',\n",
       " 'DATA TALENT',\n",
       " 'DATACAMP',\n",
       " 'DATACRAFT',\n",
       " 'DATAMICS',\n",
       " 'DATAMONKEY',\n",
       " 'DATASEC INFORMATION FACTORY',\n",
       " 'DATASOLUT',\n",
       " 'DATEV EG',\n",
       " 'DEEPREC AI',\n",
       " 'DEICHMANN',\n",
       " 'DELIVERY HERO',\n",
       " 'DELOITTE',\n",
       " 'DELTIA',\n",
       " 'DELTRA BUSINESS SOFTWARE',\n",
       " 'DENNEMEYER',\n",
       " 'DEUTSCHE APOTHEKER  UND  RZTEBANK EG   APOBANK',\n",
       " 'DEUTSCHE BANK',\n",
       " 'DEUTSCHE BUNDESBANK',\n",
       " 'DEUTSCHE KREDITBANK  DKB',\n",
       " 'DEUTSCHE RENTENVERSICHERUNG BUND',\n",
       " 'DEUTSCHES ELEKTRONEN SYNCHROTRON DESY',\n",
       " 'DEUTSCHES KREBSFORSCHUNGSZENTRUM',\n",
       " 'DEVELOPREC',\n",
       " 'DEVNET',\n",
       " 'DEVOTEAM I GOOGLE CLOUD PARTNER',\n",
       " 'DEXTER HEALTH',\n",
       " 'DFB',\n",
       " 'DHL CONSULTING',\n",
       " 'DIDA',\n",
       " 'DIGITAL CHARGING SOLUTIONS',\n",
       " 'DIGITALTREIBER UG',\n",
       " 'DIGITALTWIN TECHNOLOGY',\n",
       " 'DIGITECH SEARCH',\n",
       " 'DIGITL',\n",
       " 'DIMOS OPERATIONS',\n",
       " 'DIN SOLUTIONS',\n",
       " 'DISCOVER INTERNATIONAL',\n",
       " 'DLTHUB',\n",
       " 'DOCTOLIB',\n",
       " 'DOHLE HANDELSGRUPPE',\n",
       " 'DOUGLAS',\n",
       " 'DR  JOHANNES HEIDENHAIN',\n",
       " 'DR  KURT WOLFF',\n",
       " 'DR  WOLFF',\n",
       " 'DR GER',\n",
       " 'DR GERWERK   CO',\n",
       " 'DREES   SOMMER',\n",
       " 'DYMATRIX',\n",
       " 'DZ BANK',\n",
       " 'E ON DIGITAL TECHNOLOGY',\n",
       " 'E2N',\n",
       " 'EBENBUILD',\n",
       " 'ECE',\n",
       " 'ECMWF',\n",
       " 'EGGERSMANN',\n",
       " 'EGYM',\n",
       " 'EHRENM LLER',\n",
       " 'EIDU',\n",
       " 'ELEVENLABS',\n",
       " 'ELUNIC',\n",
       " 'EMBASSY OF THE UNITED STATES OF AMERICA',\n",
       " 'EMMA   THE SLEEP COMPANY',\n",
       " 'EMPION',\n",
       " 'ENBW ENERGIE BADEN W RTTEMBERG',\n",
       " 'ENCAVIS',\n",
       " 'ENERCITY',\n",
       " 'ENERGYEFFIZIENZ',\n",
       " 'ENGAIGE',\n",
       " 'ENJINS',\n",
       " 'ENPAL',\n",
       " 'ENTRIX',\n",
       " 'ENZO',\n",
       " 'ENZO TECH',\n",
       " 'EODA',\n",
       " 'EPM SCIENTIFIC',\n",
       " 'ERC SYSTEM',\n",
       " 'ERDMANN SOFTWAREGESELLSCHAFT MBH',\n",
       " 'ERGO',\n",
       " 'ERGOTOPIA',\n",
       " 'ERNSTING S FAMILY',\n",
       " 'ES TEC',\n",
       " 'ESL FACEIT   EFG',\n",
       " 'ESQLABS',\n",
       " 'ETRIBES',\n",
       " 'EUROPA PARK',\n",
       " 'EUROPA PARK ERLEBNIS RESORT',\n",
       " 'EUROPEAN CENTRE FOR MEDIUM RANGE WEATHER FORECASTS',\n",
       " 'EUROPEAN TECH RECRUIT',\n",
       " 'EUROPEAN X RAY FREE ELECTRON LASER FACILITY',\n",
       " 'EVERSION TECHNOLOGIES',\n",
       " 'EVIDANZA',\n",
       " 'EVONIK',\n",
       " 'EWE TEL',\n",
       " 'EWOLFF',\n",
       " 'EXACT SCIENCES CORPORATION',\n",
       " 'EXOMATTER',\n",
       " 'EXPATRIO',\n",
       " 'EXPLEO',\n",
       " 'EY',\n",
       " 'EYEO',\n",
       " 'FAIR PARKEN',\n",
       " 'FERCHAU',\n",
       " 'FEW FAR',\n",
       " 'FIBER EXPERTS',\n",
       " 'FINANZ DATA',\n",
       " 'FINANZAMT KASSEL',\n",
       " 'FINANZGURU',\n",
       " 'FINCON REPLY',\n",
       " 'FINN',\n",
       " 'FIT ANALYTICS',\n",
       " 'FLASCHENPOST',\n",
       " 'FLEXA',\n",
       " 'FLINK',\n",
       " 'FLIP',\n",
       " 'FLOORTEX EUROPE LTD',\n",
       " 'FLUGHAFEN HANNOVER LANGENHAGEN',\n",
       " 'FLYERALARM BIT LABS',\n",
       " 'FOM UNIVERSITY OF APPLIED SCIENCES FOR ECONOMICS AND MANAGEMENT',\n",
       " 'FORRS PARTNERS',\n",
       " 'FORSCHUNGSZENTRUM J LICH',\n",
       " 'FORVIS MAZARS',\n",
       " 'FORWARD EARTH',\n",
       " 'FOXBASE',\n",
       " 'FRANZ   WACH PERSONALSERVICE',\n",
       " 'FRAUNHOFER FIT',\n",
       " 'FRAUNHOFER INSTITUTE FOR MICROELECTRONIC CIRCUITS AND SYSTEMS',\n",
       " 'FREENET DLS',\n",
       " 'FREIE UNIVERSIT T BERLIN',\n",
       " 'FRIEDRICH SCHILLER UNIVERSIT T JENA',\n",
       " 'FUSION CONSULTING',\n",
       " 'FUTURAE TECHNOLOGIES',\n",
       " 'FUTURISED',\n",
       " 'G2 RECRUITMENT',\n",
       " 'GAF',\n",
       " 'GARANT',\n",
       " 'GASCADE GASTRANSPORT',\n",
       " 'GEBR  HEINEMANN',\n",
       " 'GEM',\n",
       " 'GEMA   GESELLSCHAFT F R MUSIK  AUFF HRUNGS  UND MECHAN  VERVIELF LTIGUNGSRECHTE',\n",
       " 'GEN RE',\n",
       " 'GENERALI',\n",
       " 'GENERALI DEUTSCHLAND',\n",
       " 'GERMAN AEROSPACE CENTER  DLR',\n",
       " 'GESELLSCHAFT F R MUSIKALISCHE AUFF HRUNGS  UND',\n",
       " 'GETML RESEARCH',\n",
       " 'GETRIEBEBAU NORD',\n",
       " 'GETYOURGUIDE',\n",
       " 'GHARAGE',\n",
       " 'GIE EREI INSTITUT DER RWTH AACHEN',\n",
       " 'GIGS',\n",
       " 'GIM GESELLSCHAFT F R INNOVATIVE MARKTFORSCHUNG MBH',\n",
       " 'GLASSDOLLAR',\n",
       " 'GLOBAL ENERGY INTERCONNECTION RESEARCH INSTITUTE EUROPE',\n",
       " 'GLOBAL MARKET SOLUTIONS   GERMANY',\n",
       " 'GLOBAL UNIVERSITY SYSTEMS',\n",
       " 'GNOSIS',\n",
       " 'GOLDNER',\n",
       " 'GOOGLE',\n",
       " 'GR NENTHAL',\n",
       " 'GREEN ENERGY ORIGIN  GEO',\n",
       " 'GREEN FUSION',\n",
       " 'GREEN VALUE MANAGEMENT LTD',\n",
       " 'GREENBOOTCAMPS',\n",
       " 'GREENPOCKET',\n",
       " 'GREENVENTORY',\n",
       " 'GREY ENGINEERING',\n",
       " 'GRIMME LANDMASCHINENFABRIK',\n",
       " 'GRO  BUSINESS',\n",
       " 'GROHE',\n",
       " 'GSI HELMHOLTZZENTRUM F R SCHWERIONENFORSCHUNG',\n",
       " 'GSK',\n",
       " 'GWQ SERVICEPLUS',\n",
       " 'H NDLERBUND',\n",
       " 'HAGIUS',\n",
       " 'HAMBURG UNIVERSITY OF TECHNOLOGY',\n",
       " 'HAMLYN WILLIAMS',\n",
       " 'HANDELSBLATT',\n",
       " 'HANDZ ON',\n",
       " 'HANNOVER R CK',\n",
       " 'HANNOVER RE',\n",
       " 'HANSEMERKUR',\n",
       " 'HANSETHERM',\n",
       " 'HAPEKO',\n",
       " 'HARVEY NASH',\n",
       " 'HASHLIST',\n",
       " 'HAUFE',\n",
       " 'HAUSGOLD   TALOCASA',\n",
       " 'HAVAS',\n",
       " 'HAWK',\n",
       " 'HAYS   WORKING FOR YOUR TOMORROW',\n",
       " 'HDI',\n",
       " 'HEIDELBERG MATERIALS',\n",
       " 'HEIDELBERG UNIVERSITY',\n",
       " 'HELLOWORK CONSULTANTS',\n",
       " 'HELMHOLTZ ZENTRUM M NCHEN',\n",
       " 'HELPLING',\n",
       " 'HENKEL',\n",
       " 'HETZNER',\n",
       " 'HIGHBERG MEDIAMINDS',\n",
       " 'HIGHLANDER SOLUTIONS',\n",
       " 'HIT HANDELSGRUPPE',\n",
       " 'HMS ANALYTICAL SOFTWARE',\n",
       " 'HMS ANALYTICAL SOFTWARE   CONSULTING   END TO END SOLUTIONS FOR DATA SCIENCE   ANALYTICS',\n",
       " 'HOCHSCHULE KAISERSLAUTERN',\n",
       " 'HOME24',\n",
       " 'HOPMANN MARKETING ANALYTICS',\n",
       " 'HORV TH',\n",
       " 'HOTTGENROTH',\n",
       " 'HP',\n",
       " 'HR UNIVERSAL',\n",
       " 'HUK COBURG',\n",
       " 'HYUNDAI MOTOR',\n",
       " 'IABG',\n",
       " 'IBA',\n",
       " 'IBA DOSIMETRY',\n",
       " 'ICIS TSCHACH SOLUTION',\n",
       " 'IFTA',\n",
       " 'IK PARTNERS',\n",
       " 'ILSENBURGER GROBBLECH',\n",
       " 'IMPALA SEARCH',\n",
       " 'INCARI DEVELOPMENT PLATFORM',\n",
       " 'INDIVUMED',\n",
       " 'INFINEON TECHNOLOGIES',\n",
       " 'INFRASERV H CHST',\n",
       " 'ING',\n",
       " 'INITIONS',\n",
       " 'INNNOW',\n",
       " 'INNOMOTICS',\n",
       " 'INOVEX',\n",
       " 'INSTAFFO',\n",
       " 'INSTAPRO',\n",
       " 'INSTITUT F R MEDIZINISCHE INFORMATIK',\n",
       " 'INTAPP',\n",
       " 'INTEGRITYNEXT',\n",
       " 'INTEREX',\n",
       " 'INTERHYP',\n",
       " 'INTERJOB',\n",
       " 'INTERWORKS',\n",
       " 'INVIA TRAVEL GERMANY',\n",
       " 'IOTIS',\n",
       " 'IPPEN DIGITAL',\n",
       " 'IPPEN MEDIA',\n",
       " 'IPSOS',\n",
       " 'IRON EAGLEX  INC',\n",
       " 'ISS SOFTWARE',\n",
       " 'IT INTERNATIONAL MOBILITY',\n",
       " 'IT P INFORMATION TECHNOLOGY PARTNER',\n",
       " 'IT SERVICE',\n",
       " 'IT4IPM',\n",
       " 'ITEM INDUSTRIETECHNIK',\n",
       " 'IUNA AI',\n",
       " 'IWOCA',\n",
       " 'J  RETTENMAIER   S HNE',\n",
       " 'JAAI   JUST ADD AI',\n",
       " 'JET SERVICES MARKETING',\n",
       " 'JINA AI',\n",
       " 'JOHNSON   JOHNSON',\n",
       " 'JOIN COM',\n",
       " 'JSS ASSOCIATES',\n",
       " 'JUST ADD AI',\n",
       " 'JUST EAT TAKEAWAY COM',\n",
       " 'K RCHER',\n",
       " 'KAPA AI',\n",
       " 'KARRIERE TUTOR',\n",
       " 'KASSENZAHN RZTLICHE VEREINIGUNG HESSEN   K RPERSCHAFT DES  FFENTLICHEN RECHTS',\n",
       " 'KAYZEN',\n",
       " 'KEY WORK CONSULTING',\n",
       " 'KI PERFORMANCE',\n",
       " 'KIENBAUM CONSULTANTS INTERNATIONAL   ZENTRALE',\n",
       " 'KIRESULT',\n",
       " 'KLA',\n",
       " 'KLANG GAMES',\n",
       " 'KLIM',\n",
       " 'KLINIK F R ALLGEMEIN   VISZERAL  UND',\n",
       " 'KNUDDELS',\n",
       " 'KONFUZIO',\n",
       " 'KONVERSIONSKRAFT',\n",
       " 'KORRO AI',\n",
       " 'KOSATEC COMPUTER',\n",
       " 'KPMG WIRTSCHAFTSPR FUNGSGESELLSCHAFT',\n",
       " 'KREATIVSTORM',\n",
       " 'KWS',\n",
       " 'L WENSTEIN MEDICAL',\n",
       " 'LABOREMUS',\n",
       " 'LADGOV CORPORATION',\n",
       " 'LANCH',\n",
       " 'LANDESHAUPTSTADT STUTTGART',\n",
       " 'LANDESKRANKENHILFE V V A G',\n",
       " 'LANDKREIS BODENSEEKREIS',\n",
       " 'LANG SERVICE',\n",
       " 'LEHMANN   PIONEERS DIGITAL',\n",
       " 'LEIBNIZ INSTITUT F R ANALYTISCHE WISSENSCHAFTEN',\n",
       " 'LEIBNIZ INSTITUT F R ASTROPHYSIK',\n",
       " 'LEIBNIZ INSTITUT F R NATURSTOFF FORSCHUNG UND INFEKTIONSBIOLOGIE E V',\n",
       " 'LEIBNIZ INSTITUTE OF ATMOSPHERIC PHYSICS',\n",
       " 'LEIPFINGER BADER',\n",
       " 'LEIPZIG UNIVERSITY',\n",
       " 'LEXISNEXIS',\n",
       " 'LEXWARE',\n",
       " 'LGC AXOLABS',\n",
       " 'LIBRA',\n",
       " 'LIEBHERR',\n",
       " 'LIEBHERR HAUSGER TE OCHSENHAUSEN',\n",
       " 'LIEFERANDO',\n",
       " 'LIFE SCIENCE NORD',\n",
       " 'LILT',\n",
       " 'LINDNER',\n",
       " 'LIPOTYPE',\n",
       " 'LLOYDS BANK',\n",
       " 'LOGIC HIRE SOLUTIONS LTD',\n",
       " 'LONZA',\n",
       " 'LOTUM',\n",
       " 'LUFTHANSA TECHNIK',\n",
       " 'LUMINARY',\n",
       " 'LUMINO',\n",
       " 'LUNIT',\n",
       " 'M M SOFTWARE',\n",
       " 'M NCHEN',\n",
       " 'MACHINE LEARNING REPLY',\n",
       " 'MAINGAU ENERGIE',\n",
       " 'MAINWEBSOLUTIONS',\n",
       " 'MAKERSITE',\n",
       " 'MAM',\n",
       " 'MAN TRUCK   BUS',\n",
       " 'MARC O POLO',\n",
       " 'MARKANT',\n",
       " 'MARKT PILOT',\n",
       " 'MASENT',\n",
       " 'MASTERSCHOOL',\n",
       " 'MATERNA INFORMATION   COMMUNICATIONS',\n",
       " 'MAX PLANCK COMPUTING AND DATA FACILITY  MPCDF',\n",
       " 'MAX PLANCK DIGITAL LIBRARY',\n",
       " 'MAX PLANCK INSTITUT F R BIOLOGIE T BINGEN',\n",
       " 'MAX PLANCK INSTITUT F R KOLLOID  UND',\n",
       " 'MAX PLANCK INSTITUT F R METEOROLOGIE',\n",
       " 'MAX PLANCK INSTITUTE FOR CHEMICAL ENERGY CONVERSION',\n",
       " 'MBIOMICS',\n",
       " 'MECHANICS OF MATERIALS',\n",
       " 'MED EL MEDICAL ELECTRONICS',\n",
       " 'MEDIAPLUS',\n",
       " 'MEDIFOX DAN',\n",
       " 'MEDISYNC AI',\n",
       " 'MEDPACE',\n",
       " 'MEDSCAPE',\n",
       " 'MEINESTADT DE',\n",
       " 'MELCHERS',\n",
       " 'MELOTECH',\n",
       " 'MENDEL VERLAG   CO KG',\n",
       " 'MERANTIX CAPITAL',\n",
       " 'MERCEDES BENZ',\n",
       " 'MERCEDES BENZ TECH INNOVATION',\n",
       " 'MERCK',\n",
       " 'MERCK HEALTHCARE',\n",
       " 'MERZ THERAPEUTICS',\n",
       " 'META',\n",
       " 'MEYERTHOLE SIEMS KOHLRUSS GESELLSCHAFT F R',\n",
       " 'MHP   A PORSCHE COMPANY',\n",
       " 'MICE PORTAL',\n",
       " 'MICHAEL BAUER RESEARCH',\n",
       " 'MIDEA',\n",
       " 'MILLDENT',\n",
       " 'MILTENYI BIOTEC',\n",
       " 'MINDFUEL',\n",
       " 'MINDPEAK',\n",
       " 'ML6   YOUR PARTNER IN AI',\n",
       " 'MLL M NCHNER LEUK MIELABOR',\n",
       " 'MOBILAB SOLUTIONS',\n",
       " 'MONDEL Z INTERNATIONAL',\n",
       " 'MORPHEUS TALENT SOLUTIONS',\n",
       " 'MPA PHARMA',\n",
       " 'MPB',\n",
       " 'MSG SYSTEMS AG',\n",
       " 'MTU AERO ENGINES',\n",
       " 'MUNICH RE',\n",
       " 'MVGM',\n",
       " 'MVV TRADING',\n",
       " 'MVZ D SSELDORF CENTRUM GBR',\n",
       " 'MVZ MARTINSRIED',\n",
       " 'MYMUESLI',\n",
       " 'NANOGAMI',\n",
       " 'NATIF AI',\n",
       " 'NEBUMIND',\n",
       " 'NEEW VENTURES',\n",
       " 'NEOPREDICS',\n",
       " 'NEROU',\n",
       " 'NESTL',\n",
       " 'NET SERVICES S   R L',\n",
       " 'NETCONOMY',\n",
       " 'NETLIGHT',\n",
       " 'NETTREK',\n",
       " 'NEUEFISCHE',\n",
       " 'NEURAFLOW',\n",
       " 'NEW YORKER',\n",
       " 'NEXMART',\n",
       " 'NEXTCODER SOFTWAREENTWICKLUNGS UG',\n",
       " 'NEXWAFE',\n",
       " 'NIELSENIQ',\n",
       " 'NOKIA',\n",
       " 'NOMAD ATOMICS',\n",
       " 'NORCOM INFORMATION TECHNOLOGY   CO',\n",
       " 'NORDMANN  RASSMANN',\n",
       " 'NORGINE',\n",
       " 'NOVENTIVE   IP SECURELY PROTECTED',\n",
       " 'NOVO AI',\n",
       " 'NOWEDA APOTHEKERGENOSSENSCHAFT EG',\n",
       " 'NUCS AI',\n",
       " 'NUROMEDIA',\n",
       " 'NUVISAN',\n",
       " 'OBI   CO',\n",
       " 'OLX',\n",
       " 'OLYMPUS EMEA',\n",
       " 'OMIO',\n",
       " 'OMMAX',\n",
       " 'ONE   F VE',\n",
       " 'OPITZ CONSULTING',\n",
       " 'OPTRONICS  SYSTEM TECHNOLOGIES AND IMAGE',\n",
       " 'ORANGE CYBERDEFENSE',\n",
       " 'ORANGE QUARTER',\n",
       " 'ORBEM',\n",
       " 'OSMA',\n",
       " 'OTTO  GMBH',\n",
       " 'OTTO DATA WORKS',\n",
       " 'OUTDOORACTIVE',\n",
       " 'OUTFITTERY',\n",
       " 'OXG GLASFASER',\n",
       " 'OYAK ANKER BANK',\n",
       " 'P UR   TELE COLUMBUS',\n",
       " 'PACEMAKER',\n",
       " 'PAIQO',\n",
       " 'PAIR FINANCE',\n",
       " 'PARCIT',\n",
       " 'PARETOS',\n",
       " 'PARI FIRMENGRUPPE',\n",
       " 'PARKER B ASSOCIATES',\n",
       " 'PARSHIPMEET',\n",
       " 'PARTEX',\n",
       " 'PARTSPACE',\n",
       " 'PASS APP',\n",
       " 'PAUL HARTMANN',\n",
       " 'PAYBACK',\n",
       " 'PAYMENTTOOLS',\n",
       " 'PEEK CLOPPENBURG',\n",
       " 'PERTO',\n",
       " 'PEXON CONSULTING',\n",
       " 'PFIZER',\n",
       " 'PFLEGEWEGWEISER',\n",
       " 'PHOENIX MEDICAL',\n",
       " 'PIMCO PRIME REAL ESTATE',\n",
       " 'PIVOT SEARCH',\n",
       " 'PIVOTAL',\n",
       " 'PLAN D',\n",
       " 'PLANET A FOODS',\n",
       " 'PMONE',\n",
       " 'POLARANALYTICS',\n",
       " 'POLYTEIA',\n",
       " 'PORSCHE CONSULTING',\n",
       " 'POWERCO',\n",
       " 'PREDIUM TECHNOLOGY',\n",
       " 'PRENODE',\n",
       " 'PREVENTIO',\n",
       " 'PRIMAL STATE PERFORMANCE',\n",
       " 'PROCESSAND',\n",
       " 'PROCREDIT',\n",
       " 'PROCTER   GAMBLE',\n",
       " 'PROFESSIONAL SCIENTISTS',\n",
       " 'PROJECT A',\n",
       " 'PROJEKTTR GER J LICH  PTJ',\n",
       " 'PROLYTIC',\n",
       " 'PROPERTY FINDER',\n",
       " 'PROSIEBENSAT 1 TECH   SERVICES',\n",
       " 'PROTECTION ONE',\n",
       " 'PROTEROS BIOSTRUCTURES',\n",
       " 'PROVIDE',\n",
       " 'PSI SOFTWARE',\n",
       " 'PUBLICIS MEDIA GERMANY',\n",
       " 'PULS',\n",
       " 'PWC GERMANY',\n",
       " 'Q ENERGY',\n",
       " 'QIMIA',\n",
       " 'QPLIX',\n",
       " 'QRUISE',\n",
       " 'QUANTAGONIA',\n",
       " 'QUANTISTRY',\n",
       " 'QUANTUMBLACK  AI BY MCKINSEY',\n",
       " 'QUODATA',\n",
       " 'QUOTACOM',\n",
       " 'R V ALLGEMEINE VERSICHERUNG',\n",
       " 'RABOT ENERGY',\n",
       " 'RAILPOOL',\n",
       " 'RATBACHER',\n",
       " 'RATEPAY',\n",
       " 'RAUSGEGANGEN',\n",
       " 'RAZOR',\n",
       " 'RE7 CAPITAL',\n",
       " 'RECHENZENTRUM DER FINANZVERWALTUNG DES LANDES NORDRHEIN WESTFALEN',\n",
       " 'REMATIQ',\n",
       " 'REMOBI',\n",
       " 'REPLY',\n",
       " 'REVENUECAT',\n",
       " 'REWE',\n",
       " 'REWE DIGITAL',\n",
       " 'REWIRE',\n",
       " 'RHEINDATA',\n",
       " 'RHEINISCHE POST MEDIEN',\n",
       " 'RHEINMETALL AVIATION SERVICES',\n",
       " 'RHEINMETALL ELECTRONICS',\n",
       " 'RHEINMETALL TECHNOLOGY CENTER',\n",
       " 'RHESIS AI',\n",
       " 'RISK IDENT',\n",
       " 'RISK RESEARCH',\n",
       " 'RISK SOLUTIONS',\n",
       " 'RITTER',\n",
       " 'RIVERTY',\n",
       " 'RJC',\n",
       " 'RMS  DER AUDIOVERMARKTER',\n",
       " 'ROBOMINDS',\n",
       " 'ROBOTRON DATENBANK SOFTWARE',\n",
       " 'ROCHE',\n",
       " 'ROHDE   SCHWARZ',\n",
       " 'ROLAND RECHTSSCHUTZ VERSICHERUNGS AG',\n",
       " 'ROOMPRICEGENIE',\n",
       " 'ROOSI',\n",
       " 'ROSENXT',\n",
       " 'RSIGHT',\n",
       " 'RWTH AACHEN',\n",
       " 'RWTH AACHEN UNIVERSITY',\n",
       " 'S DKURIER MEDIENHAUS',\n",
       " 'S PAYMENT   EIN UNTERNEHMEN DER DSV GRUPPE',\n",
       " 'SACHCONTROL',\n",
       " 'SAFEAD',\n",
       " 'SAFEDRIVER',\n",
       " 'SANOFI',\n",
       " 'SAP',\n",
       " 'SAP FIONEER',\n",
       " 'SCALEFREE',\n",
       " 'SCALEUP AGENCY',\n",
       " 'SCHEER',\n",
       " 'SCHICKLER UNTERNEHMENSBERATUNG',\n",
       " 'SCHLUCHSEEWERK AKTIENGESELLSCHAFT',\n",
       " 'SCHMITT ENGINEERING',\n",
       " 'SCHOTT',\n",
       " 'SCHWARM TECHNOLOGIES INC',\n",
       " 'SCIENEERS',\n",
       " 'SECA SERVICES',\n",
       " 'SEER INC',\n",
       " 'SELLERX',\n",
       " 'SENACOR TECHNOLOGIES',\n",
       " 'SENTIENT FOUNDATION',\n",
       " 'SEVDESK',\n",
       " 'SHOPIFY',\n",
       " 'SIEGWERK DRUCKFARBEN   CO',\n",
       " 'SII',\n",
       " 'SIKWEL',\n",
       " 'SIMPLY X',\n",
       " 'SINTEC INFORMATIK',\n",
       " 'SKELETON TECHNOLOGIES',\n",
       " 'SKILL FARM',\n",
       " 'SKILLS ALLIANCE',\n",
       " 'SKILLSPARK AB',\n",
       " 'SKM',\n",
       " 'SKOPOS',\n",
       " 'SLAY',\n",
       " 'SMA DEVELOPMENT',\n",
       " 'SMARTLAB INNOVATIONSGESELLSCHAFT MBH',\n",
       " 'SOCIAL MATCH   WE ARE HIRING',\n",
       " 'SOCIETE GENERALE',\n",
       " 'SOFTSERVE',\n",
       " 'SOKA BAU',\n",
       " 'SOLERA',\n",
       " 'SOLUTE GMBH',\n",
       " 'SONO MOTORS',\n",
       " 'SOPRA STERIA',\n",
       " 'SOURCE INTERNATIONAL',\n",
       " 'SPARKASSE BREMEN',\n",
       " 'SPARKASSEN RATING UND RISIKOSYSTEME',\n",
       " 'SPHERA',\n",
       " 'SR2   SOCIALLY RESPONSIBLE RECRUITMENT   CERTIFIED B CORPORATION',\n",
       " 'ST DTISCHES KLINIKUM KARLSRUHE GGMBH',\n",
       " 'STABURO',\n",
       " 'STADLER SIGNALLING',\n",
       " 'STADT K LN',\n",
       " 'STADTSPARKASSE GLADBECK',\n",
       " 'STADTWERKE VERKEHRSGESELLSCHAFT FRANKFURT AM MAIN',\n",
       " 'STARKFLOW',\n",
       " 'STATISTA',\n",
       " 'STATWORX',\n",
       " 'STEADFORCE',\n",
       " 'STENON',\n",
       " 'STHREE',\n",
       " 'STI',\n",
       " 'STIMME MEDIENGRUPPE',\n",
       " 'STORYBLOK',\n",
       " 'STRATEGION',\n",
       " 'STRATIV',\n",
       " 'STRIVENEST',\n",
       " 'STUDYFLIX',\n",
       " 'STYLINK SOCIAL MEDIA',\n",
       " 'SUPER AI',\n",
       " 'SURGE',\n",
       " 'SVA SYSTEM VERTRIEB ALEXANDER',\n",
       " 'SWISS RE',\n",
       " 'SWK ENERGIE',\n",
       " 'SYNAMIC TECHNOLOGIES UG',\n",
       " 'SYNGENTA',\n",
       " 'T V S D',\n",
       " 'TABLE BRIEFINGS',\n",
       " 'TACTO',\n",
       " 'TAOD CONSULTING',\n",
       " 'TARGOBANK',\n",
       " 'TARGOMO',\n",
       " 'TCHIBO',\n",
       " 'TEAMVIEWER',\n",
       " 'TECALLIANCE',\n",
       " 'TECAN SOFTWARE COMPETENCE CENTER',\n",
       " 'TECAN TRADING',\n",
       " 'TECHNIKER KRANKENKASSE',\n",
       " 'TECHNISCHE INFORMATIONSBIBLIOTHEK  TIB',\n",
       " 'TECHNISCHE UNIVERSIT T CLAUSTHAL',\n",
       " 'TECHNISCHE UNIVERSIT T ILMENAU',\n",
       " 'TECHNOLOGY   STRATEGY',\n",
       " 'TECKENTRUP',\n",
       " 'TELUS DIGITAL',\n",
       " 'TEMU',\n",
       " 'TENTHPIN',\n",
       " 'TERAKI',\n",
       " 'TERRITORY MEDIA',\n",
       " 'TESLA',\n",
       " 'TESLA AUTOMATION',\n",
       " 'TETHER IO',\n",
       " 'TETRASCIENCE',\n",
       " 'THE CREATIVE CLUB',\n",
       " 'THE PRODUCT GUYS',\n",
       " 'THEION',\n",
       " 'THEO F RCH',\n",
       " 'THERMO FISHER SCIENTIFIC',\n",
       " 'THINKRED WEST',\n",
       " 'THOMANN IO',\n",
       " 'THRYVE',\n",
       " 'THYSSENGAS',\n",
       " 'THYSSENKRUPP',\n",
       " 'TIETALENT',\n",
       " 'TINYBIRD',\n",
       " 'TMM',\n",
       " 'TOMORROW UNIVERSITY OF APPLIED SCIENCES',\n",
       " 'TOOZ TECHNOLOGIES',\n",
       " 'TOP TECHNOLOGIES CONSULTING',\n",
       " 'TOURLANE',\n",
       " 'TRAKKEN',\n",
       " 'TRANS O FLEX',\n",
       " 'TRANSNETBW',\n",
       " 'TRANSPARENT HIRING',\n",
       " 'TRELLEBORG SEALING SOLUTIONS GERMANY',\n",
       " 'TRIATHLON',\n",
       " 'TRINETX',\n",
       " 'TRIS TECHNOLOGY',\n",
       " 'TRIVAGO',\n",
       " 'TRKKN',\n",
       " 'TRON',\n",
       " 'TRUEMETRICS',\n",
       " 'TRUST IN SODA',\n",
       " 'TRUST WALLET',\n",
       " 'TRUSTEQ',\n",
       " 'TWOMYNDS',\n",
       " 'UCANEO',\n",
       " 'UCG UNITED CONSULTING',\n",
       " 'UELZENER ALLGEMEINE VERSICHERUNGS GESELLSCHAFT',\n",
       " 'UKSH',\n",
       " 'UNION INVESTMENT',\n",
       " 'UNITY CONSULTING   INNOVATION',\n",
       " 'UNIVERSIT TSKLINIKUM M NSTER',\n",
       " 'UNIVERSIT TSKLINIKUM W RZBURG',\n",
       " 'UNIVERSITY HOSPITAL SCHLESWIG HOLSTEIN  UKSH',\n",
       " 'UNIVERSITY OF BAYREUTH',\n",
       " 'UNIVERSITY OF HAMBURG',\n",
       " 'UNTERNEHMENSGRUPPE THEO M LLER',\n",
       " 'UPVEST',\n",
       " 'US COMMANDER  NAVAL INFORMATION WARFARE SYSTEMS',\n",
       " 'UTILIGENCE',\n",
       " 'V RIDION',\n",
       " 'VAILLANT BUSINESS SERVICES',\n",
       " 'VAISTO SOLUTIONS',\n",
       " 'VALANTIC DIGITAL FINANCE',\n",
       " 'VALANTIC SOFTWARE   TECHNOLOGY INNOVATIONS',\n",
       " 'VALUEWORKS AI',\n",
       " 'VALUEZON',\n",
       " 'VANGUARD AUTOMATION',\n",
       " 'VARTA MICRO PRODUCTION',\n",
       " 'VAY',\n",
       " 'VBN',\n",
       " 'VENT IO',\n",
       " 'VERVE',\n",
       " 'VHV',\n",
       " 'VIDLAB7',\n",
       " 'VIGENERON',\n",
       " 'VIMATEC',\n",
       " 'VINTED',\n",
       " 'VIRTUAL7',\n",
       " 'VISA',\n",
       " 'VISIONAI',\n",
       " 'VIVID MONEY',\n",
       " 'VKB',\n",
       " 'VLS VERSICHERUNGSLOGISTIK',\n",
       " 'VOLKSWOHL BUND LEBENSVERSICHERUNG',\n",
       " 'VOLLCOM DIGITAL',\n",
       " 'VP VERBUND PFLEGEHILFE',\n",
       " 'VTG',\n",
       " 'W RTTEMBERGISCHE VERSICHERUNG AKTIENGESELLSCHAFT',\n",
       " 'WACKER CHEMIE',\n",
       " 'WARGAMING',\n",
       " 'WAVE MOBILE MONEY',\n",
       " 'WDR',\n",
       " 'WEBER',\n",
       " 'WEGO SYSTEMBAUSTOFFE',\n",
       " 'WEMOLO',\n",
       " 'WENTRONIC',\n",
       " 'WESORT AI',\n",
       " 'WIBU',\n",
       " 'WIRTSCHAFTSRAT DER CDU E V',\n",
       " 'WITH LOVE AND DATA',\n",
       " 'WM',\n",
       " 'WOLT',\n",
       " 'WOOGA',\n",
       " 'WORKAROUND',\n",
       " 'WORKIDENTITY',\n",
       " 'WORLD FOOD PROGRAMME',\n",
       " 'XIBIX SOLUTIONS',\n",
       " 'XPENG',\n",
       " 'XPLAIN DATA',\n",
       " 'XSOLLA',\n",
       " 'YEAH  GLOBAL',\n",
       " 'YO IT CONSULTING',\n",
       " 'YUKAWA EXPONENTIAL',\n",
       " 'ZABEL',\n",
       " 'ZALANDO',\n",
       " 'ZANDER LABS',\n",
       " 'ZATTOO',\n",
       " 'ZAUBAR',\n",
       " 'ZEAL NETWORK',\n",
       " 'ZEISS',\n",
       " 'ZEIT VERLAGSGRUPPE',\n",
       " 'ZENDR',\n",
       " 'ZENJOB',\n",
       " 'ZERO TO ONE SEARCH   RECRUITMENT AGENCY',\n",
       " 'ZERTIFICON',\n",
       " 'ZURICH INSURANCE',\n",
       " 'ZVOOVE']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check unique list again\n",
    "np.sort(df[\"company_clean_ish\"].unique()).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate company names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_clean_ish\n",
       "1 1 MAIL   MEDIA APPLICATIONS                          1&1 Mail & Media Applications SE\n",
       "1KOMMA5                                                                        1KOMMA5°\n",
       "1KOMMA6   MULTIMEDIALE DIENSTLEISTUNGEN    1komma6 - Multimediale Dienstleistungen GmbH\n",
       "1X2 TECHNOLOGIES                                                  1x2 Technologies GmbH\n",
       "4 SCREEN                                                                        4screen\n",
       "                                                               ...                     \n",
       "ZENJOB                                                                           ZENJOB\n",
       "ZERO TO ONE SEARCH   RECRUITMENT AGENCY         Zero to One Search | Recruitment Agency\n",
       "ZERTIFICON                                                    Zertificon Solutions GmbH\n",
       "ZURICH INSURANCE                                                       Zurich Insurance\n",
       "ZVOOVE                                                                           zvoove\n",
       "Name: company, Length: 972, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group data by cleaned(-ish) company names, save first occurance of value in the original company name column.\n",
    "company_cleaning_df = df[[\"company\", \"company_clean_ish\"]].groupby(\"company_clean_ish\", as_index=False).agg({\"company\": \"first\"})\n",
    "company_cleaning_series = company_cleaning_df[\"company\"]\n",
    "company_cleaning_series.index = company_cleaning_df[\"company_clean_ish\"]\n",
    "company_cleaning_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>company_clean_ish</th>\n",
       "      <th>company_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Visa</td>\n",
       "      <td>VISA</td>\n",
       "      <td>Visa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xsolla</td>\n",
       "      <td>XSOLLA</td>\n",
       "      <td>Xsolla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global Market Solutions - Germany</td>\n",
       "      <td>GLOBAL MARKET SOLUTIONS   GERMANY</td>\n",
       "      <td>Global Market Solutions - Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MeloTech</td>\n",
       "      <td>MELOTECH</td>\n",
       "      <td>MeloTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vent.io</td>\n",
       "      <td>VENT IO</td>\n",
       "      <td>vent.io</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>VidLab7 GmbH</td>\n",
       "      <td>VIDLAB7</td>\n",
       "      <td>VidLab7 GmbH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>Planet A Foods GmbH</td>\n",
       "      <td>PLANET A FOODS</td>\n",
       "      <td>Planet A Foods GmbH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>Lipotype GmbH</td>\n",
       "      <td>LIPOTYPE</td>\n",
       "      <td>Lipotype GmbH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>Amfileon AG</td>\n",
       "      <td>AMFILEON</td>\n",
       "      <td>Amfileon AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>Workaround GmbH</td>\n",
       "      <td>WORKAROUND</td>\n",
       "      <td>Workaround GmbH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1625 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                company                  company_clean_ish   \n",
       "0                                  Visa                               VISA  \\\n",
       "1                                Xsolla                             XSOLLA   \n",
       "2     Global Market Solutions - Germany  GLOBAL MARKET SOLUTIONS   GERMANY   \n",
       "3                              MeloTech                           MELOTECH   \n",
       "4                               vent.io                            VENT IO   \n",
       "...                                 ...                                ...   \n",
       "1620                       VidLab7 GmbH                            VIDLAB7   \n",
       "1621                Planet A Foods GmbH                     PLANET A FOODS   \n",
       "1622                      Lipotype GmbH                           LIPOTYPE   \n",
       "1623                        Amfileon AG                           AMFILEON   \n",
       "1624                    Workaround GmbH                         WORKAROUND   \n",
       "\n",
       "                          company_clean  \n",
       "0                                  Visa  \n",
       "1                                Xsolla  \n",
       "2     Global Market Solutions - Germany  \n",
       "3                              MeloTech  \n",
       "4                               vent.io  \n",
       "...                                 ...  \n",
       "1620                       VidLab7 GmbH  \n",
       "1621                Planet A Foods GmbH  \n",
       "1622                      Lipotype GmbH  \n",
       "1623                        Amfileon AG  \n",
       "1624                    Workaround GmbH  \n",
       "\n",
       "[1625 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map original company name to all listings from the same company.\n",
    "df[\"company_clean\"] = df[\"company_clean_ish\"].map(company_cleaning_series)\n",
    "df.filter(like=\"company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>company_clean_ish</th>\n",
       "      <th>company_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HUK-COBURG</td>\n",
       "      <td>HUK COBURG</td>\n",
       "      <td>HUK-COBURG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>HUK-COBURG</td>\n",
       "      <td>HUK COBURG</td>\n",
       "      <td>HUK-COBURG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>HUK-COBURG</td>\n",
       "      <td>HUK COBURG</td>\n",
       "      <td>HUK-COBURG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>HUK-COBURG</td>\n",
       "      <td>HUK COBURG</td>\n",
       "      <td>HUK-COBURG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>HUK-COBURG</td>\n",
       "      <td>HUK COBURG</td>\n",
       "      <td>HUK-COBURG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>HUK-COBURG</td>\n",
       "      <td>HUK COBURG</td>\n",
       "      <td>HUK-COBURG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>HUK-COBURG Versicherungsgruppe</td>\n",
       "      <td>HUK COBURG</td>\n",
       "      <td>HUK-COBURG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>HUK-COBURG Versicherungsgruppe</td>\n",
       "      <td>HUK COBURG</td>\n",
       "      <td>HUK-COBURG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>HUK-COBURG Versicherungsgruppe</td>\n",
       "      <td>HUK COBURG</td>\n",
       "      <td>HUK-COBURG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>HUK-COBURG Versicherungsgruppe</td>\n",
       "      <td>HUK COBURG</td>\n",
       "      <td>HUK-COBURG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>HUK-COBURG Versicherungsgruppe</td>\n",
       "      <td>HUK COBURG</td>\n",
       "      <td>HUK-COBURG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>HUK-COBURG Versicherungsgruppe</td>\n",
       "      <td>HUK COBURG</td>\n",
       "      <td>HUK-COBURG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>HUK-COBURG Versicherungsgruppe</td>\n",
       "      <td>HUK COBURG</td>\n",
       "      <td>HUK-COBURG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             company company_clean_ish company_clean\n",
       "7                         HUK-COBURG        HUK COBURG    HUK-COBURG\n",
       "188                       HUK-COBURG        HUK COBURG    HUK-COBURG\n",
       "251                       HUK-COBURG        HUK COBURG    HUK-COBURG\n",
       "421                       HUK-COBURG        HUK COBURG    HUK-COBURG\n",
       "481                       HUK-COBURG        HUK COBURG    HUK-COBURG\n",
       "571                       HUK-COBURG        HUK COBURG    HUK-COBURG\n",
       "933   HUK-COBURG Versicherungsgruppe        HUK COBURG    HUK-COBURG\n",
       "987   HUK-COBURG Versicherungsgruppe        HUK COBURG    HUK-COBURG\n",
       "1014  HUK-COBURG Versicherungsgruppe        HUK COBURG    HUK-COBURG\n",
       "1050  HUK-COBURG Versicherungsgruppe        HUK COBURG    HUK-COBURG\n",
       "1360  HUK-COBURG Versicherungsgruppe        HUK COBURG    HUK-COBURG\n",
       "1392  HUK-COBURG Versicherungsgruppe        HUK COBURG    HUK-COBURG\n",
       "1394  HUK-COBURG Versicherungsgruppe        HUK COBURG    HUK-COBURG"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check result.\n",
    "df.loc[df[\"company_clean_ish\"].str.contains(\"HUK\"), [\"company\", \"company_clean_ish\", \"company_clean\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean titles first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Data Scientist (m/w/d)               48\n",
       "Senior Data Scientist (m/w/d)        20\n",
       "Senior Data Scientist                18\n",
       "Data Scientist (w/m/d)               18\n",
       "Data Scientist (all genders)         14\n",
       "                                     ..\n",
       "Data Engineer / Analyst               1\n",
       "Head of / VP - Data Experience        1\n",
       "Internship Program Autumn 2025        1\n",
       "Trainee Analytics Engineer            1\n",
       "Senior Regional Marketing Manager     1\n",
       "Name: count, Length: 1163, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"title\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove gender (non-)specification, e.g. (m/w/d), (m/f/d), (m/ f/ d), (gn),..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist ',\n",
       " 'Junior Data Scientist / AI Developer ',\n",
       " 'Junior Engineer Machine Learning / Deep Learning ',\n",
       " 'Data Scientist / ML Engineer ',\n",
       " 'Junior Data Scientist  - Tableau',\n",
       " 'Data Scientist ',\n",
       " 'Data Scientist in Energy Tech Start Up - hybrid Berlin based ',\n",
       " 'Battery Scientist ',\n",
       " 'AI&Business Analyst / Consultant (Remote Internship)',\n",
       " 'Data Scientist ']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define regular expression.\n",
    "my_regex = r\"\\(?\\s?\\w\\s?[/|,]\\s?\\w\\s?[/|,]\\s?\\w+\\s?\\)?\"\n",
    "# .         - include last character before match (likely a blank)\n",
    "# \\(?       - optional opening paranthesis (some note \"(m/w/d)\", some e.g. \"f/m/d\")\n",
    "# \\s?\\w\\s?  - word characters surrounded by optional spaces (e.g. \"(m / w / d)\")\n",
    "# [/|,]     - matches all present separators, e.g.: \"m|w|d\", \"f/m/d\", \"m,w,div\"\n",
    "# \\s?\\w+\\s? - additional '+' to match \"m/w/div\" at third position\n",
    "\n",
    "# Test regex:\n",
    "df.loc[df[\"title\"].str.find(\"/\") >= 0, \"title\"].str.replace(my_regex, \"\", regex=True).to_list()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply string replace\n",
    "df[\"title_clean\"] = df[\"title\"].str.replace(my_regex, \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>Machine Learning Engineer (LLM/RAG)</td>\n",
       "      <td>Machine Learning Engineer (LLM/RAG)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>Genomics Data Scientist (f/m/x)</td>\n",
       "      <td>Genomics Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Product Manager, DashOps (f/m/x)</td>\n",
       "      <td>Product Manager, DashOps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Working Student (part-time) or Internship (ful...</td>\n",
       "      <td>Working Student (part-time) or Internship (ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>SAP Inhouse (Senior) Consultant in Business An...</td>\n",
       "      <td>SAP Inhouse (Senior) Consultant in Business An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>Manufacturing Data Analyst @ Deltia (Remote wi...</td>\n",
       "      <td>Manufacturing Data Analyst @ Deltia (Remote wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>Big Data Architect (m/w/d)</td>\n",
       "      <td>Big Data Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>AI (Agent) Engineer (f/m/d) | Jobs at VisionAI...</td>\n",
       "      <td>AI (Agent) Engineer  | Jobs at VisionAI - Jobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>Product Analyst – Business Data &amp; Insights (m/...</td>\n",
       "      <td>Product Analyst – Business Data &amp; Insights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Bachelor of Science (m/w/d) Data Science und K...</td>\n",
       "      <td>Bachelor of Science  Data Science und Künstlic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title   \n",
       "1615                Machine Learning Engineer (LLM/RAG)  \\\n",
       "801                     Genomics Data Scientist (f/m/x)   \n",
       "146                    Product Manager, DashOps (f/m/x)   \n",
       "210   Working Student (part-time) or Internship (ful...   \n",
       "1552  SAP Inhouse (Senior) Consultant in Business An...   \n",
       "346   Manufacturing Data Analyst @ Deltia (Remote wi...   \n",
       "1544                         Big Data Architect (m/w/d)   \n",
       "1410  AI (Agent) Engineer (f/m/d) | Jobs at VisionAI...   \n",
       "679   Product Analyst – Business Data & Insights (m/...   \n",
       "120   Bachelor of Science (m/w/d) Data Science und K...   \n",
       "\n",
       "                                            title_clean  \n",
       "1615                Machine Learning Engineer (LLM/RAG)  \n",
       "801                            Genomics Data Scientist   \n",
       "146                           Product Manager, DashOps   \n",
       "210   Working Student (part-time) or Internship (ful...  \n",
       "1552  SAP Inhouse (Senior) Consultant in Business An...  \n",
       "346   Manufacturing Data Analyst @ Deltia (Remote wi...  \n",
       "1544                                Big Data Architect   \n",
       "1410     AI (Agent) Engineer  | Jobs at VisionAI - Jobs  \n",
       "679         Product Analyst – Business Data & Insights   \n",
       "120   Bachelor of Science  Data Science und Künstlic...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for additional spellings/specifications\n",
    "df.loc[df[\"title\"].str.contains(\"\\(|\\*\"), [\"title\", \"title_clean\"]].sample(10)\n",
    "# -> \" (all genders)\"; \"(aGw*)\"; \"(gn)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist (all gender)',\n",
       " 'Working Student AI/ML (all genders) - (Any location in Germany)',\n",
       " 'Working Student Data Science and Data Engineering (all genders!)',\n",
       " 'Data Scientist - Customer Data Platform (all genders)',\n",
       " 'Head of AI (all genders)',\n",
       " \"Aignostics' Talent Community\",\n",
       " 'GOglobal Trainee Data & AI (all genders)',\n",
       " 'Working Student PV Performance Engineering (all genders)',\n",
       " 'Strategy Manager Life Science (all genders)',\n",
       " 'Werkstudierende - Tutoring im Data Science (all genders)',\n",
       " 'Junior AI Platform Engineer or Working Student (all genders)',\n",
       " 'Data Scientist - Time Estimations, Logistics (all genders)',\n",
       " 'Working Student Aerospace Data Science (all genders)',\n",
       " '(Senior) BI Analyst (all genders)',\n",
       " 'Data Analyst (all gender) – Process Mining und Datenanalyse',\n",
       " 'Data Scientist  - Sektion für Hämatologische Spezialdiagnostik',\n",
       " 'DWH Analyst (all genders)',\n",
       " 'Data Analyst (all genders)',\n",
       " 'Trainee Data Engineering (all genders)',\n",
       " 'Head of Data (all genders)',\n",
       " 'Data Scientist (aGw*)',\n",
       " 'Data Scientist (all genders)',\n",
       " 'Research Assistant, Molecular Diagnostics ',\n",
       " 'Staff Data Scientist - Ad Tech (all genders)',\n",
       " 'Data Analyst Battery Cell Testing (all genders)',\n",
       " 'Senior Data Scientist - Time Estimations, Logistics (all genders)',\n",
       " 'BI Analyst (all genders)',\n",
       " 'Internship on Business and Data Analysis (all genders)',\n",
       " 'Software Engineer (Data & Python) (all genders)',\n",
       " 'AI Engineer // Data Scientist (all genders)',\n",
       " 'Senior Data Scientist, Campaigns',\n",
       " 'Data & AI Scientist Personalized Computational Genomics (all genders)',\n",
       " 'Internship Battery Analytics (all genders)',\n",
       " 'AI Platform Engineer (all genders)',\n",
       " 'Lead Data Scientist (all genders)',\n",
       " 'Werkstudent Data Science / Data Engineering (all genders)',\n",
       " 'Data Scientist (all genders)',\n",
       " 'Software & AI Engineer in Health (all genders)',\n",
       " 'Data Scientist (all genders)',\n",
       " 'Data Scientist (all genders)',\n",
       " 'Software Engineer - Machine Learning (all genders)',\n",
       " 'Data Scientist (all genders)',\n",
       " 'Innovation Cup 2025 - Team Neuroinspired AI inference acceleration (all genders)',\n",
       " 'Data Analysis Expert Battery Test Field (all genders)',\n",
       " 'Data Scientist (all genders)',\n",
       " '(Junior) Cloud Data Engineer (all genders)',\n",
       " 'Data Scientist (all genders)',\n",
       " 'Bench Scientist (all genders)',\n",
       " 'Masterprogramm Data Science & Business Analytics (all genders)',\n",
       " 'Innovation Cup 2025 - Team Drug Discovery (all genders)',\n",
       " 'Data Scientist (all genders)',\n",
       " 'Data Scientist (all genders)',\n",
       " 'Head of ML Platform & Developer Productivity (all genders)',\n",
       " 'Data Scientist (all genders)',\n",
       " 'Werkstudent/Praktikant im Bereich Data Science/Analytics & AI (all genders)',\n",
       " 'Werkstudent Analytics: Editorial Intelligence (gn)',\n",
       " 'Data Scientist (aGw*)',\n",
       " 'Data Scientist (all genders)',\n",
       " 'Lead Data Scientist (all genders)',\n",
       " 'Data Scientist  - Sektion für Hämatologische Spezialdiagnostik',\n",
       " 'Data Scientist (all gender)',\n",
       " 'AI Engineer // Data Scientist (all genders)',\n",
       " 'GOglobal Trainee Data & AI (all genders)',\n",
       " 'Data Engineer Big Data (all genders)',\n",
       " 'AI Engineer // Data Scientist (all genders)',\n",
       " 'Scientist / Study Director (all genders)',\n",
       " 'Research Scientist BIOCHEMISTRY/BIOPHYSICS (gn)',\n",
       " 'Research Scientist BIOPHYSICS WITH FOCUS PLATE-BASED ASSAYS (gn)',\n",
       " 'Senior Applied Scientist- Network Optimization (all genders)',\n",
       " 'Principal Applied Scientist - Network Optimization (all genders)',\n",
       " 'Senior Applied Scientist - Fulfilment Planning (all genders)',\n",
       " 'RESEARCH SCIENTIST (gn) PROTEIN CRYO-EM WITH PROJECT MANAGEMENT SKILLS',\n",
       " 'Postdoctoral Researcher (gn*)',\n",
       " 'Principal Applied Scientist - Payments (all genders)',\n",
       " 'Research Assistant/Associate  PhD students for \"Research and Development in the Field of Optical Flow Diagnostics\" (TME 129_241100)',\n",
       " 'Principal Applied Scientist - Transactions Risk Management (all genders)',\n",
       " 'Senior Data Scientist mit Schwerpunkt Ökonometrie/ Predictive Analytics (gn*)',\n",
       " 'Postdoctoral Scientist - Metabolomics Specialist for Drug Safety - all genders - (Fixed-term contract 24 months)',\n",
       " 'Postdoctoral Scientist / Researcher (all genders) in Relativistic High-Intensity Laser-Plasma Theory and Simulation',\n",
       " 'Research Assistant/Associate  PhD students for \"Research and Development in the Field of Combustion Systems with Optical Flow Diagnostics\" (TME 130_241100)',\n",
       " 'Postdoc (gn*)',\n",
       " 'Data Scientist (all genders)',\n",
       " 'Data Scientist (all genders)',\n",
       " 'Data Scientist - Customer Data Platform (all genders)',\n",
       " 'Staff Data Scientist - Ad Tech (all genders)',\n",
       " 'Senior Data Scientist - Time Estimations, Logistics (all genders)',\n",
       " 'Data Scientist / Engineer (gn)',\n",
       " 'Principal Research Scientist I (all genders) Medicinal Chemistry (permanent / full-time)',\n",
       " 'Principal Research Scientist I (all genders) Medicinal Chemistry (permanent / full-time)',\n",
       " 'Junior Data Scientist (all genders)',\n",
       " 'Data Scientist - Time Estimations, Logistics (all genders)',\n",
       " 'Scientist – Optical Design and Simulation',\n",
       " 'Data Scientist (all genders)',\n",
       " 'Senior Data Scientist mit Schwerpunkt Ökonometrie/ Predictive Analytics (gn*)',\n",
       " '(Senior) Data Scientist (gn) with Spanish language skills',\n",
       " '(Senior) Data Scientist (gn) Internationales Team',\n",
       " 'SAP Analytics Expert (gn*)',\n",
       " 'Wirtschaftsinformatiker für Demand Planning Diagnostics ',\n",
       " 'SAP Analytics Architect (gn*)',\n",
       " 'Senior Associate Quantitative Analyse (all genders)',\n",
       " 'Data Analyst Campaigning ',\n",
       " 'Engineering Manager - Applied Generative AI (all genders) @ Babbel | NGP Capital Job Board',\n",
       " 'Experte für Fahrzeug Telematikdaten und Datenanalysen (gn)',\n",
       " 'Senior Cloud Data Engineer (all genders)',\n",
       " '(Senior) Data Engineer (all genders)',\n",
       " 'Principal Research Scientist I (all genders) Medicinal Chemistry (permanent / full-time)',\n",
       " '(Senior) SAP Consultant (gn) Business Intelligence & Analytics',\n",
       " '(Senior) Data Engineer (all genders)',\n",
       " 'Senior Consultant / Solution Architect Data Management Manufacturing (all genders)',\n",
       " 'Senior Consultant / Solution Architect Data Management Manufacturing (all genders) 3',\n",
       " 'Senior Consultant / Solution Architect Data Management Manufacturing (all genders)']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"title_clean\"].str.contains(\"all gender|gn|aGw\", regex=True), \"title_clean\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist ',\n",
       " 'Working Student AI/ML  - (Any location in Germany)',\n",
       " 'Working Student Data Science and Data Engineering ',\n",
       " 'Data Scientist - Customer Data Platform ',\n",
       " 'Head of AI ',\n",
       " \"Aignostics' Talent Community\",\n",
       " 'GOglobal Trainee Data & AI ',\n",
       " 'Working Student PV Performance Engineering ',\n",
       " 'Strategy Manager Life Science ',\n",
       " 'Werkstudierende - Tutoring im Data Science ',\n",
       " 'Junior AI Platform Engineer or Working Student ',\n",
       " 'Data Scientist - Time Estimations, Logistics ',\n",
       " 'Working Student Aerospace Data Science ',\n",
       " '(Senior) BI Analyst ',\n",
       " 'Data Analyst  – Process Mining und Datenanalyse',\n",
       " 'Data Scientist  - Sektion für Hämatologische Spezialdiagnostik',\n",
       " 'DWH Analyst ',\n",
       " 'Data Analyst ',\n",
       " 'Trainee Data Engineering ',\n",
       " 'Head of Data ',\n",
       " 'Data Scientist ',\n",
       " 'Data Scientist ',\n",
       " 'Research Assistant, Molecular Diagnostics ',\n",
       " 'Staff Data Scientist - Ad Tech ',\n",
       " 'Data Analyst Battery Cell Testing ',\n",
       " 'Senior Data Scientist - Time Estimations, Logistics ',\n",
       " 'BI Analyst ',\n",
       " 'Internship on Business and Data Analysis ',\n",
       " 'Software Engineer (Data & Python) ',\n",
       " 'AI Engineer // Data Scientist ',\n",
       " 'Senior Data Scientist, Campaigns',\n",
       " 'Data & AI Scientist Personalized Computational Genomics ',\n",
       " 'Internship Battery Analytics ',\n",
       " 'AI Platform Engineer ',\n",
       " 'Lead Data Scientist ',\n",
       " 'Werkstudent Data Science / Data Engineering ',\n",
       " 'Data Scientist ',\n",
       " 'Software & AI Engineer in Health ',\n",
       " 'Data Scientist ',\n",
       " 'Data Scientist ',\n",
       " 'Software Engineer - Machine Learning ',\n",
       " 'Data Scientist ',\n",
       " 'Innovation Cup 2025 - Team Neuroinspired AI inference acceleration ',\n",
       " 'Data Analysis Expert Battery Test Field ',\n",
       " 'Data Scientist ',\n",
       " '(Junior) Cloud Data Engineer ',\n",
       " 'Data Scientist ',\n",
       " 'Bench Scientist ',\n",
       " 'Masterprogramm Data Science & Business Analytics ',\n",
       " 'Innovation Cup 2025 - Team Drug Discovery ',\n",
       " 'Data Scientist ',\n",
       " 'Data Scientist ',\n",
       " 'Head of ML Platform & Developer Productivity ',\n",
       " 'Data Scientist ',\n",
       " 'Werkstudent/Praktikant im Bereich Data Science/Analytics & AI ',\n",
       " 'Werkstudent Analytics: Editorial Intelligence ',\n",
       " 'Data Scientist ',\n",
       " 'Data Scientist ',\n",
       " 'Lead Data Scientist ',\n",
       " 'Data Scientist  - Sektion für Hämatologische Spezialdiagnostik',\n",
       " 'Data Scientist ',\n",
       " 'AI Engineer // Data Scientist ',\n",
       " 'GOglobal Trainee Data & AI ',\n",
       " 'Data Engineer Big Data ',\n",
       " 'AI Engineer // Data Scientist ',\n",
       " 'Scientist / Study Director ',\n",
       " 'Research Scientist BIOCHEMISTRY/BIOPHYSICS ',\n",
       " 'Research Scientist BIOPHYSICS WITH FOCUS PLATE-BASED ASSAYS ',\n",
       " 'Senior Applied Scientist- Network Optimization ',\n",
       " 'Principal Applied Scientist - Network Optimization ',\n",
       " 'Senior Applied Scientist - Fulfilment Planning ',\n",
       " 'RESEARCH SCIENTIST  PROTEIN CRYO-EM WITH PROJECT MANAGEMENT SKILLS',\n",
       " 'Postdoctoral Researcher ',\n",
       " 'Principal Applied Scientist - Payments ',\n",
       " 'Research Assistant/Associate  PhD students for \"Research and Development in the Field of Optical Flow Diagnostics\" (TME 129_241100)',\n",
       " 'Principal Applied Scientist - Transactions Risk Management ',\n",
       " 'Senior Data Scientist mit Schwerpunkt Ökonometrie/ Predictive Analytics ',\n",
       " 'Postdoctoral Scientist - Metabolomics Specialist for Drug Safety - all genders - (Fixed-term contract 24 months)',\n",
       " 'Postdoctoral Scientist / Researcher  in Relativistic High-Intensity Laser-Plasma Theory and Simulation',\n",
       " 'Research Assistant/Associate  PhD students for \"Research and Development in the Field of Combustion Systems with Optical Flow Diagnostics\" (TME 130_241100)',\n",
       " 'Postdoc ',\n",
       " 'Data Scientist ',\n",
       " 'Data Scientist ',\n",
       " 'Data Scientist - Customer Data Platform ',\n",
       " 'Staff Data Scientist - Ad Tech ',\n",
       " 'Senior Data Scientist - Time Estimations, Logistics ',\n",
       " 'Data Scientist / Engineer ',\n",
       " 'Principal Research Scientist I  Medicinal Chemistry (permanent / full-time)',\n",
       " 'Principal Research Scientist I  Medicinal Chemistry (permanent / full-time)',\n",
       " 'Junior Data Scientist ',\n",
       " 'Data Scientist - Time Estimations, Logistics ',\n",
       " 'Scientist – Optical Design and Simulation',\n",
       " 'Data Scientist ',\n",
       " 'Senior Data Scientist mit Schwerpunkt Ökonometrie/ Predictive Analytics ',\n",
       " '(Senior) Data Scientist  with Spanish language skills',\n",
       " '(Senior) Data Scientist  Internationales Team',\n",
       " 'SAP Analytics Expert ',\n",
       " 'Wirtschaftsinformatiker für Demand Planning Diagnostics ',\n",
       " 'SAP Analytics Architect ',\n",
       " 'Senior Associate Quantitative Analyse ',\n",
       " 'Data Analyst Campaigning ',\n",
       " 'Engineering Manager - Applied Generative AI  @ Babbel | NGP Capital Job Board',\n",
       " 'Experte für Fahrzeug Telematikdaten und Datenanalysen ',\n",
       " 'Senior Cloud Data Engineer ',\n",
       " '(Senior) Data Engineer ',\n",
       " 'Principal Research Scientist I  Medicinal Chemistry (permanent / full-time)',\n",
       " '(Senior) SAP Consultant  Business Intelligence & Analytics',\n",
       " '(Senior) Data Engineer ',\n",
       " 'Senior Consultant / Solution Architect Data Management Manufacturing ',\n",
       " 'Senior Consultant / Solution Architect Data Management Manufacturing  3',\n",
       " 'Senior Consultant / Solution Architect Data Management Manufacturing ']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and test regular expression\n",
    "my_regex2 = r\"\\((\\baGw.?|\\bgn.?|\\ball genders?.?)\\)\" # \"(gn)\", (gn*)\", \"(all gender)\", \"(all genders)\", \"(all genders!)\"\n",
    "df.loc[df[\"title_clean\"].str.contains(\"all gender|gn|aGw\", regex=True), \"title_clean\"].str.replace(my_regex2, \"\", regex=True).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply regex2\n",
    "df[\"title_clean\"] = df[\"title_clean\"].str.replace(my_regex2, \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear white space\n",
    "df[\"title_clean\"] = df[\"title_clean\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_clean\n",
       "Data Scientist                                                        115\n",
       "Senior Data Scientist                                                  59\n",
       "Data Analyst                                                           25\n",
       "Data Engineer                                                          21\n",
       "Machine Learning Engineer                                              17\n",
       "                                                                     ... \n",
       "Business Intelligence Engineer*                                         1\n",
       "Head of IoT                                                             1\n",
       "Working student software development                                    1\n",
       "Wissenschaftliche/r Mitarbeiter/in  | Thermomechanische Simulation      1\n",
       "Senior Regional Marketing Manager                                       1\n",
       "Name: count, Length: 1081, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"title_clean\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(Advanced) Data Developer',\n",
       " '(Associate) Consultant (Gen) AI & Data Scientist | AI Garage',\n",
       " '(Cloud) Data Engineer / BI Developer',\n",
       " '(Global) Senior Applied Research Scientist',\n",
       " '(Junior) AI Engineer',\n",
       " '(Junior) Berater Business Intelligence',\n",
       " '(Junior) Cloud Data Engineer',\n",
       " '(Junior) Consultant Data Analytics',\n",
       " '(Junior) Consultant Data Science & Artificial Intelligence',\n",
       " '(Junior) Consultant | Gen AI Finance',\n",
       " '(Junior) Data Analyst/ Business Analyst Procurement',\n",
       " '(Junior) Data Engineer',\n",
       " '(Junior) Data Product Associate',\n",
       " '(Junior) Data Scientist',\n",
       " '(Junior) Digital Produktmanager  AurumCars',\n",
       " '(Junior) Digital Produktmanager  Mietwagen',\n",
       " '(Junior) Digital Produktmanager  Payment Mietwagen',\n",
       " '(Junior) Online-Marketing Produktmanager  Mietwagen',\n",
       " '(Junior) Product Manager Financial Services',\n",
       " '(Junior) Produktmanager  Chatbot Mietwagen',\n",
       " '(Junior) Produktmanager  Operations Analytics Mietwagen',\n",
       " '(Junior) Produktmanager  SEO-Automatisierung Mietwagen',\n",
       " '(Junior) Produktmanager / Operationsmanager  Automatisierung Mietwagen',\n",
       " '(Junior) Specialist ESG Reporting',\n",
       " '(Junior) Technischer Produktmanager  Partnermanagement Mietwagen',\n",
       " '(Junior/Mid-level) Big Data Engineer',\n",
       " '(Sen.) Data Scientist',\n",
       " '(Senior) BI Analyst',\n",
       " '(Senior) Biochemist / Biopyhsicist',\n",
       " '(Senior) Business & Data Analyst',\n",
       " '(Senior) Business Analyst / Data Analyst',\n",
       " '(Senior) Consultant AI Specialist',\n",
       " '(Senior) Consultant Data Science & MLOp/m',\n",
       " '(Senior) Consultant Data Science Time-Series & Forecasting  (Data Scientist)',\n",
       " '(Senior) Consultant Data Strategy & Governance',\n",
       " '(Senior) Consultant Tech & AI Implementation',\n",
       " '(Senior) Data & AI PreSales Consultant',\n",
       " '(Senior) Data & Survey Engineer , Quantitative Marktforschung',\n",
       " '(Senior) Data Analyst',\n",
       " '(Senior) Data Analyst / Data Scientist  in Data Division',\n",
       " '(Senior) Data Analyst / Scientist',\n",
       " '(Senior) Data Engineer',\n",
       " '(Senior) Data Engineer  (Informatiker/in)',\n",
       " '(Senior) Data Engineer  | Jobs bei Pexon Consulting GmbH',\n",
       " '(Senior) Data Engineer / Data Warehouse Entwickler',\n",
       " '(Senior) Data Scientist',\n",
       " '(Senior) Data Scientist  Internationales Team',\n",
       " '(Senior) Data Scientist  in München',\n",
       " '(Senior) Data Scientist  with Spanish language skills',\n",
       " '(Senior) Data Scientist  – Schwerpunkt Predictive Modelling und GenAI (ab 01.04.25)',\n",
       " '(Senior) Data Scientist  – Schwerpunkt Predictive Modelling und GenAI ab 01.04.25',\n",
       " '(Senior) Data Scientist (Analytics), Merchant',\n",
       " '(Senior) Data Scientist - Document and Text Analytics',\n",
       " '(Senior) Data Scientist / ML Engineer',\n",
       " '(Senior) Data Scientist / Researcher',\n",
       " '(Senior) Data Scientist Analytics',\n",
       " '(Senior) Data Scientist Health Data Lab',\n",
       " '(Senior) Data Scientist with focus Clinical Statistics - part/full-time)',\n",
       " '(Senior) Data Scientist with focus SAS programming - part/full-time)',\n",
       " '(Senior) DevOps Data Integration Engineer',\n",
       " '(Senior) Fraud Data Scientist / Data Analyst',\n",
       " '(Senior) Machine Learning Data Scientist',\n",
       " '(Senior) Machine Learning Engineer',\n",
       " '(Senior) Process Analyst / Prozessberater  Reporting – SAP BW / BPC / Power BI / Tableau',\n",
       " '(Senior) SAP Consultant  Business Intelligence & Analytics',\n",
       " '(Senior) Scientist Primary Pharmacology of the Target Incubator Unit',\n",
       " '(Senior)Machine Learning Data Scientist',\n",
       " '(Senior-) Digital Transformation Engineer - Data Science',\n",
       " '(Senior-) Software Engineer',\n",
       " '(Wirtschafts-)Mathematiker, Statistiker, Data Scientist für die Tarifentwicklung Komposit',\n",
       " '1D/2D MATERIAL SCIENTIST',\n",
       " '2025 Applied Scientist Internship, Amazon University Talent Acquisition',\n",
       " '2025 Software Development Engineer - Machine Learning',\n",
       " '2025 Working Student Internship - Business Intelligence Engineer',\n",
       " 'ACTUARIAL DATA SCIENTIST',\n",
       " 'AI & Data - Analyst',\n",
       " 'AI (Agent) Engineer  | Jobs at VisionAI - Jobs',\n",
       " 'AI Architect & Optimization Specialist',\n",
       " 'AI Architect / Machine Learning Engineer',\n",
       " 'AI Cloud Engineer',\n",
       " 'AI Consultant',\n",
       " 'AI Developer',\n",
       " 'AI Engineer',\n",
       " 'AI Engineer (Intern)',\n",
       " 'AI Engineer (Senior)',\n",
       " 'AI Engineer - Germany (Remote)',\n",
       " 'AI Engineer / AI Developer  bei einem SaaS-Unternehmen aus Würzburg (Full-Remote oder vor Ort)',\n",
       " 'AI Engineer / Data Scientist',\n",
       " 'AI Engineer // Data Scientist',\n",
       " 'AI Engineer for AI Startup',\n",
       " 'AI Engineer mit Schwerpunkt NLP',\n",
       " 'AI Experience Researcher',\n",
       " 'AI Lead',\n",
       " 'AI Platform Engineer',\n",
       " 'AI Research Scientist - Generative AI Red Teaming (London or Paris)',\n",
       " 'AI Researcher',\n",
       " 'AI Software Developer in Test',\n",
       " 'AI Software Engineer',\n",
       " 'AI consultant  - Energy',\n",
       " 'AI&Business Analyst / Consultant (Remote Internship)',\n",
       " 'AI-Engineer/Vollzeit',\n",
       " 'AI/ML Engineer - Biomedical AI',\n",
       " 'AI\\xa0computational\\xa0\\xa0material\\xa0\\xa0researcher/expert',\n",
       " 'Abschlussarbeit im Bereich Datenstrategie und Künstliche Intelligenz',\n",
       " 'Abschlussarbeit im Bereich: KI basierte Generierung von Schiffsgeräuschen',\n",
       " 'Abschlussarbeit zum Thema: „Generative KI\"',\n",
       " 'Account Manager:in für Sound Branding, Podcasts und Audiospots',\n",
       " \"Aignostics' Talent Community\",\n",
       " 'Aktuar (DAV)/Data Scientist  - Krankenversicherungen & Data Warehouse',\n",
       " 'Analyst  Short Term Trading in Renewable Energies',\n",
       " 'Analyst & Marketing Technology Manager',\n",
       " 'Analyst - Fokus Data Science / AI',\n",
       " 'Analytics & Insights Internship',\n",
       " 'Analytics Engineer',\n",
       " 'Analytics Engineer  im Bereich Business Intelligence & Web Analytics',\n",
       " 'Analytics Engineer - Graduate (Hybrid;/d)',\n",
       " 'Analytics Engineering Lead',\n",
       " 'Analytics and Insight Professional, Amazon Advertising, Analytics and Insights',\n",
       " 'Applied Machine Learning Engineers',\n",
       " 'Applied Scientist II (L5), AFT AI, Amazon AFT AI',\n",
       " 'Applied Scientist for Probabilistic Machine Learning and Human-Computer Interaction',\n",
       " 'Applied Scientist, ATS Machine Learning & Engineering',\n",
       " 'Applied Scientist, Amazon Nova',\n",
       " 'Applied Scientist, Amazon Robotics R&D',\n",
       " 'Applied Scientist, Artificial General Intelligence, AGI Information',\n",
       " 'Applied Scientist, Content Systems Science and Engineering, Amazon',\n",
       " 'Applied Scientist, Fintech (Fraud)',\n",
       " 'Artificial Intelligence Engineer',\n",
       " 'Artificial Intelligence Specialist',\n",
       " 'Artificial Intelligence and Machine learning Business & Data Analyst',\n",
       " 'Assistant  Databases and Data Analysis',\n",
       " 'Associate - Index Operations',\n",
       " 'Associate / (Senior) AI Technology Consultant',\n",
       " 'Associate Data Analyst',\n",
       " 'Associate Data Science & Management Consultant',\n",
       " 'Associate Special Project, Esports',\n",
       " 'Atomic, Molecular, and Optical Physicist',\n",
       " 'BI & Data Modeling Expert',\n",
       " 'BI Analyst',\n",
       " 'BI Business Analyst',\n",
       " 'BI Manager  Data Science/Data Analytics',\n",
       " 'BI-Entwickler Trainee (Data Analyst / Data Engineer)',\n",
       " 'Bachelor  of Science - Data Science und Künstliche Intelligenz - Start 01.09.2025',\n",
       " 'Bachelor  of Science - Wirtschaftsinformatik - Data Science - Start 01.09.2025',\n",
       " 'Bachelor of Science  - Data Science und Künstliche Intelligenz ab 01.09.2025',\n",
       " 'Bachelor of Science  Data Science und Künstliche Intelligenz, Start 2025',\n",
       " 'Bachelor of Science  Data Science und Künstliche Intelligenz, Start 2026',\n",
       " 'Bachelor of Science (DHBW) Data Science / Künstliche Intelligenz  am Standort Winnenden 2025',\n",
       " 'Bachelor of Science (DHBW) Wirtschaftsinformatik - Data Science am Standort Obersontheim 2025',\n",
       " 'Bachelor-/Master Thesis »Full-field Thermo-mechanical Characterization of Glass Materials«',\n",
       " 'Bachelor/ Master Thesis: Methane leak localization from ambient data',\n",
       " 'Backend Developer',\n",
       " 'Backend Software Engineer - Remote',\n",
       " 'Backend/ML Software Engineer (Entry to Mid-Level) - Remote',\n",
       " 'Battery Scientist',\n",
       " 'Bench Scientist',\n",
       " 'Beschäftigte/r Qualitätsmanagement und Datenanalyse',\n",
       " 'Big Data Architect',\n",
       " 'Big Data DevOps Engineer  | (DSIDMG)',\n",
       " 'Bilanzmathematiker / Statistiker',\n",
       " 'Binance Accelarator Program - LLM Data Scientist',\n",
       " 'Bioinformatician',\n",
       " 'Bioinformatician  Immunogenetics',\n",
       " 'Bioinformatician  in immunopeptidomics',\n",
       " 'Bloomwell - Working Student Data & Analytics *',\n",
       " 'Breeding Informatics Analyst  Full Time - in Tübingen',\n",
       " 'Business  Development Manger',\n",
       " 'Business & Data Analyst',\n",
       " 'Business / Data Analyst',\n",
       " 'Business / Data Analyst  Real Estate Consulting Digitalisierungsberatung',\n",
       " 'Business Analyst',\n",
       " 'Business Analyst  - im Team Data Science Solutions',\n",
       " 'Business Analyst  – Data Analytics Vertriebsplanung | Banking',\n",
       " 'Business Analyst - Marketing Planning und Forecasting',\n",
       " 'Business Analyst / Controller',\n",
       " 'Business Analyst Data Management',\n",
       " 'Business Analyst Intern',\n",
       " 'Business Analyst – Data Quality',\n",
       " 'Business Data Analyst',\n",
       " 'Business Data Analyst  im LSZ - Qualität und Support, Referat Stab Reporting und Controlling',\n",
       " 'Business Data Analyst & Engineer',\n",
       " 'Business Intelligence & Analytics Manager',\n",
       " 'Business Intelligence / Data Analytics-& Management Consultant',\n",
       " 'Business Intelligence Analyst',\n",
       " 'Business Intelligence Analyst  mit Schwerpunkt Sales',\n",
       " 'Business Intelligence Consultant',\n",
       " 'Business Intelligence Developer  Tech / E-Commerce',\n",
       " 'Business Intelligence Developer * (Junior Level)',\n",
       " 'Business Intelligence Engineer',\n",
       " 'Business Intelligence Engineer (BIE), Supply Chain Outbound Execution',\n",
       " 'Business Intelligence Engineer*',\n",
       " 'Business Intelligence Engineer, Transportation, Global Transportation Services',\n",
       " 'Business Intelligence Engineer, WHS Data',\n",
       " 'Business Intelligence Expert F-35',\n",
       " 'Business Intelligence Manager',\n",
       " 'Business Intelligence Specialist',\n",
       " 'Business Intelligence Workshop',\n",
       " 'Business Intelligence und Data Analyst',\n",
       " 'Business Process Analyst – Marketing & Sales',\n",
       " 'Business Relationship Manager BI and Data Science',\n",
       " 'CO-Data Scientist',\n",
       " 'COMPUTATIONAL GENOMICS SCIENTIST , Referenz: „51004-24-05-WAPRO“',\n",
       " 'CRA/SCRA',\n",
       " 'CRM Data Specialist *',\n",
       " 'Carbon Project Risk Analyst',\n",
       " 'Certified Strength and Conditioning Specialist',\n",
       " 'Chemical Technical Assistant',\n",
       " 'Chief AI Engineer',\n",
       " 'Chief Commercial Officer - AI (Berlin)',\n",
       " 'Chief Data Officer',\n",
       " 'Chief Technology Officer',\n",
       " 'Chief Technology Officer - Must be based in Germany',\n",
       " 'Climate Risk Intern *',\n",
       " 'Cloud & Machine Learning Consultant',\n",
       " 'Cloud Big Data Engineer / DevOps Engineer',\n",
       " 'Cloud Engineer',\n",
       " 'Computational Biologist',\n",
       " 'Computational Chemist Lead',\n",
       " 'Computational Materials Scientist*',\n",
       " 'Computational Scientist – (Machine Learning) Digital R&D Large Molecule Research',\n",
       " 'Computer Scientist | InformatikerIn | Software EntwicklerIn für klinische KI-Forschung und Anwendung',\n",
       " 'Computer Scientist – Mendel Verlag',\n",
       " 'Computer Vision Engineer',\n",
       " 'Consultant  Energy, Environment & Telecommunication',\n",
       " 'Consultant - Digital Analytics  for Hamburg',\n",
       " 'Consultant AI & Analytics',\n",
       " 'Consultant AI & Data Analytics / Data Science',\n",
       " 'Consultant AI & Data Analytics / Data Science  in Berlin',\n",
       " 'Consultant AI & Data Analytics / Data Science  in Frankfurt (Main)',\n",
       " 'Consultant AI & Data Analytics / Data Science  in Hamburg',\n",
       " 'Consultant AI & Data Analytics / Data Science  in München',\n",
       " 'Consultant Data Science Credit Risk  in Berlin',\n",
       " 'Consultant Datamanagement & Data Analyst',\n",
       " 'Consultant Künstliche Intelligenz / Artificial Intelligence Energy',\n",
       " 'Consultant im Bereich Energy, Transformation & Sustainability',\n",
       " 'Consultant | Senior Consultant  Data Scientist in Credit Risk Management',\n",
       " 'Consulting & Analytics Summer Intern',\n",
       " 'Controlling & Analytics Trainee',\n",
       " 'Create a DataCamp Course - Cloud (Part-Time, Freelance)',\n",
       " 'Customer Data Consultant',\n",
       " 'DATA ANALYST',\n",
       " 'DATA ANALYST:IN',\n",
       " 'DATA ENGINEER',\n",
       " 'DATA SCIENCE MANAGER*',\n",
       " 'DATA SCIENTIST',\n",
       " 'DATA SCIENTIST  SMART PROCESS AUTOMATION',\n",
       " 'DATA SCIENTIST ENGINEER  DIGITAL SOLUTIONS – BRAUNSCHWEIG, BERLIN',\n",
       " 'DH-STUDIERENDE FÜR DATA SCIENCE & KÜNSTLICHE INTELLIGENZ 2025',\n",
       " 'DWH Analyst',\n",
       " 'DWH-Entwickler',\n",
       " 'Data & AI Business Consultant',\n",
       " 'Data & AI Scientist',\n",
       " 'Data & AI Scientist Personalized Computational Genomics',\n",
       " 'Data & AI Strategist',\n",
       " 'Data / Analytics Engineer',\n",
       " 'Data Analysis / Data Engineering / Data Science',\n",
       " 'Data Analysis Expert Battery Test Field',\n",
       " 'Data Analysis, Modeling & Simulation Engineer',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst  (Job-ID 2022099)',\n",
       " 'Data Analyst  / Remote möglich',\n",
       " 'Data Analyst  Berlin, Hamburg, Munich',\n",
       " 'Data Analyst  Search',\n",
       " 'Data Analyst  Telematikdaten',\n",
       " 'Data Analyst  at Allianz SE',\n",
       " 'Data Analyst  in IT security company',\n",
       " 'Data Analyst  – Process Mining und Datenanalyse',\n",
       " 'Data Analyst - MS Tech Stack',\n",
       " 'Data Analyst - Product',\n",
       " 'Data Analyst / Data Engineer',\n",
       " 'Data Analyst / Data Scientist',\n",
       " 'Data Analyst / Decision Scientist, Digital Marketing',\n",
       " 'Data Analyst / Decision Scientist, Policy',\n",
       " 'Data Analyst / Scientist  für die Energietransformation',\n",
       " 'Data Analyst / Scientist (Microsoft PowerBI und MS SQL Server)',\n",
       " 'Data Analyst Battery Cell Testing',\n",
       " 'Data Analyst Campaigning',\n",
       " 'Data Analyst bei Siemens',\n",
       " 'Data Analyst/Market Researcher',\n",
       " 'Data Analyst/Scientist  für die Energietransformation',\n",
       " 'Data Analyst:in Münster/Köln/Berlin/Remote (DE)',\n",
       " 'Data Analytics Architect',\n",
       " 'Data Analytics Consultant',\n",
       " 'Data Analytics Consultant Frontend',\n",
       " 'Data Analytics Engineer',\n",
       " 'Data Analytics Specialist',\n",
       " 'Data Analytics Training & Internship',\n",
       " 'Data Architect',\n",
       " 'Data Architect AI/ML  | Jobs bei Pexon Consulting GmbH',\n",
       " 'Data Architekt',\n",
       " 'Data Architekt / Data Engineer / Data Scientist',\n",
       " 'Data Assimilation Scientist',\n",
       " 'Data Consultant',\n",
       " 'Data Driven Business Consultant - Automotive',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer  Tech / E-Commerce',\n",
       " 'Data Engineer (English speaking)',\n",
       " 'Data Engineer - Recommendation Systeme',\n",
       " 'Data Engineer / Analyst',\n",
       " 'Data Engineer / Data Analyst',\n",
       " 'Data Engineer / Data Scientist',\n",
       " 'Data Engineer / Scientist',\n",
       " 'Data Engineer Big Data',\n",
       " 'Data Engineer Intern (Mandatory/Pflichtpraktikum)',\n",
       " 'Data Engineer Schwerpunkt Kundenpersonalisierung',\n",
       " 'Data Engineer* / Machine Learning Engineer*',\n",
       " 'Data Engineering Consultant',\n",
       " 'Data Engineering Internship  - Gigafactory Berlin-Brandenburg',\n",
       " 'Data Engineering Training & Internship',\n",
       " 'Data Engineering Working Student/Intern',\n",
       " 'Data Enthusiast',\n",
       " 'Data Integrity Specialist Pharma',\n",
       " 'Data Product Manager',\n",
       " 'Data Quality Manager',\n",
       " 'Data Reporting Analyst',\n",
       " 'Data Science & Engineering Lehrassistent:in (Pflichtpraktikum, Werkstudententätigkeit)',\n",
       " 'Data Science Analyst',\n",
       " 'Data Science Consultant',\n",
       " 'Data Science Consultant - QuantumBlack, AI by McKinsey',\n",
       " 'Data Science Graduate',\n",
       " 'Data Science Intern',\n",
       " 'Data Science Intern - Intelligence Automation (Remote)',\n",
       " 'Data Science Intern - Summer 2025, EMEA (Remote)',\n",
       " 'Data Science Lead - Credit Risk',\n",
       " 'Data Science and AI Mentor (Freelance, Remote)',\n",
       " 'Data Science und KI - Smart Operations Management',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist  (Data Scientist)',\n",
       " 'Data Scientist  (Job-ID 2023061)',\n",
       " 'Data Scientist  (Junior)',\n",
       " 'Data Scientist  - Schwerpunkt Customer Intelligence',\n",
       " 'Data Scientist  - Sektion für Hämatologische Spezialdiagnostik',\n",
       " 'Data Scientist  Short-Term Asset Trading',\n",
       " 'Data Scientist  Smart Process Automation',\n",
       " 'Data Scientist  in Hamburg | EPROFESSIONAL',\n",
       " 'Data Scientist  in den Bereichen NLP und LLM (Entwicklung/ Betrieb, Kompetenzaufbau und Support)',\n",
       " 'Data Scientist  mit Fokus auf Big Data und KI',\n",
       " 'Data Scientist  zur Auswertung und Analyse von komplexen Messdaten',\n",
       " 'Data Scientist & Machine Learning Engineer',\n",
       " 'Data Scientist (Growth Team)',\n",
       " 'Data Scientist (alle Geschlechter)',\n",
       " 'Data Scientist (jun. / sen.)',\n",
       " 'Data Scientist (mwd)',\n",
       " 'Data Scientist - 24 month contract',\n",
       " 'Data Scientist - Consumer (Global Discovery)',\n",
       " 'Data Scientist - Customer Data Platform',\n",
       " 'Data Scientist - Customer Success Projects (ValueWorks)',\n",
       " 'Data Scientist - Data Engineering',\n",
       " 'Data Scientist - Datenmanagement - AOK Bayern - Die Gesundheitskasse',\n",
       " 'Data Scientist - LLM',\n",
       " 'Data Scientist - Lexware Office',\n",
       " 'Data Scientist - Portfolio Analyst & Product Owner *',\n",
       " 'Data Scientist - Process Mining',\n",
       " 'Data Scientist - Ranking',\n",
       " 'Data Scientist - Startup Berlin',\n",
       " 'Data Scientist - Supply Chain & Procurement',\n",
       " 'Data Scientist - Time Estimations, Logistics',\n",
       " 'Data Scientist / AI Developer',\n",
       " 'Data Scientist / Analyst',\n",
       " 'Data Scientist / Biostatistician',\n",
       " 'Data Scientist / Data Analyst',\n",
       " 'Data Scientist / Data Engineer (Python)',\n",
       " 'Data Scientist / Engineer',\n",
       " 'Data Scientist / Engineer mit LLM-Fokus',\n",
       " 'Data Scientist / ML Engineer',\n",
       " 'Data Scientist / Machine Learning Expert',\n",
       " 'Data Scientist / Softwareentwickler',\n",
       " 'Data Scientist 100%',\n",
       " 'Data Scientist Automotive',\n",
       " 'Data Scientist Consultant',\n",
       " 'Data Scientist Datenmanagement',\n",
       " 'Data Scientist Digital Health ‒ Strategie, Analyse & Infrastruktur',\n",
       " 'Data Scientist Intern',\n",
       " 'Data Scientist Lead and Team Lead \"Customer Intelligence Team\"',\n",
       " 'Data Scientist NLP and Text Mining',\n",
       " 'Data Scientist Natural Language Processing',\n",
       " 'Data Scientist Online Analytics',\n",
       " 'Data Scientist Optical Spectroscopy',\n",
       " 'Data Scientist Pathologisches Institut',\n",
       " 'Data Scientist Trainee Life and Health Reinsurance, 1792',\n",
       " 'Data Scientist als Modellentwickler Einsatzplanung Energiesysteme',\n",
       " 'Data Scientist and Process Mining Architect',\n",
       " 'Data Scientist and Team Lead Property',\n",
       " 'Data Scientist für das Pathologische Institut',\n",
       " 'Data Scientist in Energy Tech Start Up - hybrid Berlin based',\n",
       " 'Data Scientist mit Fokus auf datengetriebenes Marketing',\n",
       " 'Data Scientist mit Schwerpunkt Datenarbeit',\n",
       " 'Data Scientist mit Schwerpunkt Operationalisierung',\n",
       " 'Data Scientist with focus Clinical Statistics - part/full-time)',\n",
       " 'Data Scientist – AI Engineer',\n",
       " 'Data Scientist – CRM / Kundenbeziehungsmanagement',\n",
       " 'Data Scientist – Supply & Demand Modelling',\n",
       " 'Data Scientist*in',\n",
       " 'Data Scientist*in  - remote oder Karlsruhe',\n",
       " 'Data Scientist*in/Data Analyst*in',\n",
       " 'Data Scientist, Germany - BCG X',\n",
       " 'Data Scientist, Internship, Germany - BCG X',\n",
       " 'Data Scientist, Mathematiker - Dateningenieur - AOK Bayern - Die Gesundheitskasse',\n",
       " 'Data Scientist/ AI-Architekt',\n",
       " 'Data Scientist/Analyst prüfungsnahe Beratung/Quants - Assurance (Financial Services)',\n",
       " 'Data Scientist/Bioinformatiker im Team Molekulargenetik',\n",
       " 'Data Scientist/ML Engineer',\n",
       " 'Data Solutions Specialist',\n",
       " 'Data Specialist',\n",
       " 'Data Steward SAP S/4HANA - \"Business Partner\"',\n",
       " 'Data Team Manager',\n",
       " 'Data and AI Director',\n",
       " 'Data and AI Partner',\n",
       " 'Data and AI/ML Engineer',\n",
       " 'Data and Reporting Analyst',\n",
       " 'Data-Analyst',\n",
       " 'Data-Scientist/MLOps - KI-basiertes Recycling',\n",
       " 'Data/Software Engineer',\n",
       " 'Datenanalyst',\n",
       " 'Datenanalyst  / Data Analyst',\n",
       " 'Datenanalyst  im Bereich Energiewirtschaft',\n",
       " 'Datenanalyst  im Vertriebsmanagement',\n",
       " 'Datenanalyst / Data Analyst Risikomanagement',\n",
       " 'Datenanalyst für Logistikprozesse',\n",
       " 'Datenanalyst:in Metering',\n",
       " 'Datenanalysten/in  für Modelle in der konjunkturstatistischen Erhebung im Gastgewerbe',\n",
       " 'Datenarchitekt Versicherungsplattform',\n",
       " 'Decision Scientist',\n",
       " 'Deep Learning Researcher',\n",
       " 'Detector Calibration and Characterisation Scientist',\n",
       " 'Deutsche Bank Graduate Programme  Technology, Data & Innovation 2025',\n",
       " 'DevOps & Cloud Engineer - Data Analytics & AI',\n",
       " 'DevOps/ML Engineer',\n",
       " 'Digital Data Scientist',\n",
       " 'Digital Marketing & Data Analytics Manager',\n",
       " 'Digital Trust and Safety Analyst with German',\n",
       " 'Director of AI Engineering',\n",
       " 'Director of Data Science',\n",
       " 'Director, Clinical Scientist',\n",
       " 'Doctoral Researcher Position in Materials Science',\n",
       " 'Doktorand für die Konzipierung und Implementierung von KI-gestützten Produktionssystemen',\n",
       " 'Doktorand:in – Untersuchung der Rolle zukünftiger Energietechnologien mit Hilfe von Natural Language Processing und Data Science',\n",
       " 'Dr. rer. nat. Physik / Chemie / Materialwissenschaften - Teamleitung & Projektmanagement',\n",
       " 'Duales Studium Bachelor of Science in Data Science und Künstlicher Intelligenz , ab 09/2025',\n",
       " 'Duales Studium – Data Science und Künstliche Intelligenz',\n",
       " 'E-Commerce Analyst & Marketing Support Manager (Kaufmann/-frau - E-Commerce)',\n",
       " 'EMEA - Solutions Engineer',\n",
       " 'ERP Business Analyst, Microsoft Business Central  Digital Development',\n",
       " 'ERP Business Analyst, SAP  Digital Development',\n",
       " 'ETL-Entwickler  Azure Data Factory',\n",
       " 'Economic Modeller / Contract Role  Full Remote',\n",
       " 'Electrical Engineer or Computer Scientist  in Technical Support / Automation Technology',\n",
       " 'Engagement Manager (Data & AI)',\n",
       " 'Engineer AI',\n",
       " 'Engineering Manager - Applied Generative AI  @ Babbel | NGP Capital Job Board',\n",
       " 'Enterprise Solutions Engineer, Germany',\n",
       " 'Experte für Fahrzeug Telematikdaten und Datenanalysen',\n",
       " 'Experte für Fahrzeug-Telematikdaten und Datenanalysen  - hybrides Arbeiten (Remote & Präsenz)',\n",
       " 'Fachkraft für den Bereich Einnahmeaufteilung & Statistik',\n",
       " 'Fachreferent/in für Künstliche Intelligenz A13/E13',\n",
       " 'Festanstellung im Bereich Data Analytics und Machine Learning für Datenanalyse-Startup in München',\n",
       " 'Field Application Scientist, EMEA',\n",
       " 'Financial Analyst - Intern (Remote Internship - Finance)',\n",
       " 'Financial Analyst Intern',\n",
       " 'Financial Data Specialist  Corporate Actions Shares & Funds',\n",
       " 'Financial Data Specialist  – Masterdata Shares / Funds',\n",
       " 'Financial Data Specialist – Bonds / Wertpapiere',\n",
       " 'Financial Engineer',\n",
       " 'Financial Engineer Expert',\n",
       " 'Forecasting Data Scientist SCM',\n",
       " 'Founding Software Engineer',\n",
       " 'Fraud Analyst',\n",
       " 'Fraud Fighter Wanted',\n",
       " 'Fraud Operations Specialist',\n",
       " 'Freelance Machine Learning Engineer',\n",
       " 'Full Stack Entwickler',\n",
       " 'Full-Stack Data Analyst',\n",
       " 'Full-Stack Data Analytics/Data Science Expert im Competence Center Digital Accelerator /x)',\n",
       " 'GOglobal Trainee Data & AI',\n",
       " 'GenAI-Developer/Data Scientist',\n",
       " 'Generative AI Engineer',\n",
       " 'Generative AI Explorer (Stable Diffusion, ControlNet...)',\n",
       " 'Generative Machine Learning Engineer',\n",
       " 'Genomics Data Scientist',\n",
       " 'Geospatial Data Scientist with focus on remote sensing',\n",
       " 'Gesundheitsökonom / Data Scientist im Gesundheitswesen',\n",
       " 'Global Engineer - Real World Evidence - Europe',\n",
       " 'Google Cloud AI/ML Consultant',\n",
       " 'Government Affairs Specialist',\n",
       " 'Gruppenleiter  Sach-Firmen SF - Strategie, Steuerung, Pricing und Produktmanagement für das Geschäftsfeld Sach-Firmen',\n",
       " 'HR Analytics Specialist',\n",
       " 'HR Business Partner',\n",
       " 'HR Data Analytics  - Gigafactory Berlin-Brandenburg',\n",
       " 'HYDROGEN TECHNOLOGY RESEARCH ENGINEER',\n",
       " 'Head Applied Data & Genetics Science – Seeds Field Crops Europe',\n",
       " 'Head of / VP - Data Experience',\n",
       " 'Head of AI',\n",
       " 'Head of AI Research & Development (100% remote - Munich)',\n",
       " 'Head of Artificial Intelligence',\n",
       " 'Head of Clinical Data Management & IT',\n",
       " 'Head of Data',\n",
       " 'Head of Data & Analytics',\n",
       " 'Head of Data & Analytics - Medical Cannabis Industry',\n",
       " 'Head of Data Science',\n",
       " 'Head of Data Science and AI',\n",
       " 'Head of IoT',\n",
       " 'Head of ML Platform & Developer Productivity',\n",
       " 'Head of R&D',\n",
       " 'Health Data Analyst*in',\n",
       " 'IIoT Research Developer – Young Professional',\n",
       " 'INTERDISCIPLINARY ENGINEER/SCIENTIST',\n",
       " 'IT Business Analyst for Research Labs',\n",
       " 'IT Business Analyst*in Data Warehouse & Business Intelligence (in Voll- oder Teilzeit)',\n",
       " 'IT Consultant - SAP Fiori / ABAP / User Experience / CDS Views',\n",
       " 'IT Consultant Energy',\n",
       " 'IT Consultant Energy & Utilities',\n",
       " 'IT Entwickler / Data Scientist  – Systembetrieb (befristet auf 2 Jahre)',\n",
       " 'IT Projektleiter / Projektmanager (mwd) DevOps',\n",
       " 'IT-Business / Data Analyst',\n",
       " 'Informatiker*in  für den Bereich High Performance Computing (HPC) / Infrastruktur',\n",
       " 'Information Security Management Consultant mit Schwerpunkt DORA',\n",
       " 'Ingenieur  technische Integritätsbewertung und Datenanalyse',\n",
       " 'Ingenieur / Data-Scientist',\n",
       " 'Inhouse Consultant - Schwerpunkt Datamanagement',\n",
       " 'Inhouse Consultant Master Data Management Kunde/Lieferant .)',\n",
       " 'Initiativbewerbung',\n",
       " 'Initiativbewerbung Data Science /BI',\n",
       " 'Initiativbewerbung Graduates Consulting @ MHP – A Porsche Company',\n",
       " 'Initiativbewerbung: Wissenschaftliche Mitarbeitende',\n",
       " 'Innovation Cup 2025 - Team Drug Discovery',\n",
       " 'Innovation Cup 2025 - Team Neuroinspired AI inference acceleration',\n",
       " 'Insights Analyst',\n",
       " 'Instrument Scientist (Gamma Rays and UV) in Astroparticle Physics',\n",
       " 'Intern  - Business Intelligence / Data Warehouse',\n",
       " 'Intern  - Data Science in a Smart Energy Startup',\n",
       " 'Intern - Global Data and Analytics',\n",
       " 'Intern AI-based Recommender Systems',\n",
       " 'Intern Artificial Intelligence *',\n",
       " 'Intern Business Analytics - Web & Commerce',\n",
       " 'Intern Consultant Data Science and AI *',\n",
       " 'Intern Data Science & AI',\n",
       " 'Intern Data Science - Digital Product Offering',\n",
       " 'Intern Data Science - Vehicle Testing Strategies',\n",
       " 'Intern Data Science - Web & Commerce Analytics',\n",
       " 'Intern Machine Learning & Computer Vision Engineer',\n",
       " 'Intern automation and computer vision in microscopy',\n",
       " 'Intern/WS - Product Data Science',\n",
       " 'Internationaler Datenanalyst / Projektassistenz Procurement Data Analyst  im internationalen Food und NON Food Einkauf',\n",
       " 'Interns Epidemic Risk Solutions *',\n",
       " 'Internship - Credit Risk Analyst',\n",
       " 'Internship - Investment Product Analyst',\n",
       " 'Internship AI engineer: Product driven research',\n",
       " 'Internship Battery Analytics',\n",
       " 'Internship Clinical Data Science with focus on Bayesian Statistics',\n",
       " 'Internship Data Analytics',\n",
       " 'Internship Data Science & Data Visualization',\n",
       " 'Internship Program Autumn 2025',\n",
       " 'Internship Program Summer 2025',\n",
       " 'Internship for Battery Data Analysis and Lab Automation',\n",
       " 'Internship in Customer Preferences & Vehicle Recommendations starting February/March 2025',\n",
       " 'Internship on Business and Data Analysis',\n",
       " 'Internship: Research & Insights   - Start: April 2025',\n",
       " 'Job Offer: Account Manager  * - Lipotype GmbH',\n",
       " 'Junior / Medior Model Validator – Credit Risk',\n",
       " 'Junior AI Platform Engineer or Working Student',\n",
       " 'Junior Aktuar / Data Scientist für das Pricing Aktuariat',\n",
       " 'Junior Aktuar/Actuarial Data Scientist Non-Motor Köln',\n",
       " 'Junior Blockchain Data Scientist',\n",
       " 'Junior Business Analyst Risikomanagement',\n",
       " 'Junior Business Intelligence Consultant',\n",
       " 'Junior Business Intelligence Engineer (All Genders)',\n",
       " 'Junior Clinical Research Associate',\n",
       " 'Junior Cloud Data Engineer  – Google Looker & BigQuery',\n",
       " 'Junior Cloud Engineer',\n",
       " 'Junior Consultant',\n",
       " 'Junior Consultant Big Data für Weltkonzern',\n",
       " 'Junior Consultant Business Intelligence',\n",
       " 'Junior Credit Analyst',\n",
       " 'Junior Data & Survey Engineer , Quantitative Marktforschung',\n",
       " 'Junior Data Engineer',\n",
       " 'Junior Data Scientist',\n",
       " 'Junior Data Scientist  - Tableau',\n",
       " 'Junior Data Scientist  Reise',\n",
       " 'Junior Data Scientist (Data Scientist)',\n",
       " 'Junior Data Scientist / AI Developer',\n",
       " 'Junior Data Scientist Controller',\n",
       " 'Junior Data Scientist Controller  [JR105592]',\n",
       " 'Junior Data-Scientist',\n",
       " 'Junior DevOps / Machine Learning Engineer',\n",
       " 'Junior Engineer Machine Learning / Deep Learning',\n",
       " 'Junior Integration Engineer // Data Engineer',\n",
       " 'Junior KI-Entwickler',\n",
       " 'Junior Machine Learning Engineer (Leipzig)',\n",
       " 'Junior Managers Program - Business Intelligence und Analytics - Trainee Program .)',\n",
       " 'Junior Managers Program - Business Intelligence und Analytics - Trainee programm .)',\n",
       " 'Junior Professor of Artificial Intelligence and Machine Learning',\n",
       " 'Junior Prozessmanager  InsurTech',\n",
       " 'Junior Quality Lab Scientist Microbiology',\n",
       " 'Junior Scientist (DEL), Bachelor/Master',\n",
       " 'Junior Scientist Machine Learning / Deep Learning',\n",
       " 'Junior Techno-Economic & Sustainability Analyst',\n",
       " 'KI Data Scientist',\n",
       " 'KI-Entwickler/in - Mitarbeiter/in Künstliche Intelligenz',\n",
       " 'Lab Working Student',\n",
       " 'Laboratory management',\n",
       " 'Lead AI Engineer (Cloud, Machine Learning)',\n",
       " 'Lead AI Engineer | Jobs at ES-Tec GmbH',\n",
       " 'Lead Consultant AI (Ref:IgLWy)',\n",
       " 'Lead Data Scientist',\n",
       " 'Lead Data Scientist (Deep Learning)',\n",
       " 'Lead Data Scientist NLP',\n",
       " 'Lead Data Scientist, Insurance - BCG X',\n",
       " 'Lead ML Engineer',\n",
       " 'Lead Machine Learning Engineer – Generative AI',\n",
       " 'Leitung  für den Sachbereich Personalmanagement und Zentralaufgaben',\n",
       " 'Life Scientist as Global Technical Support Specialist  French Speaking',\n",
       " 'MDM Developer  - Junior Data Engineer Stammdaten',\n",
       " 'ML / AI Engineer Intern',\n",
       " 'ML Architect Engineer',\n",
       " 'ML Engineer',\n",
       " 'ML Ops Engineer',\n",
       " 'ML Ops Engineer - Berlin',\n",
       " 'ML Software Engineer / Data Scientist',\n",
       " 'MLOps Engineer',\n",
       " 'MLOps Engineer  100% remote',\n",
       " 'MRI Scientist',\n",
       " 'MRI Working Student/Intern',\n",
       " 'Machine Learning / AI - Engineer  - Hybrid Working',\n",
       " 'Machine Learning Consultant',\n",
       " 'Machine Learning Engineer',\n",
       " 'Machine Learning Engineer (LLM/RAG)',\n",
       " 'Machine Learning Engineer (NLP)',\n",
       " 'Machine Learning Engineer (NLP) - Climate Tech',\n",
       " 'Machine Learning Engineer - Freelance',\n",
       " 'Machine Learning Engineer Autonomous Driving',\n",
       " 'Machine Learning Engineer, Applied AI',\n",
       " 'Machine Learning Engineer, Fraud Prevention',\n",
       " 'Machine Learning Engineer, Search',\n",
       " 'Machine Learning Lead',\n",
       " 'Machine Learning Platform Engineers',\n",
       " 'Machine Learning Software Developer (Karlsruhe)',\n",
       " 'Machine Learning Software Engineer – Optimization & LLM Development',\n",
       " 'Machine Learning Working Student - Hybrid',\n",
       " 'Machine Vision Engineer (Halcon)',\n",
       " 'Manufacturing Data Analyst',\n",
       " 'Manufacturing Data Analyst @ Deltia (Remote within Europe)',\n",
       " 'Market Researcher',\n",
       " 'Marketing Data Analyst',\n",
       " 'Marketing Researcher',\n",
       " 'Master Data Assistant',\n",
       " 'Master Data Operator (Schwerpunkt: Liquor, Tobacco & Confectionary)',\n",
       " 'Master Student Cryopreserved Natural Killer (NK) cell research',\n",
       " 'Master of Science (M.Sc.)  Start 2025 Location Berlin-Potsdam (VT/STAR)',\n",
       " 'Masterarbeit',\n",
       " 'Masterarbeit im Bereich Data Science und AI Development ab Januar 2025',\n",
       " 'Masterarbeit: Schnelleres Erkennen unbekannter Gegenstände unter Wasser dank Few Shot Learning',\n",
       " 'Masterprogramm Data Science & Business Analytics',\n",
       " 'Material Development Engineer, Formulation Scientist',\n",
       " 'Mathematiker:in / Physiker:in Aktuarielles Controlling',\n",
       " 'Medical Research Coordinator - MedTech Venture',\n",
       " 'Middleware Analyst / SAP Consultant PO/IS',\n",
       " 'Mitarbeiter Datenanalyse im HomeOffice',\n",
       " 'Mitarbeiter im Qualitätsmanagement  (Fachinformatiker/in - Daten- und Prozessanalyse)',\n",
       " 'Mitarbeiter/-in Projektmanagement digitaler Service / Datenanalyse',\n",
       " 'Mitarbeiterin/Mitarbeiter im Bereich Zahlen- und Datenanalyse',\n",
       " 'NGS Data Analyst for Molecular Oncology',\n",
       " 'NLP Engineer',\n",
       " 'Network Engineers',\n",
       " 'Off-Cycle Analyst Intern - Hamburg',\n",
       " 'Operations & Marketing Associate',\n",
       " 'PRAKTIKUM / PRAXISSEMESTER IM BEREICH DATA SCIENCE',\n",
       " 'Performance Engineer - Laundry Care',\n",
       " 'Pflichtpraktikum im eBusiness - Business Intelligence & Digital Analyst',\n",
       " 'PhD Candidate',\n",
       " 'PhD Candidate : Spatial Metabolomics',\n",
       " 'Physicist Dosimetry Expert',\n",
       " 'Planer*in  für das Sachgebiet -Räumliche Entwicklungsplanung- im Amt für Stadtentwicklung und Statistik',\n",
       " 'Portfolio Analyst',\n",
       " 'Post Doc - Data Science in Drug Discovery',\n",
       " 'PostDoc in \"A system-wide view of processes driving recent observed Southern Ocean change\"',\n",
       " 'PostDoc in atmospheric physics on deep learning / foundational modelling of clouds',\n",
       " 'Postdoc',\n",
       " 'Postdoc for the investigation of biomaterial structural properties',\n",
       " 'Postdoctoral Researcher',\n",
       " 'Postdoctoral Researcher  in Microbiome research',\n",
       " 'Postdoctoral Scientist - Metabolomics Specialist for Drug Safety - all genders - (Fixed-term contract 24 months)',\n",
       " 'Postdoctoral Scientist / Researcher  in Relativistic High-Intensity Laser-Plasma Theory and Simulation',\n",
       " 'Postdoctoral Scientist Chemistry Innovations for Oligonucleotide Delivery',\n",
       " 'Postdoctoral Scientist Position',\n",
       " 'Postdoctoral Scientist for Artificial Intelligence in Oncology',\n",
       " 'Postdoctoral Scientist, Amazon Robotics',\n",
       " 'Postdoctoral scientist, Atmospheric global observing system simulations',\n",
       " 'Postdoctoral | Research Scientist (W-0032)',\n",
       " 'Postdoctoral | Research Scientist (W-0033)',\n",
       " 'Postdoctural Scientist  for detector calibration and optimisation',\n",
       " 'Postdoktorand:in',\n",
       " 'Praktikant  Data Science',\n",
       " 'Praktikant Data Science/Data Analytics',\n",
       " 'Praktikant*in Data Engineer / Data Scientist Cloud Analytics',\n",
       " 'Praktikant:in  im Bereich Data Science und Prozesssoptimierung',\n",
       " 'Praktikum Data Analytics',\n",
       " 'Praktikum Data Science (Schwerpunkt Machine Learning)',\n",
       " 'Praktikum Data Science / Analytics',\n",
       " 'Praktikum Data Science im Bereich Preis-, Immobilienmarkt- und Konjunkturstatistiken',\n",
       " 'Praktikum Data Scientist im Produktkomplexitätsmanagement',\n",
       " 'Praktikum im Bereich Data Science / Data Analytics',\n",
       " 'Praktikum im Bereich Machine Learning Engineer ab Februar/März 2025',\n",
       " 'Praktikum: Data Science',\n",
       " 'Praktikum: Data Science und KI',\n",
       " 'Pre-Sales Consultant Datacenter - Süd  (Data-Consultant)',\n",
       " 'Pricing Actuary',\n",
       " 'Principal Applied Scientist - Network Optimization',\n",
       " 'Principal Applied Scientist - Payments',\n",
       " 'Principal Applied Scientist - Transactions Risk Management',\n",
       " 'Principal Data Scientist',\n",
       " 'Principal Data Scientist - Media Measurement',\n",
       " 'Principal Data Scientist \\\\u007C Pricing',\n",
       " 'Principal Electron-Optics Research Scientist (E)',\n",
       " 'Principal Research Scientist I  Medicinal Chemistry (permanent / full-time)',\n",
       " 'Principal Research Scientist II, AI / ML Team Lead',\n",
       " 'Principal Software Engineer',\n",
       " 'Principal, Same Day Long-Term Planning',\n",
       " 'Principal, Same Day, Long-term planning',\n",
       " 'Principal/Senior Scientist Non-Infectious Disease - Cardio-Metabolic Renal Disease (Research)',\n",
       " 'Process Data Analyst',\n",
       " 'Process Development Engineer',\n",
       " 'Process Engineer (relocation to St. Gallen, Switzerland)',\n",
       " 'Product Analyst',\n",
       " 'Product Analyst - Shopping Experience',\n",
       " 'Product Analyst - Social Discovery app',\n",
       " 'Product Analyst – Business Data & Insights',\n",
       " 'Product Analytics Associate (Based in Dubai)',\n",
       " 'Product Associate',\n",
       " 'Product Data Analyst (Banking + Data Quality)  mit 100% Homeoffice',\n",
       " 'Product Data Analyst (Savings and Contract Optimization) mit 100% Homeoffice',\n",
       " 'Product Data Science Managers',\n",
       " 'Product Lead, Platform Products',\n",
       " 'Product Lead, Pricing',\n",
       " 'Product Lead, Search',\n",
       " 'Product Manager',\n",
       " 'Product Manager (DeFi / Earn) - Web3',\n",
       " 'Product Manager Pricing & Analytics',\n",
       " 'Product Manager, DashOps',\n",
       " 'Product Owner  - Buchhaltung & Berichte',\n",
       " 'Product Safety Specialist *',\n",
       " 'Production Technology Engineer',\n",
       " 'Produkt- und Datenanalyst/in  (Kaufmann/-frau - Versicherungen u. Finanzen - Versicherung)',\n",
       " 'Professor for Data Science',\n",
       " 'Program/Product Manager Intern',\n",
       " 'Project Management Assistant (Real World Data)',\n",
       " 'Projektingenieur - Data Scientist',\n",
       " 'Projektleiter:in Künstliche Intelligenz',\n",
       " 'Projektmanager AI & Data Science',\n",
       " 'Prozess-und Betriebsdatenspezialist  (Berufsspezialist/in - Datenanalyse)',\n",
       " 'Prüfungsassistent / Consultant Audit & Advisory  mit Schwerpunkt Energy & Public',\n",
       " 'Publicis Media - (Junior) Data Scientist',\n",
       " 'Python Developer',\n",
       " 'Python Developer  in the field of ML and AI',\n",
       " 'Python Developer / Data Scientist - Remote or Berlin based',\n",
       " 'Python Full Stack Developer',\n",
       " 'Quant Developer',\n",
       " 'Quantitative Power Trading Analyst',\n",
       " 'Quantum Scientist - Superconducting Qubits (remote-ish)',\n",
       " 'R&D Internship – Data Science, ML and AI',\n",
       " 'R&D Scientist',\n",
       " 'RESEARCH SCIENTIST  PROTEIN CRYO-EM WITH PROJECT MANAGEMENT SKILLS',\n",
       " 'Referent Netzplanungsdatenmanagement',\n",
       " 'Remote (Sr.) Data Scientist Python (Django)',\n",
       " 'Remote (Sr.) Python Data Scientist',\n",
       " 'Research And Development Engineer',\n",
       " 'Research Assistant, Molecular Diagnostics',\n",
       " 'Research Assistant/Associate',\n",
       " 'Research Assistant/Associate  PhD students for \"Research and Development in the Field of Combustion Systems with Optical Flow Diagnostics\" (TME 130_241100)',\n",
       " 'Research Assistant/Associate  PhD students for \"Research and Development in the Field of Optical Flow Diagnostics\" (TME 129_241100)',\n",
       " 'Research Associate for the Project “DASHH - Data Science in Hamburg - Helmholtz Graduate School for the Structure of Matter, Particle Physics with the CMS Experiment” § 28 Subsection 3 HmbHG',\n",
       " 'Research Associate for the Project “DASHH - Data Science in Hamburg - Helmholtz Graduate School for the Structure of Matter, dAIbetes” § 28 Subsection 3 HmbHG',\n",
       " 'Research Engineer',\n",
       " 'Research Engineer, Applied AI',\n",
       " 'Research Engineer/Analyst',\n",
       " 'Research Scientist',\n",
       " 'Research Scientist (PhD in Nuclear Physics',\n",
       " 'Research Scientist BIOCHEMISTRY/BIOPHYSICS',\n",
       " 'Research Scientist BIOPHYSICS WITH FOCUS PLATE-BASED ASSAYS',\n",
       " 'Research Scientist I, Germany',\n",
       " 'Research assistant',\n",
       " 'Research assistant  - Department of Mathematics and Natural Science - Mathematics of Data Science Group - ID 142/2024',\n",
       " 'Research assistant  with 75%part-time job limited to 30.09.2027 salary grade (Entgeltgruppe) 13 TV-L FU reference code: WiMi_Clementi_FAIME_2025',\n",
       " 'Research assistant for AAI and federated services project ROCK-IT',\n",
       " 'Research, Analytics, and Knowledge Management Team Lead',\n",
       " 'Researcher / Project Manager',\n",
       " 'Robotics Software Engineer all levels',\n",
       " 'Robotics and Autonomous Systems / Robotics and AI Engineer',\n",
       " 'SAP Analytics Architect',\n",
       " 'SAP Analytics Expert',\n",
       " 'SAP Business Analyst  Data Migrations',\n",
       " 'SAP Consultant - Energy / Utilities / Remote',\n",
       " 'SAP Inhouse (Senior) Consultant in Business Analytics',\n",
       " 'SENIOR DATA SCIENTIST',\n",
       " 'SEO - Data Analyst:in',\n",
       " 'Sales / Vertrieb Weiterbildung  - Jobchance für Remote-Workers (Teilzeit)',\n",
       " 'Sales Consultant Digital Solutions',\n",
       " 'Sales Manager / Sales Development Representative',\n",
       " 'Salesforce Data Analyst CRM-Marketing',\n",
       " 'Scientific Data Architect / Senior Scientific Data Architect- EMEA Remote',\n",
       " 'Scientific Software Engineer',\n",
       " 'Scientist  Bioprocess Development RDI-Projects',\n",
       " 'Scientist  for the area Immunoassays (full-time)',\n",
       " 'Scientist  in vitro DMPK',\n",
       " 'Scientist (Postdoc) for Scanning Microprobe Endstation at Beamline P25, PETRA III',\n",
       " 'Scientist - In vivo Pharmacology',\n",
       " 'Scientist - LC-MS: Drug Product Characterization for Biopharmaceuticals',\n",
       " 'Scientist - Protein Analytics',\n",
       " 'Scientist / Postdoc : Analysis of Microscopic BIOMedical Images (AMBIOM)',\n",
       " 'Scientist / Postdoc in bioinformatics  Institute Molekularbiologie',\n",
       " 'Scientist / Study Director',\n",
       " 'Scientist Biotic Stress Trait Development',\n",
       " 'Scientist Digital Imaging , Referenz: „51001-24-03-WAPRO“',\n",
       " 'Scientist III, Field Applications',\n",
       " 'Scientist Viral Vector Production',\n",
       " 'Scientist at innoFSPEC, AIP Technology Transfer',\n",
       " 'Scientist in the field of fiber drawing technology for active fibers',\n",
       " 'Scientist in the field of fiber drawing technology for active fluoride fibers',\n",
       " 'Scientist in the field of fiber preform development for active fibers',\n",
       " 'Scientist – DNA-, RNA- Oligonucleotide Synthesis',\n",
       " 'Scientist – Optical Design and Simulation',\n",
       " 'Scientist/DevOps Position in EScience Section',\n",
       " 'Scientist/DevOps in EScience Section',\n",
       " 'Scientist/Research-Associate – Retinal Gene Therapy',\n",
       " 'Semantics Engineer',\n",
       " 'Senior AI & Data Science Consultant',\n",
       " 'Senior AI / ML Engineer',\n",
       " 'Senior AI Developer',\n",
       " 'Senior AI Engineer',\n",
       " 'Senior AI Scientist : SAP Business AI - SAP Knowledge Graph',\n",
       " 'Senior Analyst / Engineer  im Bereich IT Data Analytics & Integration',\n",
       " 'Senior Analytical Scientist',\n",
       " 'Senior Analytics Engineer',\n",
       " 'Senior Applied Scientist - Fulfilment Planning',\n",
       " 'Senior Applied Scientist, ATS Science and Technology',\n",
       " 'Senior Applied Scientist, Amazon Robotics R&D',\n",
       " 'Senior Applied Scientist, Artificial General Intelligence',\n",
       " 'Senior Applied Scientist, Logistics',\n",
       " 'Senior Applied Scientist- Network Optimization',\n",
       " 'Senior Associate Quantitative Analyse',\n",
       " 'Senior Backend Developer',\n",
       " 'Senior Big Data Engineer',\n",
       " 'Senior Cloud Data Engineer',\n",
       " 'Senior Consultant / Manager (Gen) AI & Data Scientist | AI Garage',\n",
       " 'Senior Consultant / Solution Architect Data Management Manufacturing',\n",
       " 'Senior Consultant / Solution Architect Data Management Manufacturing  3',\n",
       " 'Senior Consultant Data Analytics, gern Informatiker:in, Mathematiker:in oder erfahrener Data Analyst',\n",
       " 'Senior Consultant Data Management',\n",
       " 'Senior Consultant IT Regulatory Risk / Risikomanagement',\n",
       " 'Senior Consultant SAP Data & Analytics',\n",
       " 'Senior Controller Projektmanagement  [JR105408]',\n",
       " 'Senior Controlling Data Scientist',\n",
       " 'Senior Data / Machine-Learning Engineer',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Architect',\n",
       " 'Senior Data Consultant',\n",
       " 'Senior Data Engineer',\n",
       " 'Senior Data Engineer (Python)',\n",
       " 'Senior Data Engineer Advanced Analytics',\n",
       " 'Senior Data Engineer Azure & Snowflake in Mainz(Data Engineer)',\n",
       " 'Senior Data Engineer Python/ML/AWS - Remote',\n",
       " 'Senior Data Engineer* / Machine Learning Engineer*',\n",
       " 'Senior Data Engineering Consultant',\n",
       " 'Senior Data Quality Consultant  gesucht - curexus',\n",
       " 'Senior Data Science Consultant',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist  - Business Intelligence Application',\n",
       " 'Senior Data Scientist  - ID: 233',\n",
       " 'Senior Data Scientist  - Large-scale Machine Learning',\n",
       " 'Senior Data Scientist  NLP in München',\n",
       " 'Senior Data Scientist  im Automotive Bereich',\n",
       " 'Senior Data Scientist  | hybrid (office/remote)',\n",
       " 'Senior Data Scientist  – Risikomodelle',\n",
       " 'Senior Data Scientist (Recommendation Systems Expert)',\n",
       " 'Senior Data Scientist (SOC / carbon modelling)',\n",
       " 'Senior Data Scientist (mwd)',\n",
       " 'Senior Data Scientist * Generative AI',\n",
       " 'Senior Data Scientist - Conversational AI (German Speaking) - AI Teams',\n",
       " 'Senior Data Scientist - Data & AI',\n",
       " 'Senior Data Scientist - Fraud & Credit Risk',\n",
       " 'Senior Data Scientist - Operations Research',\n",
       " 'Senior Data Scientist - Remote from Germany',\n",
       " 'Senior Data Scientist - Time Estimations, Logistics',\n",
       " 'Senior Data Scientist / AI Developer',\n",
       " 'Senior Data Scientist / Senior Software Technology Engineer',\n",
       " 'Senior Data Scientist / Senior Software Technology Engineer*',\n",
       " 'Senior Data Scientist Generative AI',\n",
       " 'Senior Data Scientist NLP/GenAI',\n",
       " 'Senior Data Scientist for Innovative Digital Product',\n",
       " 'Senior Data Scientist mit Schwerpunkt Ökonometrie/ Predictive Analytics',\n",
       " 'Senior Data Scientist – Energy Storage / Li-ion / Battery Technologies',\n",
       " 'Senior Data Scientist – Supply & Demand Modelling',\n",
       " 'Senior Data Scientist, AI-Experte für Natural Language Processing',\n",
       " 'Senior Data Scientist, Campaigns',\n",
       " 'Senior Data Scientist, Payments Product',\n",
       " 'Senior Data Scientist, gTech Ads',\n",
       " 'Senior Data Scientist- Optimization',\n",
       " 'Senior Database Engineer  (Data Engineer)',\n",
       " 'Senior Engineer Machine Learning / Deep Learning',\n",
       " 'Senior Essential Adoption Service Consultant  - Data Science, Automation & Technology',\n",
       " 'Senior Full-Stack Data Analytics/Data Science Expert*in im Competence Center Digital Accelerator im Mercedes-Benz Management Consulting /x)',\n",
       " 'Senior ML / AI Engineer',\n",
       " 'Senior ML Engineer',\n",
       " 'Senior ML Engineer, AWS Generative AI Innovation Center',\n",
       " 'Senior Machine Learning Data Scientist',\n",
       " 'Senior Machine Learning Engineer',\n",
       " 'Senior Machine Learning Engineer DevOps/MLOps',\n",
       " 'Senior Machine Learning Scientist for GenAI',\n",
       " 'Senior Manager, Safety Scientist',\n",
       " 'Senior Operations Research Scientist',\n",
       " 'Senior People Data Scientist (All genders) - Global People Analytics team',\n",
       " 'Senior Product Manager',\n",
       " 'Senior Product Manager - Fraud Prevention',\n",
       " 'Senior Python Developer (LLM-based applications, SME)',\n",
       " 'Senior Quant Developer',\n",
       " 'Senior Regional Marketing Manager',\n",
       " 'Senior Remote Sensing Scientist',\n",
       " 'Senior Research Scientist (permanent, E15 pay scale)',\n",
       " 'Senior Research Scientist in vitro neurophysiology',\n",
       " 'Senior Scientist',\n",
       " 'Senior Scientist  Molecular Complex Development',\n",
       " 'Senior Scientist - Mass Spectrometry',\n",
       " 'Senior Scientist / Platform Lead  Process Cheese - Temporary contract until 28.02.2027',\n",
       " 'Senior Scientist Machine Learning - Causal Machine Learning',\n",
       " 'Senior Scientist Machine Learning - Risikomodellierung und Pricing',\n",
       " 'Senior Scientist Machine Learning / Deep Learning',\n",
       " 'Senior Scientist Machine Learning – Causal Machine Learning',\n",
       " 'Senior Scientist Machine Learning – Risikomodellierung und Pricing',\n",
       " 'Senior Scientist R&D  Life Science MS',\n",
       " 'Senior Sensory Scientist',\n",
       " 'Senior Software Developer Data & ML',\n",
       " 'Senior Software Engineer',\n",
       " 'Senior Software Engineer (Python)',\n",
       " 'Senior Specialist/Data Scientist OSS Analytics in Voll- und Teilzeit',\n",
       " 'Senior Staff AI Engineer',\n",
       " 'Senior/Lead ML Engineer (AI-Powered Platform) - REMOTE UK/EUROPE/AMER',\n",
       " 'Senior/Principal Scientist Systems Pharmacology',\n",
       " 'Senior/Principal Scientist Systems Pharmacology PBPK /...',\n",
       " 'Simulation and Machine Learning Engineer',\n",
       " 'Software & AI Engineer in Health',\n",
       " 'Software Engineer  – Data Lake Architect',\n",
       " 'Software Engineer (Data & Python)',\n",
       " 'Software Engineer (Python)',\n",
       " 'Software Engineer (Python, Machine Learning, Cloud) - Remote',\n",
       " 'Software Engineer - Machine Learning',\n",
       " 'Software Engineer mit Data Science Background',\n",
       " 'Softwareentwickler/Data-Scientist für MES Integration  im Bereich Li-Ion Large Cells',\n",
       " 'Solutions Engineer',\n",
       " 'Spezialist  Data Engineering & Data Science',\n",
       " 'Spezialist Customer Data Governance',\n",
       " 'Spezialist Risikocontrolling CO2-Accounting / Data Scientist',\n",
       " 'Spezialist für Verkehrsdatenanalyse',\n",
       " 'Sports Scientist',\n",
       " 'Sr Data Scientist - LLM',\n",
       " 'Sr Scientist I, AI / ML',\n",
       " 'Sr. Data Engineer',\n",
       " 'Sr. Machine Learning Engineer',\n",
       " 'Staff Data Scientist',\n",
       " 'Staff Data Scientist - Ad Tech',\n",
       " 'Staff Data Scientist - Consumer Insights & Marketing Technology (CIMT) ( All genders )',\n",
       " 'Staff Data Scientist, Investment Modelling',\n",
       " 'Staff Engineer - Machine Learning',\n",
       " 'Staff ML / AI Engineer',\n",
       " 'Staff ML Engineer',\n",
       " 'Staff Scientist',\n",
       " 'Staff Scientist Cell Therapy-Type 1 Diabetes',\n",
       " 'Start Up Praktikum Business Intelligence',\n",
       " 'Strategy Manager Life Science',\n",
       " 'Student Data Scientist',\n",
       " 'Student Engineering, Natural Sciences, Data Science or similar',\n",
       " 'Student Researcher, 2025',\n",
       " 'Student für ein Praktikum als Data Analyst im Bereich Business Development/ Intelligence',\n",
       " 'Supply- Chain- Daten Analyst:in  - unbefristet',\n",
       " 'TOP TECHNOLOGIES CONSULTING GmbH – Berater (Mensch) Data Lifecycle Management',\n",
       " 'Talent Day - Explore a Tech Career with Netlight',\n",
       " 'Talent Pool',\n",
       " 'Team Lead Data Scientist',\n",
       " 'Teamlead Data Intelligence',\n",
       " 'Teamlead Data Science und Data Engineering',\n",
       " 'Technical Assistant - Biotechnology',\n",
       " 'Technical Investigator / Data Scientist - AI Safety',\n",
       " 'Technical Solutions Engineer - Data (Remote)',\n",
       " 'Technical Support Consultant  Data Center Operational Technology Management Software',\n",
       " 'Trainee  - Data Analyst / Data Scientist',\n",
       " 'Trainee  Data Analyst / Scientist',\n",
       " 'Trainee AI Engineer  - 12 Monate',\n",
       " 'Trainee Analytics Engineer',\n",
       " 'Trainee Data Analytics',\n",
       " 'Trainee Data Engineer',\n",
       " 'Trainee Data Engineer  - 12 Monate',\n",
       " 'Trainee Data Engineering',\n",
       " 'Trainee Data Science  - 12 Monate',\n",
       " 'Trainee Data Science  – Fokus NLP',\n",
       " 'Trainee Data Scientist Personen-Rückversicherung',\n",
       " 'Trainee Data Scientist Personen-Rückversicherung, 1792',\n",
       " 'Traineeship Data Engineer',\n",
       " 'UX Mixed Methods Researcher',\n",
       " 'Unsolicited Application / Initiativbewerbung',\n",
       " 'Unsolicited application (Full time)',\n",
       " 'Unterstützung im Bereich Einnahmeaufteilung & Statistik',\n",
       " 'VP of Data & Analytics',\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(df[\"title_clean\"].unique()).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seniority Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(Advanced) Data Developer (m/w/d)',\n",
       " '(Associate) Consultant (Gen) AI & Data Scientist | AI Garage (m/w/d)',\n",
       " '(Cloud) Data Engineer / BI Developer (m/w/d) (m/w/d)',\n",
       " '(Global) Senior Applied Research Scientist',\n",
       " '(Junior) AI Engineer (m/w/d)',\n",
       " '(Junior) Berater Business Intelligence (m/w/d)',\n",
       " '(Junior) Cloud Data Engineer (all genders)',\n",
       " '(Junior) Consultant Data Analytics (m/w/d)',\n",
       " '(Junior) Consultant Data Science & Artificial Intelligence (m/w/d)',\n",
       " '(Junior) Consultant | Gen AI Finance (m/w/d)',\n",
       " '(Junior) Data Analyst/ Business Analyst Procurement',\n",
       " '(Junior) Data Engineer (m/w/d)',\n",
       " '(Junior) Data Engineer (m/w/x)',\n",
       " '(Junior) Data Product Associate (f/m/x)',\n",
       " '(Junior) Data Scientist',\n",
       " '(Junior) Digital Produktmanager (m/w/d) AurumCars',\n",
       " '(Junior) Digital Produktmanager (m/w/d) Mietwagen',\n",
       " '(Junior) Digital Produktmanager (m/w/d) Payment Mietwagen',\n",
       " '(Junior) Online-Marketing Produktmanager (m/w/d) Mietwagen',\n",
       " '(Junior) Product Manager Financial Services (d/w/m)',\n",
       " '(Junior) Produktmanager (m/w/d) Chatbot Mietwagen',\n",
       " '(Junior) Produktmanager (m/w/d) Operations Analytics Mietwagen',\n",
       " '(Junior) Produktmanager (m/w/d) SEO-Automatisierung Mietwagen',\n",
       " '(Junior) Produktmanager / Operationsmanager (m/w/d) Automatisierung Mietwagen',\n",
       " '(Junior) Specialist ESG Reporting',\n",
       " '(Junior) Technischer Produktmanager (m/w/d) Partnermanagement Mietwagen',\n",
       " '(Junior/Mid-level) Big Data Engineer',\n",
       " '(Sen.) Data Scientist (m/w/d)',\n",
       " '(Senior) BI Analyst (all genders)',\n",
       " '(Senior) Biochemist / Biopyhsicist (m/f/d)',\n",
       " '(Senior) Business & Data Analyst (w/m/d)',\n",
       " '(Senior) Business Analyst / Data Analyst (m/w/d)',\n",
       " '(Senior) Consultant AI Specialist (m/w/d)',\n",
       " '(Senior) Consultant Data Science & MLOps, d/f/m',\n",
       " '(Senior) Consultant Data Science Time-Series & Forecasting (w/m/d) (Data Scientist)',\n",
       " '(Senior) Consultant Data Strategy & Governance (w/m/d)',\n",
       " '(Senior) Consultant Tech & AI Implementation (m/w/d)',\n",
       " '(Senior) Data & AI PreSales Consultant (m/w/d)',\n",
       " '(Senior) Data & Survey Engineer (m/w/d), Quantitative Marktforschung',\n",
       " '(Senior) Data Analyst (m/w/d)',\n",
       " '(Senior) Data Analyst / Data Scientist (f/m/d) in Data Division',\n",
       " '(Senior) Data Analyst / Scientist (m/w/d)',\n",
       " '(Senior) Data Engineer (all genders)',\n",
       " '(Senior) Data Engineer (m/f/d)',\n",
       " '(Senior) Data Engineer (m/w/d) (Informatiker/in)',\n",
       " '(Senior) Data Engineer (m/w/d) | Jobs bei Pexon Consulting GmbH',\n",
       " '(Senior) Data Engineer / Data Warehouse Entwickler (m/w/d)',\n",
       " '(Senior) Data Scientist (Analytics), Merchant',\n",
       " '(Senior) Data Scientist (gn) Internationales Team',\n",
       " '(Senior) Data Scientist (gn) with Spanish language skills',\n",
       " '(Senior) Data Scientist (m/f/d)',\n",
       " '(Senior) Data Scientist (m/w/d)',\n",
       " '(Senior) Data Scientist (m/w/d) in München',\n",
       " '(Senior) Data Scientist (m/w/d) – Schwerpunkt Predictive Modelling und GenAI (ab 01.04.25)',\n",
       " '(Senior) Data Scientist (m/w/d) – Schwerpunkt Predictive Modelling und GenAI ab 01.04.25',\n",
       " '(Senior) Data Scientist (w/m/d)',\n",
       " '(Senior) Data Scientist - Document and Text Analytics (w/m/d)',\n",
       " '(Senior) Data Scientist / ML Engineer (m/w/d)',\n",
       " '(Senior) Data Scientist / Researcher',\n",
       " '(Senior) Data Scientist Analytics (m/w/d)',\n",
       " '(Senior) Data Scientist Health Data Lab (w/m/d)',\n",
       " '(Senior) Data Scientist with focus Clinical Statistics (f/m/d - part/full-time)',\n",
       " '(Senior) Data Scientist with focus SAS programming (f/m/d - part/full-time)',\n",
       " '(Senior) DevOps Data Integration Engineer (w/m/x)',\n",
       " '(Senior) Fraud Data Scientist / Data Analyst (f/d/m)',\n",
       " '(Senior) Machine Learning Data Scientist (d/f/m)',\n",
       " '(Senior) Machine Learning Engineer (m/f/d)',\n",
       " '(Senior) Process Analyst / Prozessberater (m/w/d) Reporting – SAP BW / BPC / Power BI / Tableau',\n",
       " '(Senior) SAP Consultant (gn) Business Intelligence & Analytics',\n",
       " '(Senior) Scientist Primary Pharmacology of the Target Incubator Unit (f/m/d)',\n",
       " '(Senior)Machine Learning Data Scientist(d/f/m)',\n",
       " '(Senior-) Digital Transformation Engineer - Data Science (m/w/d)',\n",
       " '(Senior-) Software Engineer (m/w/d)',\n",
       " '(Wirtschafts-)Mathematiker, Statistiker, Data Scientist für die Tarifentwicklung Komposit',\n",
       " '1D/2D MATERIAL SCIENTIST (M/F/D)',\n",
       " '2025 Applied Scientist Internship, Amazon University Talent Acquisition',\n",
       " '2025 Software Development Engineer - Machine Learning (m/w/d)',\n",
       " '2025 Working Student Internship - Business Intelligence Engineer',\n",
       " 'ACTUARIAL DATA SCIENTIST (M/W/D)',\n",
       " 'AI & Data - Analyst',\n",
       " 'AI (Agent) Engineer (f/m/d) | Jobs at VisionAI - Jobs',\n",
       " 'AI Architect & Optimization Specialist (m/w/d)',\n",
       " 'AI Architect / Machine Learning Engineer (m,f,d)',\n",
       " 'AI Cloud Engineer',\n",
       " 'AI Consultant',\n",
       " 'AI Developer',\n",
       " 'AI Developer (m/w/d)',\n",
       " 'AI Engineer',\n",
       " 'AI Engineer (Intern)',\n",
       " 'AI Engineer (Senior)',\n",
       " 'AI Engineer (m/w/d)',\n",
       " 'AI Engineer - Germany (Remote)',\n",
       " 'AI Engineer / AI Developer (m/w/d) bei einem SaaS-Unternehmen aus Würzburg (Full-Remote oder vor Ort)',\n",
       " 'AI Engineer / Data Scientist m|w|d',\n",
       " 'AI Engineer // Data Scientist (all genders)',\n",
       " 'AI Engineer for AI Startup',\n",
       " 'AI Engineer mit Schwerpunkt NLP (m/w/d)',\n",
       " 'AI Experience Researcher (m/f/d)',\n",
       " 'AI Lead',\n",
       " 'AI Platform Engineer (all genders)',\n",
       " 'AI Research Scientist - Generative AI Red Teaming (London or Paris)',\n",
       " 'AI Researcher',\n",
       " 'AI Software Developer in Test (f/m/d)',\n",
       " 'AI Software Engineer',\n",
       " 'AI Software Engineer (w/m/x)',\n",
       " 'AI consultant  - Energy',\n",
       " 'AI&Business Analyst / Consultant (Remote Internship)',\n",
       " 'AI-Engineer/Vollzeit',\n",
       " 'AI/ML Engineer - Biomedical AI (m/f/d)',\n",
       " 'AI\\xa0computational\\xa0\\xa0material\\xa0\\xa0researcher/expert',\n",
       " 'Abschlussarbeit im Bereich Datenstrategie und Künstliche Intelligenz',\n",
       " 'Abschlussarbeit im Bereich: KI basierte Generierung von Schiffsgeräuschen (m/w/d)',\n",
       " 'Abschlussarbeit zum Thema: „Generative KI\"',\n",
       " 'Account Manager:in für Sound Branding, Podcasts und Audiospots',\n",
       " \"Aignostics' Talent Community\",\n",
       " 'Aktuar (DAV)/Data Scientist (d/w/m) - Krankenversicherungen & Data Warehouse',\n",
       " 'Analyst & Marketing Technology Manager (d/w/m)',\n",
       " 'Analyst (m/w/d) Short Term Trading in Renewable Energies',\n",
       " 'Analyst - Fokus Data Science / AI (m/w/d)',\n",
       " 'Analytics & Insights Internship (m/f/d)',\n",
       " 'Analytics Engineer',\n",
       " 'Analytics Engineer (m/f/d)',\n",
       " 'Analytics Engineer (m/w/d)',\n",
       " 'Analytics Engineer (m|w|d) im Bereich Business Intelligence & Web Analytics',\n",
       " 'Analytics Engineer (w/m/d)',\n",
       " 'Analytics Engineer - Graduate (Hybrid; m/f/x/d)',\n",
       " 'Analytics Engineering Lead',\n",
       " 'Analytics and Insight Professional, Amazon Advertising, Analytics and Insights',\n",
       " 'Applied Machine Learning Engineers',\n",
       " 'Applied Scientist II (L5), AFT AI, Amazon AFT AI',\n",
       " 'Applied Scientist for Probabilistic Machine Learning and Human-Computer Interaction',\n",
       " 'Applied Scientist, ATS Machine Learning & Engineering',\n",
       " 'Applied Scientist, Amazon Nova',\n",
       " 'Applied Scientist, Amazon Robotics R&D',\n",
       " 'Applied Scientist, Artificial General Intelligence, AGI Information',\n",
       " 'Applied Scientist, Content Systems Science and Engineering, Amazon',\n",
       " 'Applied Scientist, Fintech (Fraud)',\n",
       " 'Artificial Intelligence Engineer',\n",
       " 'Artificial Intelligence Specialist',\n",
       " 'Artificial Intelligence Specialist (w/m/d)',\n",
       " 'Artificial Intelligence and Machine learning Business & Data Analyst',\n",
       " 'Assistant (m/f/d) Databases and Data Analysis',\n",
       " 'Associate - Index Operations (m/f/d)',\n",
       " 'Associate / (Senior) AI Technology Consultant (m/w/d)',\n",
       " 'Associate Data Analyst (f/m/d)',\n",
       " 'Associate Data Science & Management Consultant',\n",
       " 'Associate Special Project, Esports',\n",
       " 'Atomic, Molecular, and Optical Physicist',\n",
       " 'BI & Data Modeling Expert (m/f/d)',\n",
       " 'BI Analyst (all genders)',\n",
       " 'BI Analyst (m/w/d)',\n",
       " 'BI Business Analyst (m/f/d)',\n",
       " 'BI Manager (m/w/d) Data Science/Data Analytics',\n",
       " 'BI-Entwickler Trainee (Data Analyst / Data Engineer)',\n",
       " 'Bachelor (m/w/d) of Science - Data Science und Künstliche Intelligenz - Start 01.09.2025',\n",
       " 'Bachelor (m/w/d) of Science - Wirtschaftsinformatik - Data Science - Start 01.09.2025',\n",
       " 'Bachelor of Science (DHBW) Data Science / Künstliche Intelligenz (m/w/d) am Standort Winnenden 2025',\n",
       " 'Bachelor of Science (DHBW) Wirtschaftsinformatik - Data Science(m/w/d) am Standort Obersontheim 2025',\n",
       " 'Bachelor of Science (m/w/d) - Data Science und Künstliche Intelligenz ab 01.09.2025',\n",
       " 'Bachelor of Science (m/w/d) Data Science und Künstliche Intelligenz, Start 2025',\n",
       " 'Bachelor of Science (m/w/d) Data Science und Künstliche Intelligenz, Start 2026',\n",
       " 'Bachelor-/Master Thesis »Full-field Thermo-mechanical Characterization of Glass Materials«',\n",
       " 'Bachelor/ Master Thesis: Methane leak localization from ambient data (f/m/x)',\n",
       " 'Backend Developer (m/f/d)',\n",
       " 'Backend Software Engineer - Remote (m/f/d)',\n",
       " 'Backend/ML Software Engineer (Entry to Mid-Level) - Remote',\n",
       " 'Battery Scientist (m/f/x)',\n",
       " 'Bench Scientist (all genders)',\n",
       " 'Beschäftigte/r Qualitätsmanagement und Datenanalyse (m/w/d)',\n",
       " 'Big Data Architect (m/w/d)',\n",
       " 'Big Data DevOps Engineer (m/w/d) | (DSIDMG)',\n",
       " 'Bilanzmathematiker / Statistiker (m/w/d)',\n",
       " 'Binance Accelarator Program - LLM Data Scientist',\n",
       " 'Bioinformatician',\n",
       " 'Bioinformatician (m/f/d) in immunopeptidomics',\n",
       " 'Bioinformatician (m/f/div) Immunogenetics',\n",
       " 'Bloomwell - Working Student Data & Analytics (m/w/d)*',\n",
       " 'Breeding Informatics Analyst (d/f/m) Full Time - in Tübingen',\n",
       " 'Business  Development Manger',\n",
       " 'Business & Data Analyst (f/m/x)',\n",
       " 'Business / Data Analyst (m/w/d)',\n",
       " 'Business / Data Analyst (w/m/d) Real Estate Consulting Digitalisierungsberatung',\n",
       " 'Business Analyst',\n",
       " 'Business Analyst (m/w/d) - im Team Data Science Solutions',\n",
       " 'Business Analyst (m/w/d) – Data Analytics Vertriebsplanung | Banking',\n",
       " 'Business Analyst - Marketing Planning und Forecasting (m/w/d)',\n",
       " 'Business Analyst / Controller',\n",
       " 'Business Analyst Data Management (w/m/d)',\n",
       " 'Business Analyst Intern',\n",
       " 'Business Analyst – Data Quality (w/m/d)',\n",
       " 'Business Data Analyst',\n",
       " 'Business Data Analyst & Engineer (m/w/d)',\n",
       " 'Business Data Analyst (m/w/d) im LSZ - Qualität und Support, Referat Stab Reporting und Controlling',\n",
       " 'Business Intelligence & Analytics Manager',\n",
       " 'Business Intelligence / Data Analytics-& Management Consultant',\n",
       " 'Business Intelligence Analyst (m/w/d)',\n",
       " 'Business Intelligence Analyst (w/d/m) mit Schwerpunkt Sales',\n",
       " 'Business Intelligence Consultant',\n",
       " 'Business Intelligence Developer (m/w/d) Tech / E-Commerce',\n",
       " 'Business Intelligence Developer * (Junior Level)',\n",
       " 'Business Intelligence Engineer',\n",
       " 'Business Intelligence Engineer (BIE), Supply Chain Outbound Execution',\n",
       " 'Business Intelligence Engineer (m/w/d)',\n",
       " 'Business Intelligence Engineer (w/m/d)',\n",
       " 'Business Intelligence Engineer*',\n",
       " 'Business Intelligence Engineer, Transportation, Global Transportation Services',\n",
       " 'Business Intelligence Engineer, WHS Data',\n",
       " 'Business Intelligence Expert F-35 (m/w/d)',\n",
       " 'Business Intelligence Manager (m/w/d)',\n",
       " 'Business Intelligence Specialist (m/w/x)',\n",
       " 'Business Intelligence Workshop',\n",
       " 'Business Intelligence und Data Analyst (m/w/d)',\n",
       " 'Business Process Analyst – Marketing & Sales (f/m/d)',\n",
       " 'Business Relationship Manager BI and Data Science (m/w/d)',\n",
       " 'CO-Data Scientist (m/w/d)',\n",
       " 'COMPUTATIONAL GENOMICS SCIENTIST (m/f/d), Referenz: „51004-24-05-WAPRO“',\n",
       " 'CRA/SCRA',\n",
       " 'CRM Data Specialist *',\n",
       " 'Carbon Project Risk Analyst (f/d/m)',\n",
       " 'Certified Strength and Conditioning Specialist',\n",
       " 'Chemical Technical Assistant (f/m/d)',\n",
       " 'Chief AI Engineer',\n",
       " 'Chief Commercial Officer - AI (Berlin)',\n",
       " 'Chief Data Officer (m/w/d)',\n",
       " 'Chief Technology Officer',\n",
       " 'Chief Technology Officer - Must be based in Germany',\n",
       " 'Climate Risk Intern (m/f/d)*',\n",
       " 'Cloud & Machine Learning Consultant (m/f/d)',\n",
       " 'Cloud Big Data Engineer / DevOps Engineer (m/w/d)',\n",
       " 'Cloud Engineer m/w/d',\n",
       " 'Computational Biologist (m/f/d)',\n",
       " 'Computational Chemist Lead',\n",
       " 'Computational Materials Scientist* (m/f/d)',\n",
       " 'Computational Scientist – (Machine Learning) Digital R&D Large Molecule Research',\n",
       " 'Computer Scientist | InformatikerIn | Software EntwicklerIn für klinische KI-Forschung und Anwendung',\n",
       " 'Computer Scientist – Mendel Verlag',\n",
       " 'Computer Vision Engineer',\n",
       " 'Consultant (w/m/d) Energy, Environment & Telecommunication',\n",
       " 'Consultant - Digital Analytics (m/w/d) for Hamburg',\n",
       " 'Consultant AI & Analytics',\n",
       " 'Consultant AI & Data Analytics / Data Science (m/w/d)',\n",
       " 'Consultant AI & Data Analytics / Data Science (m/w/d) in Berlin',\n",
       " 'Consultant AI & Data Analytics / Data Science (m/w/d) in Frankfurt (Main)',\n",
       " 'Consultant AI & Data Analytics / Data Science (m/w/d) in Hamburg',\n",
       " 'Consultant AI & Data Analytics / Data Science (m/w/d) in München',\n",
       " 'Consultant Data Science Credit Risk (m/w/d) in Berlin',\n",
       " 'Consultant Datamanagement & Data Analyst (m/w/d)',\n",
       " 'Consultant Datamanagement & Data Analyst m/w/d',\n",
       " 'Consultant Künstliche Intelligenz / Artificial Intelligence Energy (m/w/d)',\n",
       " 'Consultant im Bereich Energy, Transformation & Sustainability (m/w/x)',\n",
       " 'Consultant | Senior Consultant (W/M/D) Data Scientist in Credit Risk Management',\n",
       " 'Consulting & Analytics Summer Intern',\n",
       " 'Controlling & Analytics Trainee (m/w/d)',\n",
       " 'Create a DataCamp Course - Cloud (Part-Time, Freelance)',\n",
       " 'Customer Data Consultant (m/w/d)',\n",
       " 'DATA ANALYST (M/W/D)',\n",
       " 'DATA ANALYST:IN (m/w/d)',\n",
       " 'DATA ENGINEER (M/W/D)',\n",
       " 'DATA ENGINEER M/W/D',\n",
       " 'DATA SCIENCE MANAGER*',\n",
       " 'DATA SCIENTIST (M/F/D)',\n",
       " 'DATA SCIENTIST (M/W/D)',\n",
       " 'DATA SCIENTIST (M/W/D) SMART PROCESS AUTOMATION',\n",
       " 'DATA SCIENTIST ENGINEER (M/W/D) DIGITAL SOLUTIONS – BRAUNSCHWEIG, BERLIN',\n",
       " 'DH-STUDIERENDE FÜR DATA SCIENCE & KÜNSTLICHE INTELLIGENZ 2025 (M/W/D)',\n",
       " 'DWH Analyst (all genders)',\n",
       " 'DWH-Entwickler (m/w/d)',\n",
       " 'Data & AI Business Consultant (m/w/d)',\n",
       " 'Data & AI Scientist',\n",
       " 'Data & AI Scientist Personalized Computational Genomics (all genders)',\n",
       " 'Data & AI Strategist (m/f/d)',\n",
       " 'Data / Analytics Engineer (m/w/d)',\n",
       " 'Data Analysis / Data Engineering / Data Science (M/F/D)',\n",
       " 'Data Analysis Expert Battery Test Field (all genders)',\n",
       " 'Data Analysis, Modeling & Simulation Engineer (f/m/d)',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst (all gender) – Process Mining und Datenanalyse',\n",
       " 'Data Analyst (all genders)',\n",
       " 'Data Analyst (m/f/d)',\n",
       " 'Data Analyst (m/f/d) Search',\n",
       " 'Data Analyst (m/f/d) at Allianz SE',\n",
       " 'Data Analyst (m/f/d) in IT security company',\n",
       " 'Data Analyst (m/w/d)',\n",
       " 'Data Analyst (m/w/d) (Job-ID 2022099)',\n",
       " 'Data Analyst (m/w/d) / Remote möglich',\n",
       " 'Data Analyst (m/w/d) Berlin, Hamburg, Munich',\n",
       " 'Data Analyst (m/w/d) Telematikdaten',\n",
       " 'Data Analyst (w/m/d)',\n",
       " 'Data Analyst - MS Tech Stack',\n",
       " 'Data Analyst - Product',\n",
       " 'Data Analyst / Data Engineer (m/f/d)',\n",
       " 'Data Analyst / Data Scientist (m/w/d)',\n",
       " 'Data Analyst / Decision Scientist, Digital Marketing',\n",
       " 'Data Analyst / Decision Scientist, Policy',\n",
       " 'Data Analyst / Scientist (Microsoft PowerBI und MS SQL Server)',\n",
       " 'Data Analyst / Scientist (m/w/d) für die Energietransformation',\n",
       " 'Data Analyst Battery Cell Testing (all genders)',\n",
       " 'Data Analyst Campaigning (w/m/d)',\n",
       " 'Data Analyst bei Siemens (m/w/d)',\n",
       " 'Data Analyst m/f/d',\n",
       " 'Data Analyst/Market Researcher',\n",
       " 'Data Analyst/Scientist (m/w/d) für die Energietransformation',\n",
       " 'Data Analyst:in Münster/Köln/Berlin/Remote (DE)',\n",
       " 'Data Analytics Architect (w/m/d)',\n",
       " 'Data Analytics Consultant (m/w/d)',\n",
       " 'Data Analytics Consultant Frontend (m/w/d)',\n",
       " 'Data Analytics Engineer',\n",
       " 'Data Analytics Specialist (d/w/m)',\n",
       " 'Data Analytics Specialist (m/f/d)',\n",
       " 'Data Analytics Training & Internship',\n",
       " 'Data Architect (m/f/d)',\n",
       " 'Data Architect (m/w/d)',\n",
       " 'Data Architect AI/ML (m/w/d) | Jobs bei Pexon Consulting GmbH',\n",
       " 'Data Architekt (m/w/d)',\n",
       " 'Data Architekt / Data Engineer / Data Scientist (m/w/d)',\n",
       " 'Data Assimilation Scientist',\n",
       " 'Data Consultant (m/w/d)',\n",
       " 'Data Consultant (w/m/d)',\n",
       " 'Data Driven Business Consultant - Automotive (m/w/d)',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer (English speaking)(M/F/D)',\n",
       " 'Data Engineer (d/f/m)',\n",
       " 'Data Engineer (f/m/d)',\n",
       " 'Data Engineer (f/m/x)',\n",
       " 'Data Engineer (m/w/d)',\n",
       " 'Data Engineer (m/w/d) Tech / E-Commerce',\n",
       " 'Data Engineer (w/m/d)',\n",
       " 'Data Engineer - Recommendation Systeme (m/w/d)',\n",
       " 'Data Engineer / Analyst',\n",
       " 'Data Engineer / Data Analyst (m/w/d)',\n",
       " 'Data Engineer / Data Scientist (M/F/D)',\n",
       " 'Data Engineer / Scientist (m/w/d)',\n",
       " 'Data Engineer Big Data (all genders)',\n",
       " 'Data Engineer Intern (Mandatory/Pflichtpraktikum) (w/m/d)',\n",
       " 'Data Engineer Schwerpunkt Kundenpersonalisierung (m/w/d)',\n",
       " 'Data Engineer* / Machine Learning Engineer*',\n",
       " 'Data Engineering Consultant',\n",
       " 'Data Engineering Internship (m/w/d) - Gigafactory Berlin-Brandenburg',\n",
       " 'Data Engineering Training & Internship',\n",
       " 'Data Engineering Working Student/Intern (f/m/d)',\n",
       " 'Data Enthusiast (m/w/d)',\n",
       " 'Data Integrity Specialist Pharma (m/w/d)',\n",
       " 'Data Product Manager',\n",
       " 'Data Quality Manager (m/f/x)',\n",
       " 'Data Reporting Analyst',\n",
       " 'Data Science & Engineering Lehrassistent:in (Pflichtpraktikum, Werkstudententätigkeit)',\n",
       " 'Data Science Analyst (m/w/d)',\n",
       " 'Data Science Consultant (m/w/d)',\n",
       " 'Data Science Consultant - QuantumBlack, AI by McKinsey',\n",
       " 'Data Science Graduate',\n",
       " 'Data Science Intern',\n",
       " 'Data Science Intern - Intelligence Automation (Remote)',\n",
       " 'Data Science Intern - Summer 2025, EMEA (Remote)',\n",
       " 'Data Science Lead - Credit Risk (m/f/d)',\n",
       " 'Data Science and AI Mentor (Freelance, Remote)',\n",
       " 'Data Science und KI - Smart Operations Management\\xa0(m/w/d)',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist & Machine Learning Engineer (m/w/d)',\n",
       " 'Data Scientist & Machine Learning Engineer (w|m|d)',\n",
       " 'Data Scientist (Growth Team)',\n",
       " 'Data Scientist (aGw*)',\n",
       " 'Data Scientist (all gender)',\n",
       " 'Data Scientist (all genders)',\n",
       " 'Data Scientist (alle Geschlechter)',\n",
       " 'Data Scientist (d/f/m)',\n",
       " 'Data Scientist (d/m/w) Short-Term Asset Trading',\n",
       " 'Data Scientist (d/w/m)',\n",
       " 'Data Scientist (f/m/d)',\n",
       " 'Data Scientist (f/m/x)',\n",
       " 'Data Scientist (jun. / sen.)',\n",
       " 'Data Scientist (m/f/d)',\n",
       " 'Data Scientist (m/f/x)',\n",
       " 'Data Scientist (m/w/d)',\n",
       " 'Data Scientist (m/w/d) (Data Scientist)',\n",
       " 'Data Scientist (m/w/d) (Job-ID 2023061)',\n",
       " 'Data Scientist (m/w/d) (Junior)',\n",
       " 'Data Scientist (m/w/d) - Sektion für Hämatologische Spezialdiagnostik',\n",
       " 'Data Scientist (m/w/d) Smart Process Automation',\n",
       " 'Data Scientist (m/w/d) in Hamburg | EPROFESSIONAL',\n",
       " 'Data Scientist (m/w/d) in den Bereichen NLP und LLM (Entwicklung/ Betrieb, Kompetenzaufbau und Support)',\n",
       " 'Data Scientist (m/w/d) mit Fokus auf Big Data und KI',\n",
       " 'Data Scientist (m/w/d) zur Auswertung und Analyse von komplexen Messdaten',\n",
       " 'Data Scientist (m/w/x)',\n",
       " 'Data Scientist (mwd)',\n",
       " 'Data Scientist (w/m/d)',\n",
       " 'Data Scientist (w/m/d) - Schwerpunkt Customer Intelligence',\n",
       " 'Data Scientist - 24 month contract',\n",
       " 'Data Scientist - Consumer (Global Discovery)',\n",
       " 'Data Scientist - Customer Data Platform (all genders)',\n",
       " 'Data Scientist - Customer Success Projects (ValueWorks)',\n",
       " 'Data Scientist - Data Engineering (m/w/d)',\n",
       " 'Data Scientist - Datenmanagement (m/w/d)- AOK Bayern - Die Gesundheitskasse',\n",
       " 'Data Scientist - LLM',\n",
       " 'Data Scientist - Lexware Office (w/d/m)',\n",
       " 'Data Scientist - Portfolio Analyst & Product Owner (m/f/d)*',\n",
       " 'Data Scientist - Process Mining (m/w/d)',\n",
       " 'Data Scientist - Ranking',\n",
       " 'Data Scientist - Startup Berlin',\n",
       " 'Data Scientist - Supply Chain & Procurement',\n",
       " 'Data Scientist - Time Estimations, Logistics (all genders)',\n",
       " 'Data Scientist / AI Developer (m/w/d)',\n",
       " 'Data Scientist / Analyst (m/w/d)',\n",
       " 'Data Scientist / Biostatistician (m/f/d)',\n",
       " 'Data Scientist / Data Analyst (m/w/d)',\n",
       " 'Data Scientist / Data Engineer (Python) (m/w/d)',\n",
       " 'Data Scientist / Engineer (gn)',\n",
       " 'Data Scientist / Engineer (m/w/d)',\n",
       " 'Data Scientist / Engineer mit LLM-Fokus (m/w/d)',\n",
       " 'Data Scientist / ML Engineer (m/ f/ d)',\n",
       " 'Data Scientist / Machine Learning Expert (m/w/d)',\n",
       " 'Data Scientist / Softwareentwickler (m/w/d)',\n",
       " 'Data Scientist 100%',\n",
       " 'Data Scientist Automotive (m/w/d)',\n",
       " 'Data Scientist Consultant (m/f/d)',\n",
       " 'Data Scientist Consultant (m/w/d)',\n",
       " 'Data Scientist Datenmanagement',\n",
       " 'Data Scientist Digital Health ‒ Strategie, Analyse & Infrastruktur (m/w/d)',\n",
       " 'Data Scientist Intern',\n",
       " 'Data Scientist Lead and Team Lead \"Customer Intelligence Team\" (m/f/d)',\n",
       " 'Data Scientist NLP and Text Mining (f/m/d)',\n",
       " 'Data Scientist Natural Language Processing (m/w/d)',\n",
       " 'Data Scientist Online Analytics',\n",
       " 'Data Scientist Optical Spectroscopy (w/m/d)',\n",
       " 'Data Scientist Pathologisches Institut',\n",
       " 'Data Scientist Trainee Life and Health Reinsurance, 1792',\n",
       " 'Data Scientist als Modellentwickler Einsatzplanung Energiesysteme (w|m|d)',\n",
       " 'Data Scientist and Process Mining Architect',\n",
       " 'Data Scientist and Team Lead Property',\n",
       " 'Data Scientist für das Pathologische Institut',\n",
       " 'Data Scientist in Energy Tech Start Up - hybrid Berlin based (f/m/d)',\n",
       " 'Data Scientist mit Fokus auf datengetriebenes Marketing',\n",
       " 'Data Scientist mit Schwerpunkt Datenarbeit (m/w/d)',\n",
       " 'Data Scientist mit Schwerpunkt Operationalisierung (m/w/d)',\n",
       " 'Data Scientist w/m/d',\n",
       " 'Data Scientist with focus Clinical Statistics (f/m/d - part/full-time)',\n",
       " 'Data Scientist – AI Engineer (m/w/d)',\n",
       " 'Data Scientist – CRM / Kundenbeziehungsmanagement (m/w/d)',\n",
       " 'Data Scientist – Supply & Demand Modelling',\n",
       " 'Data Scientist*in (m/w/d)',\n",
       " 'Data Scientist*in (m/w/d) - remote oder Karlsruhe',\n",
       " 'Data Scientist*in/Data Analyst*in (m/w/d)',\n",
       " 'Data Scientist, Germany - BCG X',\n",
       " 'Data Scientist, Internship, Germany - BCG X',\n",
       " 'Data Scientist, Mathematiker - Dateningenieur (m/w/d)- AOK Bayern - Die Gesundheitskasse',\n",
       " 'Data Scientist/ AI-Architekt (m/w/d)',\n",
       " 'Data Scientist/Analyst prüfungsnahe Beratung/Quants - Assurance (Financial Services) (w/m/d)',\n",
       " 'Data Scientist/Bioinformatiker im Team Molekulargenetik',\n",
       " 'Data Scientist/ML Engineer',\n",
       " 'Data Solutions Specialist (m/w/d)',\n",
       " 'Data Specialist (m/w/d)',\n",
       " 'Data Steward SAP S/4HANA - \"Business Partner\" (w/m/d)',\n",
       " 'Data Team Manager',\n",
       " 'Data and AI Director',\n",
       " 'Data and AI Partner',\n",
       " 'Data and AI/ML Engineer (f/m/d)',\n",
       " 'Data and Reporting Analyst (f/m/d)',\n",
       " 'Data-Analyst (m/w/d)',\n",
       " 'Data-Scientist/MLOps - KI-basiertes Recycling',\n",
       " 'Data/Software Engineer (f/m/d)',\n",
       " 'Datenanalyst (m/w/d)',\n",
       " 'Datenanalyst (m/w/d) / Data Analyst (m/f/d)',\n",
       " 'Datenanalyst (m/w/d) im Bereich Energiewirtschaft',\n",
       " 'Datenanalyst (m/w/d) im Vertriebsmanagement',\n",
       " 'Datenanalyst / Data Analyst Risikomanagement (w/m/d)',\n",
       " 'Datenanalyst für Logistikprozesse (m/w/d)',\n",
       " 'Datenanalyst:in Metering',\n",
       " 'Datenanalysten/in (m/w/d) für Modelle in der konjunkturstatistischen Erhebung im Gastgewerbe',\n",
       " 'Datenarchitekt Versicherungsplattform (m/w/d)',\n",
       " 'Decision Scientist (m/w/d)',\n",
       " 'Deep Learning Researcher',\n",
       " 'Detector Calibration and Characterisation Scientist (m/f/w)',\n",
       " 'Deutsche Bank Graduate Programme (f/m/x) Technology, Data & Innovation 2025',\n",
       " 'DevOps & Cloud Engineer - Data Analytics & AI',\n",
       " 'DevOps/ML Engineer (m/f/d)',\n",
       " 'Digital Data Scientist (w|m|d)',\n",
       " 'Digital Marketing & Data Analytics Manager (m/w/d)',\n",
       " 'Digital Trust and Safety Analyst with German (m/f/d)',\n",
       " 'Director of AI Engineering',\n",
       " 'Director of Data Science (f/m/x)',\n",
       " 'Director, Clinical Scientist (m/f/x)',\n",
       " 'Doctoral Researcher Position in Materials Science',\n",
       " 'Doktorand für die Konzipierung und Implementierung von KI-gestützten Produktionssystemen (w/m/d)',\n",
       " 'Doktorand:in – Untersuchung der Rolle zukünftiger Energietechnologien mit Hilfe von Natural Language Processing und Data Science (w/m/d)',\n",
       " 'Dr. rer. nat. Physik / Chemie / Materialwissenschaften - Teamleitung & Projektmanagement (m/w/d)',\n",
       " 'Duales Studium Bachelor of Science in Data Science und Künstlicher Intelligenz (m/w/d), ab 09/2025',\n",
       " 'Duales Studium – Data Science und Künstliche Intelligenz',\n",
       " 'E-Commerce Analyst & Marketing Support Manager (Kaufmann/-frau - E-Commerce)',\n",
       " 'EMEA - Solutions Engineer',\n",
       " 'ERP Business Analyst, Microsoft Business Central (m/f/d) Digital Development',\n",
       " 'ERP Business Analyst, SAP (m/f/d) Digital Development',\n",
       " 'ETL-Entwickler (m/w/d) Azure Data Factory',\n",
       " 'Economic Modeller / Contract Role (m/f/x) Full Remote',\n",
       " 'Electrical Engineer or Computer Scientist (m/f/d) in Technical Support / Automation Technology',\n",
       " 'Engagement Manager (Data & AI)',\n",
       " 'Engineer AI (m/w/d)',\n",
       " 'Engineering Manager - Applied Generative AI (all genders) @ Babbel | NGP Capital Job Board',\n",
       " 'Enterprise Solutions Engineer, Germany',\n",
       " 'Experte für Fahrzeug Telematikdaten und Datenanalysen (gn)',\n",
       " 'Experte für Fahrzeug-Telematikdaten und Datenanalysen (m/w/d) - hybrides Arbeiten (Remote & Präsenz)',\n",
       " 'Fachkraft für den Bereich Einnahmeaufteilung & Statistik (m/w/d)',\n",
       " 'Fachreferent/in für Künstliche Intelligenz A13/E13 (w/m/d)',\n",
       " 'Festanstellung im Bereich Data Analytics und Machine Learning für Datenanalyse-Startup in München (m/w/d)',\n",
       " 'Field Application Scientist, EMEA',\n",
       " 'Financial Analyst - Intern (Remote Internship - Finance)',\n",
       " 'Financial Analyst Intern',\n",
       " 'Financial Data Specialist (m/w/d) Corporate Actions Shares & Funds',\n",
       " 'Financial Data Specialist (m/w/d) – Masterdata Shares / Funds',\n",
       " 'Financial Data Specialist – Bonds / Wertpapiere (m/w/d)',\n",
       " 'Financial Engineer Expert (m/w/d)',\n",
       " 'Financial Engineer m/w/d',\n",
       " 'Forecasting Data Scientist SCM (m/w/d)',\n",
       " 'Founding Software Engineer (m/w/d)',\n",
       " 'Fraud Analyst',\n",
       " 'Fraud Fighter Wanted (d/m/w)',\n",
       " 'Fraud Operations Specialist (f/m/x)',\n",
       " 'Freelance Machine Learning Engineer',\n",
       " 'Full Stack Entwickler (w/m/d)',\n",
       " 'Full-Stack Data Analyst (f/m/d)',\n",
       " 'Full-Stack Data Analytics/Data Science Expert im Competence Center Digital Accelerator (d/m/w/x)',\n",
       " 'GOglobal Trainee Data & AI (all genders)',\n",
       " 'GenAI-Developer/Data Scientist (m/w/d)',\n",
       " 'Generative AI Engineer',\n",
       " 'Generative AI Explorer (Stable Diffusion, ControlNet...)',\n",
       " 'Generative Machine Learning Engineer',\n",
       " 'Genomics Data Scientist (f/m/x)',\n",
       " 'Geospatial Data Scientist with focus on remote sensing',\n",
       " 'Gesundheitsökonom / Data Scientist im Gesundheitswesen (D/M/W)',\n",
       " 'Global Engineer - Real World Evidence - Europe',\n",
       " 'Google Cloud AI/ML Consultant (m/w/d)',\n",
       " 'Government Affairs Specialist',\n",
       " 'Gruppenleiter (w/m/d) Sach-Firmen SF - Strategie, Steuerung, Pricing und Produktmanagement für das Geschäftsfeld Sach-Firmen',\n",
       " 'HR Analytics Specialist (m/f/d)',\n",
       " 'HR Business Partner (d/f/m)',\n",
       " 'HR Data Analytics (m/w/d) - Gigafactory Berlin-Brandenburg',\n",
       " 'HYDROGEN TECHNOLOGY RESEARCH ENGINEER (M/F/D)',\n",
       " 'Head Applied Data & Genetics Science – Seeds Field Crops Europe (M/F/D)',\n",
       " 'Head of / VP - Data Experience',\n",
       " 'Head of AI',\n",
       " 'Head of AI (all genders)',\n",
       " 'Head of AI (m / f / d)',\n",
       " 'Head of AI Research & Development (100% remote - Munich)',\n",
       " 'Head of Artificial Intelligence',\n",
       " 'Head of Clinical Data Management & IT (m/f/d)',\n",
       " 'Head of Data & Analytics (m/w/d)',\n",
       " 'Head of Data & Analytics - Medical Cannabis Industry',\n",
       " 'Head of Data (all genders)',\n",
       " 'Head of Data Science',\n",
       " 'Head of Data Science (f/m/x)',\n",
       " 'Head of Data Science and AI (m/w/d)',\n",
       " 'Head of IoT',\n",
       " 'Head of ML Platform & Developer Productivity (all genders)',\n",
       " 'Head of R&D (m/w/d)',\n",
       " 'Health Data Analyst*in (m/w/div)',\n",
       " 'IIoT Research Developer – Young Professional (m/w/d)',\n",
       " 'INTERDISCIPLINARY ENGINEER/SCIENTIST',\n",
       " 'IT Business Analyst for Research Labs (f/m/d)',\n",
       " 'IT Business Analyst*in Data Warehouse & Business Intelligence (in Voll- oder Teilzeit)',\n",
       " 'IT Consultant - SAP Fiori / ABAP / User Experience / CDS Views (m/w/d)',\n",
       " 'IT Consultant Energy & Utilities (m/w/d)',\n",
       " 'IT Consultant Energy (m/w/d)',\n",
       " 'IT Entwickler / Data Scientist (m/w/d) – Systembetrieb (befristet auf 2 Jahre)',\n",
       " 'IT Projektleiter / Projektmanager (mwd) DevOps',\n",
       " 'IT-Business / Data Analyst (m/f/d)',\n",
       " 'Informatiker*in (m/w/div) für den Bereich High Performance Computing (HPC) / Infrastruktur',\n",
       " 'Information Security Management Consultant mit Schwerpunkt DORA',\n",
       " 'Ingenieur (m/w/d) technische Integritätsbewertung und Datenanalyse',\n",
       " 'Ingenieur / Data-Scientist (w/m/d)',\n",
       " 'Inhouse Consultant - Schwerpunkt Datamanagement (m/w/d)',\n",
       " 'Inhouse Consultant Master Data Management Kunde/Lieferant (w/m/div.)',\n",
       " 'Initiativbewerbung',\n",
       " 'Initiativbewerbung (m/w/d)',\n",
       " 'Initiativbewerbung (w/m/d)',\n",
       " 'Initiativbewerbung Data Science /BI',\n",
       " 'Initiativbewerbung Graduates Consulting @ MHP – A Porsche Company (f/m/d)',\n",
       " 'Initiativbewerbung: Wissenschaftliche Mitarbeitende (m/w/d)',\n",
       " 'Innovation Cup 2025 - Team Drug Discovery (all genders)',\n",
       " 'Innovation Cup 2025 - Team Neuroinspired AI inference acceleration (all genders)',\n",
       " 'Insights Analyst',\n",
       " 'Instrument Scientist (Gamma Rays and UV) in Astroparticle Physics',\n",
       " 'Intern (m/f/d) - Business Intelligence / Data Warehouse',\n",
       " 'Intern (m/w/d) - Data Science in a Smart Energy Startup',\n",
       " 'Intern - Global Data and Analytics (m/f/d)',\n",
       " 'Intern AI-based Recommender Systems (f/m/x)',\n",
       " 'Intern Artificial Intelligence (m/f/d)*',\n",
       " 'Intern Business Analytics - Web & Commerce (f/m/x)',\n",
       " 'Intern Consultant Data Science and AI (m/f/d)*',\n",
       " 'Intern Data Science & AI (m/f/d)',\n",
       " 'Intern Data Science - Digital Product Offering (f/m/x)',\n",
       " 'Intern Data Science - Vehicle Testing Strategies (f/m/x)',\n",
       " 'Intern Data Science - Web & Commerce Analytics (f/m/x)',\n",
       " 'Intern Machine Learning & Computer Vision Engineer (f/m/x)',\n",
       " 'Intern automation and computer vision in microscopy (f/m/x)',\n",
       " 'Intern/WS - Product Data Science',\n",
       " 'Internationaler Datenanalyst / Projektassistenz Procurement Data Analyst (m/w/d) im internationalen Food und NON Food Einkauf',\n",
       " 'Interns Epidemic Risk Solutions (m/f/d)*',\n",
       " 'Internship - Credit Risk Analyst',\n",
       " 'Internship - Investment Product Analyst',\n",
       " 'Internship AI engineer: Product driven research',\n",
       " 'Internship Battery Analytics (all genders)',\n",
       " 'Internship Clinical Data Science with focus on Bayesian Statistics',\n",
       " 'Internship Data Analytics',\n",
       " 'Internship Data Science & Data Visualization',\n",
       " 'Internship Program Autumn 2025',\n",
       " 'Internship Program Summer 2025',\n",
       " 'Internship for Battery Data Analysis and Lab Automation (m/f/d)',\n",
       " 'Internship in Customer Preferences & Vehicle Recommendations starting February/March 2025',\n",
       " 'Internship on Business and Data Analysis (all genders)',\n",
       " 'Internship: Research & Insights (m/f/d)  - Start: April 2025',\n",
       " 'Job Offer: Account Manager (f/m/d) * - Lipotype GmbH',\n",
       " 'Junior / Medior Model Validator – Credit Risk (w/m/d)',\n",
       " 'Junior AI Platform Engineer or Working Student (all genders)',\n",
       " 'Junior Aktuar / Data Scientist für das Pricing Aktuariat (m/w/d)',\n",
       " 'Junior Aktuar/Actuarial Data Scientist Non-Motor Köln (m/w/d)',\n",
       " 'Junior Blockchain Data Scientist',\n",
       " 'Junior Business Analyst Risikomanagement (m/w/d)',\n",
       " 'Junior Business Intelligence Consultant (m/w/d)',\n",
       " 'Junior Business Intelligence Engineer (All Genders)',\n",
       " 'Junior Clinical Research Associate',\n",
       " 'Junior Cloud Data Engineer (m/w/d) – Google Looker & BigQuery',\n",
       " 'Junior Cloud Engineer (m/w/d)',\n",
       " 'Junior Consultant (m/f/d)',\n",
       " 'Junior Consultant Big Data für Weltkonzern (m/w/d)',\n",
       " 'Junior Consultant Business Intelligence (m/w/d)',\n",
       " 'Junior Credit Analyst',\n",
       " 'Junior Data & Survey Engineer (m/w/d), Quantitative Marktforschung',\n",
       " 'Junior Data Engineer',\n",
       " 'Junior Data Engineer (f/m/d)',\n",
       " 'Junior Data Engineer (m/w/d)',\n",
       " 'Junior Data Scientist',\n",
       " 'Junior Data Scientist (Data Scientist)',\n",
       " 'Junior Data Scientist (all genders)',\n",
       " 'Junior Data Scientist (m/w/d)',\n",
       " 'Junior Data Scientist (m/w/d) Reise',\n",
       " 'Junior Data Scientist (w/m/d) - Tableau',\n",
       " 'Junior Data Scientist / AI Developer (m/w/d)',\n",
       " 'Junior Data Scientist Controller (m/w/d)',\n",
       " 'Junior Data Scientist Controller (m/w/d) [JR105592]',\n",
       " 'Junior Data-Scientist (m/w/d)',\n",
       " 'Junior DevOps / Machine Learning Engineer (m/w/d)',\n",
       " 'Junior Engineer Machine Learning / Deep Learning (w/m/d)',\n",
       " 'Junior Integration Engineer // Data Engineer',\n",
       " 'Junior KI-Entwickler (w/m/d)',\n",
       " 'Junior Machine Learning Engineer (Leipzig)',\n",
       " 'Junior Managers Program - Business Intelligence und Analytics - Trainee Program (f/m/div.)',\n",
       " 'Junior Managers Program - Business Intelligence und Analytics - Trainee programm (f/m/div.)',\n",
       " 'Junior Professor of Artificial Intelligence and Machine Learning',\n",
       " 'Junior Prozessmanager (m/w/d) InsurTech',\n",
       " 'Junior Quality Lab Scientist Microbiology',\n",
       " 'Junior Scientist (DEL), Bachelor/Master',\n",
       " 'Junior Scientist Machine Learning / Deep Learning (w/m/d)',\n",
       " 'Junior Techno-Economic & Sustainability Analyst',\n",
       " 'KI Data Scientist (m/w/d)',\n",
       " 'KI-Entwickler/in - Mitarbeiter/in Künstliche Intelligenz (m/w/d)',\n",
       " 'Lab Working Student',\n",
       " 'Laboratory management (m/f/d)',\n",
       " 'Lead AI Engineer (Cloud, Machine Learning)',\n",
       " 'Lead AI Engineer | Jobs at ES-Tec GmbH',\n",
       " 'Lead Consultant AI (Ref:IgLWy)',\n",
       " 'Lead Data Scientist',\n",
       " 'Lead Data Scientist (Deep Learning)',\n",
       " 'Lead Data Scientist (all genders)',\n",
       " 'Lead Data Scientist (m/f/d)',\n",
       " 'Lead Data Scientist NLP',\n",
       " 'Lead Data Scientist, Insurance - BCG X',\n",
       " 'Lead ML Engineer',\n",
       " 'Lead ML Engineer (m/f/d)',\n",
       " 'Lead Machine Learning Engineer – Generative AI',\n",
       " 'Leitung (m/w/d) für den Sachbereich Personalmanagement und Zentralaufgaben',\n",
       " 'Life Scientist as Global Technical Support Specialist (m|f|d) French Speaking',\n",
       " 'MDM Developer (m/w/d) - Junior Data Engineer Stammdaten',\n",
       " 'ML / AI Engineer Intern (m/f/d)',\n",
       " 'ML Architect Engineer',\n",
       " 'ML Engineer',\n",
       " 'ML Engineer (f/m/d)',\n",
       " 'ML Engineer (m/f/x)',\n",
       " 'ML Ops Engineer',\n",
       " 'ML Ops Engineer - Berlin',\n",
       " 'ML Software Engineer / Data Scientist (m/w/d)',\n",
       " 'MLOps Engineer',\n",
       " 'MLOps Engineer (w/m/d) 100% remote',\n",
       " 'MRI Scientist (f/m/d)',\n",
       " 'MRI Working Student/Intern (f/m/d)',\n",
       " 'Machine Learning / AI - Engineer (F/M/D) - Hybrid Working',\n",
       " 'Machine Learning Consultant (m/f/d)',\n",
       " 'Machine Learning Engineer',\n",
       " 'Machine Learning Engineer (LLM/RAG)',\n",
       " 'Machine Learning Engineer (NLP)',\n",
       " 'Machine Learning Engineer (NLP) - Climate Tech',\n",
       " 'Machine Learning Engineer (m/f/d)',\n",
       " 'Machine Learning Engineer (m/f/x)',\n",
       " 'Machine Learning Engineer (m/w/d)',\n",
       " 'Machine Learning Engineer - Freelance',\n",
       " 'Machine Learning Engineer Autonomous Driving (m/w/d)',\n",
       " 'Machine Learning Engineer, Applied AI',\n",
       " 'Machine Learning Engineer, Fraud Prevention',\n",
       " 'Machine Learning Engineer, Search',\n",
       " 'Machine Learning Lead',\n",
       " 'Machine Learning Platform Engineers',\n",
       " 'Machine Learning Software Developer (Karlsruhe)',\n",
       " 'Machine Learning Software Engineer – Optimization & LLM Development (m/f/x)',\n",
       " 'Machine Learning Working Student - Hybrid',\n",
       " 'Machine Vision Engineer (Halcon)',\n",
       " 'Manufacturing Data Analyst',\n",
       " 'Manufacturing Data Analyst @ Deltia (Remote within Europe)',\n",
       " 'Market Researcher',\n",
       " 'Marketing Data Analyst',\n",
       " 'Marketing Data Analyst (f/m/x)',\n",
       " 'Marketing Researcher',\n",
       " 'Master Data Assistant m/w/d',\n",
       " 'Master Data Operator (Schwerpunkt: Liquor, Tobacco & Confectionary) (m/w/d)',\n",
       " 'Master Student Cryopreserved Natural Killer (NK) cell research (m|f|d)',\n",
       " 'Master of Science (M.Sc.) (m/w/d) Start 2025 Location Berlin-Potsdam (VT/STAR)',\n",
       " 'Masterarbeit',\n",
       " 'Masterarbeit im Bereich Data Science und AI Development ab Januar 2025',\n",
       " 'Masterarbeit: Schnelleres Erkennen unbekannter Gegenstände unter Wasser dank Few Shot Learning (m/w/d)',\n",
       " 'Masterprogramm Data Science & Business Analytics (all genders)',\n",
       " 'Material Development Engineer, Formulation Scientist (m/f/d)',\n",
       " 'Mathematiker:in / Physiker:in Aktuarielles Controlling',\n",
       " 'Medical Research Coordinator - MedTech Venture',\n",
       " 'Middleware Analyst / SAP Consultant PO/IS (m/w/d)',\n",
       " 'Mitarbeiter Datenanalyse im HomeOffice (m/w/d)',\n",
       " 'Mitarbeiter im Qualitätsmanagement (m/w/d) (Fachinformatiker/in - Daten- und Prozessanalyse)',\n",
       " 'Mitarbeiter/-in Projektmanagement digitaler Service / Datenanalyse (m/w/d)',\n",
       " 'Mitarbeiterin/Mitarbeiter im Bereich Zahlen- und Datenanalyse (m/w/d)',\n",
       " 'NGS Data Analyst for Molecular Oncology',\n",
       " 'NLP Engineer (m/w/d)',\n",
       " 'Network Engineers (m/f/div)',\n",
       " 'Off-Cycle Analyst Intern - Hamburg',\n",
       " 'Operations & Marketing Associate',\n",
       " 'PRAKTIKUM / PRAXISSEMESTER IM BEREICH DATA SCIENCE (M/W/D)',\n",
       " 'Performance Engineer - Laundry Care',\n",
       " 'Pflichtpraktikum im eBusiness - Business Intelligence & Digital Analyst',\n",
       " 'PhD Candidate',\n",
       " 'PhD Candidate (m/f/d): Spatial Metabolomics',\n",
       " 'Physicist Dosimetry Expert',\n",
       " 'Planer*in (m/w/d) für das Sachgebiet -Räumliche Entwicklungsplanung- im Amt für Stadtentwicklung und Statistik',\n",
       " 'Portfolio Analyst (f/m/d)',\n",
       " 'Post Doc - Data Science in Drug Discovery',\n",
       " 'PostDoc in \"A system-wide view of processes driving recent observed Southern Ocean change\" (d/f/m)',\n",
       " 'PostDoc in atmospheric physics on deep learning / foundational modelling of clouds (w/d/m)',\n",
       " 'Postdoc (gn*)',\n",
       " 'Postdoc for the investigation of biomaterial structural properties (m/f/d)',\n",
       " 'Postdoctoral Researcher (gn*)',\n",
       " 'Postdoctoral Researcher (m/f/d)',\n",
       " 'Postdoctoral Researcher (m/f/div) in Microbiome research',\n",
       " 'Postdoctoral Scientist - Metabolomics Specialist for Drug Safety - all genders - (Fixed-term contract 24 months)',\n",
       " 'Postdoctoral Scientist / Researcher (all genders) in Relativistic High-Intensity Laser-Plasma Theory and Simulation',\n",
       " 'Postdoctoral Scientist Chemistry Innovations for Oligonucleotide Delivery (m/f/d)',\n",
       " 'Postdoctoral Scientist Position (f/m/d)',\n",
       " 'Postdoctoral Scientist for Artificial Intelligence in Oncology',\n",
       " 'Postdoctoral Scientist, Amazon Robotics',\n",
       " 'Postdoctoral scientist, Atmospheric global observing system simulations',\n",
       " 'Postdoctoral | Research Scientist (W-0032)',\n",
       " 'Postdoctoral | Research Scientist (W-0033)',\n",
       " 'Postdoctural Scientist (m/f/d) for detector calibration and optimisation',\n",
       " 'Postdoktorand:in (m/w/d)',\n",
       " 'Praktikant (m/w/d) Data Science',\n",
       " 'Praktikant Data Science/Data Analytics (w/m/x)',\n",
       " 'Praktikant*in Data Engineer / Data Scientist Cloud Analytics (m/w/d)',\n",
       " 'Praktikant:in (m/w/d) im Bereich Data Science und Prozesssoptimierung',\n",
       " 'Praktikum Data Analytics  (m/w/d)',\n",
       " 'Praktikum Data Science (Schwerpunkt Machine Learning)',\n",
       " 'Praktikum Data Science / Analytics',\n",
       " 'Praktikum Data Science im Bereich Preis-, Immobilienmarkt- und Konjunkturstatistiken',\n",
       " 'Praktikum Data Scientist im Produktkomplexitätsmanagement',\n",
       " 'Praktikum im Bereich Data Science / Data Analytics',\n",
       " 'Praktikum im Bereich Machine Learning Engineer ab Februar/März 2025',\n",
       " 'Praktikum: Data Science (w/m/d)',\n",
       " 'Praktikum: Data Science und KI',\n",
       " 'Pre-Sales Consultant Datacenter - Süd (m/w/d) (Data-Consultant)',\n",
       " 'Pricing Actuary',\n",
       " 'Principal Applied Scientist - Network Optimization (all genders)',\n",
       " 'Principal Applied Scientist - Payments (all genders)',\n",
       " 'Principal Applied Scientist - Transactions Risk Management (all genders)',\n",
       " 'Principal Data Scientist (d/f/m)',\n",
       " 'Principal Data Scientist - Media Measurement (m/f/d)',\n",
       " 'Principal Data Scientist \\\\u007C Pricing',\n",
       " 'Principal Electron-Optics Research Scientist (E)',\n",
       " 'Principal Research Scientist I (all genders) Medicinal Chemistry (permanent / full-time)',\n",
       " 'Principal Research Scientist II, AI / ML Team Lead',\n",
       " 'Principal Software Engineer (d/f/m)',\n",
       " 'Principal, Same Day Long-Term Planning',\n",
       " 'Principal, Same Day, Long-term planning',\n",
       " 'Principal/Senior Scientist Non-Infectious Disease - Cardio-Metabolic Renal Disease (Research)',\n",
       " 'Process Data Analyst (m/w/d)',\n",
       " 'Process Development Engineer (m/f/d)',\n",
       " 'Process Engineer (relocation to St. Gallen, Switzerland)',\n",
       " 'Product Analyst',\n",
       " 'Product Analyst - Shopping Experience (m/f/d)',\n",
       " 'Product Analyst - Social Discovery app',\n",
       " 'Product Analyst – Business Data & Insights (m/f/d)',\n",
       " 'Product Analytics Associate (Based in Dubai)',\n",
       " 'Product Associate',\n",
       " 'Product Data Analyst (Banking + Data Quality) (w/m/d) mit 100% Homeoffice',\n",
       " 'Product Data Analyst (Savings and Contract Optimization) mit 100% Homeoffice',\n",
       " 'Product Data Science Managers',\n",
       " 'Product Lead, Platform Products',\n",
       " 'Product Lead, Pricing',\n",
       " 'Product Lead, Search',\n",
       " 'Product Manager',\n",
       " 'Product Manager (DeFi / Earn) - Web3',\n",
       " 'Product Manager (m/f/x)',\n",
       " 'Product Manager Pricing & Analytics (x/f/m)',\n",
       " 'Product Manager, DashOps (f/m/x)',\n",
       " 'Product Owner (w/d/m) - Buchhaltung & Berichte',\n",
       " 'Product Safety Specialist *',\n",
       " 'Production Technology Engineer (m/w/d)',\n",
       " 'Produkt- und Datenanalyst/in (m/w/d) (Kaufmann/-frau - Versicherungen u. Finanzen - Versicherung)',\n",
       " 'Professor for Data Science (m/f/d)',\n",
       " 'Program/Product Manager Intern',\n",
       " 'Project Management Assistant (Real World Data)',\n",
       " 'Projektingenieur - Data Scientist (m/w/d)',\n",
       " 'Projektleiter:in Künstliche Intelligenz',\n",
       " 'Projektmanager AI & Data Science',\n",
       " 'Prozess-und Betriebsdatenspezialist (m,w,d) (Berufsspezialist/in - Datenanalyse)',\n",
       " 'Prüfungsassistent / Consultant Audit & Advisory (m/w/d) mit Schwerpunkt Energy & Public',\n",
       " 'Publicis Media - (Junior) Data Scientist (m/w/d)',\n",
       " 'Python Developer',\n",
       " 'Python Developer (m/f/d) in the field of ML and AI',\n",
       " 'Python Developer / Data Scientist - Remote or Berlin based',\n",
       " 'Python Full Stack Developer',\n",
       " 'Quant Developer (f/m/d)',\n",
       " 'Quantitative Power Trading Analyst',\n",
       " 'Quantum Scientist - Superconducting Qubits (remote-ish)',\n",
       " 'R&D Internship – Data Science, ML and AI (m/f/d)',\n",
       " 'R&D Scientist (m/w/d)',\n",
       " 'RESEARCH SCIENTIST (gn) PROTEIN CRYO-EM WITH PROJECT MANAGEMENT SKILLS',\n",
       " 'Referent Netzplanungsdatenmanagement (m/w/d)',\n",
       " 'Remote (Sr.) Data Scientist Python (Django) (m/f/d)',\n",
       " 'Remote (Sr.) Python Data Scientist (m/f/d)',\n",
       " 'Research And Development Engineer',\n",
       " 'Research Assistant, Molecular Diagnostics (m/f/d)',\n",
       " 'Research Assistant/Associate (f/m/d)',\n",
       " 'Research Assistant/Associate (f/m/d) PhD students for \"Research and Development in the Field of Combustion Systems with Optical Flow Diagnostics\" (TME 130_241100)',\n",
       " 'Research Assistant/Associate (f/m/d) PhD students for \"Research and Development in the Field of Optical Flow Diagnostics\" (TME 129_241100)',\n",
       " 'Research Associate for the Project “DASHH - Data Science in Hamburg - Helmholtz Graduate School for the Structure of Matter, Particle Physics with the CMS Experiment” § 28 Subsection 3 HmbHG',\n",
       " 'Research Associate for the Project “DASHH - Data Science in Hamburg - Helmholtz Graduate School for the Structure of Matter, dAIbetes” § 28 Subsection 3 HmbHG',\n",
       " 'Research Engineer (m/w/d)',\n",
       " 'Research Engineer, Applied AI',\n",
       " 'Research Engineer/Analyst',\n",
       " 'Research Scientist (PhD m/f/d) in Nuclear Physics',\n",
       " 'Research Scientist (f/m/d)',\n",
       " 'Research Scientist BIOCHEMISTRY/BIOPHYSICS (gn)',\n",
       " 'Research Scientist BIOPHYSICS WITH FOCUS PLATE-BASED ASSAYS (gn)',\n",
       " 'Research Scientist I, Germany',\n",
       " 'Research assistant (f/m/d) - Department of Mathematics and Natural Science - Mathematics of Data Science Group - ID 142/2024',\n",
       " 'Research assistant (m/f/d)',\n",
       " 'Research assistant (m/f/d) with 75%part-time job limited to 30.09.2027 salary grade (Entgeltgruppe) 13 TV-L FU reference code: WiMi_Clementi_FAIME_2025',\n",
       " 'Research assistant for AAI and federated services project ROCK-IT',\n",
       " 'Research, Analytics, and Knowledge Management Team Lead',\n",
       " 'Researcher / Project Manager',\n",
       " 'Robotics Software Engineer all levels (m/w/d)',\n",
       " 'Robotics and Autonomous Systems / Robotics and AI Engineer',\n",
       " 'SAP Analytics Architect (gn*)',\n",
       " 'SAP Analytics Expert (gn*)',\n",
       " 'SAP Business Analyst (m/f/d) Data Migrations',\n",
       " 'SAP Consultant - Energy / Utilities / Remote (m/w/d)',\n",
       " 'SAP Inhouse (Senior) Consultant in Business Analytics (m/w/d)',\n",
       " 'SENIOR DATA SCIENTIST (F/M/D)',\n",
       " 'SEO - Data Analyst:in',\n",
       " 'Sales / Vertrieb Weiterbildung (m/w/d) - Jobchance für Remote-Workers (Teilzeit)',\n",
       " 'Sales Consultant Digital Solutions (w/m/d)',\n",
       " 'Sales Manager / Sales Development Representative (m/w/d)',\n",
       " 'Salesforce Data Analyst CRM-Marketing (m/w/d)',\n",
       " 'Scientific Data Architect / Senior Scientific Data Architect- EMEA Remote',\n",
       " 'Scientific Software Engineer (f/m/x)',\n",
       " 'Scientist (Postdoc) for Scanning Microprobe Endstation at Beamline P25, PETRA III',\n",
       " 'Scientist (f/m/d) in vitro DMPK',\n",
       " 'Scientist (f/m/d)- LC-MS: Drug Product Characterization for Biopharmaceuticals',\n",
       " 'Scientist (m/f/d) for the area Immunoassays (full-time)',\n",
       " 'Scientist (m/f/div) Bioprocess Development RDI-Projects',\n",
       " 'Scientist - In vivo Pharmacology (m/w/x)',\n",
       " 'Scientist - Protein Analytics',\n",
       " 'Scientist / Postdoc (m/f/d): Analysis of Microscopic BIOMedical Images (AMBIOM)',\n",
       " 'Scientist / Postdoc in bioinformatics (m/f/d) Institute Molekularbiologie',\n",
       " 'Scientist / Study Director (all genders)',\n",
       " 'Scientist Biotic Stress Trait Development (m/f/d)',\n",
       " 'Scientist Digital Imaging (m/f/d), Referenz: „51001-24-03-WAPRO“',\n",
       " 'Scientist III, Field Applications',\n",
       " 'Scientist Viral Vector Production',\n",
       " 'Scientist at innoFSPEC, AIP Technology Transfer',\n",
       " 'Scientist in the field of fiber drawing technology for active fibers',\n",
       " 'Scientist in the field of fiber drawing technology for active fluoride fibers',\n",
       " 'Scientist in the field of fiber preform development for active fibers',\n",
       " 'Scientist – DNA-, RNA- Oligonucleotide Synthesis (x/f/m)',\n",
       " 'Scientist – Optical Design and Simulation',\n",
       " 'Scientist/DevOps Position in EScience Section (w/m/d)',\n",
       " 'Scientist/DevOps in EScience Section (w/m/d)',\n",
       " 'Scientist/Research-Associate – Retinal Gene Therapy (m/f/x)',\n",
       " 'Semantics Engineer (f/m/x)',\n",
       " 'Senior AI & Data Science Consultant',\n",
       " 'Senior AI / ML Engineer (w/m/d)',\n",
       " 'Senior AI Developer f/m/d',\n",
       " 'Senior AI Engineer',\n",
       " 'Senior AI Engineer (m/f/d)',\n",
       " 'Senior AI Scientist (f/m/d): SAP Business AI - SAP Knowledge Graph',\n",
       " 'Senior Analyst / Engineer (m/w/d) im Bereich IT Data Analytics & Integration',\n",
       " 'Senior Analytical Scientist (m/f/d)',\n",
       " 'Senior Analytics Engineer (m/f/d)',\n",
       " 'Senior Applied Scientist - Fulfilment Planning (all genders)',\n",
       " 'Senior Applied Scientist, ATS Science and Technology',\n",
       " 'Senior Applied Scientist, Amazon Robotics R&D',\n",
       " 'Senior Applied Scientist, Artificial General Intelligence',\n",
       " 'Senior Applied Scientist, Logistics',\n",
       " 'Senior Applied Scientist- Network Optimization (all genders)',\n",
       " 'Senior Associate Quantitative Analyse (all genders)',\n",
       " 'Senior Backend Developer (w/m/d)',\n",
       " 'Senior Big Data Engineer (m/w/d)',\n",
       " 'Senior Cloud Data Engineer (all genders)',\n",
       " 'Senior Consultant / Manager (Gen) AI & Data Scientist | AI Garage (m/w/d)',\n",
       " 'Senior Consultant / Solution Architect Data Management Manufacturing (all genders)',\n",
       " 'Senior Consultant / Solution Architect Data Management Manufacturing (all genders) 3',\n",
       " 'Senior Consultant Data Analytics, gern Informatiker:in, Mathematiker:in oder erfahrener Data Analyst',\n",
       " 'Senior Consultant Data Management (w/m/d)',\n",
       " 'Senior Consultant IT Regulatory Risk / Risikomanagement (m/w/d)',\n",
       " 'Senior Consultant SAP Data & Analytics (m/w/d)',\n",
       " 'Senior Controller Projektmanagement (m/w/d) [JR105408]',\n",
       " 'Senior Controlling Data Scientist (m/w/d)',\n",
       " 'Senior Data / Machine-Learning Engineer (w/m/d)',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst (m/f/d)',\n",
       " 'Senior Data Architect (m/d/w)',\n",
       " 'Senior Data Consultant (m/w/d)',\n",
       " 'Senior Data Engineer (Python)',\n",
       " 'Senior Data Engineer (f/m/x)',\n",
       " 'Senior Data Engineer (m/f/d)',\n",
       " 'Senior Data Engineer (m/w/d)',\n",
       " 'Senior Data Engineer (w/m/d)',\n",
       " 'Senior Data Engineer Advanced Analytics (m/f/d)',\n",
       " 'Senior Data Engineer Azure & Snowflake in Mainz m/w/d (Data Engineer)',\n",
       " 'Senior Data Engineer Python/ML/AWS (m/f/d)- Remote',\n",
       " 'Senior Data Engineer* / Machine Learning Engineer*',\n",
       " 'Senior Data Engineering Consultant (m/w/d)',\n",
       " 'Senior Data Quality Consultant (m/w/d) gesucht - curexus',\n",
       " 'Senior Data Science Consultant',\n",
       " 'Senior Data Science Consultant (m/w/d)',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist (M/W/D) NLP in München',\n",
       " 'Senior Data Scientist (Recommendation Systems Expert) (f/m/d)',\n",
       " 'Senior Data Scientist (SOC / carbon modelling)',\n",
       " 'Senior Data Scientist (d/f/m)',\n",
       " 'Senior Data Scientist (d/f/m) - Large-scale Machine Learning',\n",
       " 'Senior Data Scientist (f/m/d)',\n",
       " 'Senior Data Scientist (f/m/x)',\n",
       " 'Senior Data Scientist (m/f/d)',\n",
       " 'Senior Data Scientist (m/f/d) - Business Intelligence Application',\n",
       " 'Senior Data Scientist (m/f/x)',\n",
       " 'Senior Data Scientist (m/w/d)',\n",
       " 'Senior Data Scientist (m/w/d) - ID: 233',\n",
       " 'Senior Data Scientist (m/w/d) im Automotive Bereich',\n",
       " 'Senior Data Scientist (m/w/d) – Risikomodelle',\n",
       " 'Senior Data Scientist (mwd)',\n",
       " 'Senior Data Scientist (w/m/d)',\n",
       " 'Senior Data Scientist (w/m/d) | hybrid (office/remote)',\n",
       " 'Senior Data Scientist * Generative AI',\n",
       " 'Senior Data Scientist - Conversational AI (German Speaking)(x/f/m) - AI Teams',\n",
       " 'Senior Data Scientist - Data & AI (f/m/d)',\n",
       " 'Senior Data Scientist - Fraud & Credit Risk (m/f/d)',\n",
       " 'Senior Data Scientist - Operations Research',\n",
       " 'Senior Data Scientist - Remote from Germany',\n",
       " 'Senior Data Scientist - Time Estimations, Logistics (all genders)',\n",
       " 'Senior Data Scientist / AI Developer (m/w/d)',\n",
       " 'Senior Data Scientist / Senior Software Technology Engineer',\n",
       " 'Senior Data Scientist / Senior Software Technology Engineer*',\n",
       " 'Senior Data Scientist Generative AI (m/w/d)',\n",
       " 'Senior Data Scientist NLP/GenAI (m/w/d)',\n",
       " 'Senior Data Scientist for Innovative Digital Product (m/f/d)',\n",
       " 'Senior Data Scientist mit Schwerpunkt Ökonometrie/ Predictive Analytics (gn*)',\n",
       " 'Senior Data Scientist – Energy Storage / Li-ion / Battery Technologies',\n",
       " 'Senior Data Scientist – Supply & Demand Modelling',\n",
       " 'Senior Data Scientist, AI-Experte für Natural Language Processing',\n",
       " 'Senior Data Scientist, Campaigns',\n",
       " 'Senior Data Scientist, Payments Product',\n",
       " 'Senior Data Scientist, gTech Ads',\n",
       " 'Senior Data Scientist- Optimization (d/f/m)',\n",
       " 'Senior Database Engineer (m/w/d) (Data Engineer)',\n",
       " 'Senior Engineer Machine Learning / Deep Learning (w/m/d)',\n",
       " 'Senior Essential Adoption Service Consultant (w/m/d) - Data Science, Automation & Technology',\n",
       " 'Senior Full-Stack Data Analytics/Data Science Expert*in im Competence Center Digital Accelerator im Mercedes-Benz Management Consulting (d/m/w/x)',\n",
       " 'Senior ML / AI Engineer',\n",
       " 'Senior ML Engineer',\n",
       " 'Senior ML Engineer, AWS Generative AI Innovation Center',\n",
       " 'Senior Machine Learning Data Scientist (d/m/f)',\n",
       " 'Senior Machine Learning Engineer',\n",
       " 'Senior Machine Learning Engineer (m/w/d)',\n",
       " 'Senior Machine Learning Engineer DevOps/MLOps (m/w/d)',\n",
       " 'Senior Machine Learning Scientist for GenAI (m/w/d)',\n",
       " 'Senior Manager, Safety Scientist (m/f/x)',\n",
       " 'Senior Operations Research Scientist',\n",
       " 'Senior People Data Scientist (All genders) - Global People Analytics team',\n",
       " 'Senior Product Manager (m/f/d)',\n",
       " 'Senior Product Manager - Fraud Prevention',\n",
       " 'Senior Python Developer (LLM-based applications, SME)',\n",
       " 'Senior Quant Developer (f/m/d)',\n",
       " 'Senior Regional Marketing Manager',\n",
       " 'Senior Remote Sensing Scientist',\n",
       " 'Senior Research Scientist (permanent, E15 pay scale)',\n",
       " 'Senior Research Scientist in vitro neurophysiology',\n",
       " 'Senior Scientist',\n",
       " 'Senior Scientist (m/f/d) Molecular Complex Development',\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The level of seniority will be extracted from information provided in the raw job titles.\n",
    "#  E.g.: \"(Junior) AI Engineer\", \"Senior Data Scientist\"\n",
    "np.sort(df[\"title\"].unique()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seniority_level\n",
       "NaN                  829\n",
       "Mid-Senior level     269\n",
       "Entry level          250\n",
       "Associate            100\n",
       "Internship            96\n",
       "Not Applicable        58\n",
       "Director              16\n",
       "Executive              7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some job platforms already provided the information of seniority level\n",
    "df[\"seniority_level\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"seniority_level\"] = df[\"seniority_level\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search words and associated seniority\n",
    "seniority_dict = {\n",
    "    \"Senior\": \"Senior\",\n",
    "    \"Sen.\": \"Senior\",\n",
    "    \"Sr.\": \"Senior\",\n",
    "    \"(Advanced)\": \"Senior\",\n",
    "    \"Teamlead\": \"Senior\",\n",
    "\n",
    "    \"Junior\": \"Junior\",\n",
    "    \"Jun.\": \"Junior\",\n",
    "    \"Jr.\": \"Junior\",\n",
    "    \"Trainee\": \"Trainee\",\n",
    "    \"Internship\": \"Intern\",\n",
    "    \"Intern\": \"Intern\",\n",
    "    \"Praktikum\": \"Intern\",\n",
    "    \"PRAKTIKUM\": \"Intern\",\n",
    "    \"Praktikant\": \"Intern\",\n",
    "\n",
    "    \"Head\": \"Director\",\n",
    "    \"Lead\": \"Director\",\n",
    "    \"Principal\": \"Director\",\n",
    "    \"Director\": \"Director\",\n",
    "\n",
    "    \"Abschlussarbeit\": \"Student\", \n",
    "    \"Working student\": \"Student\", \n",
    "    \"Working Student\": \"Student\", \n",
    "    \"Werkstudent\": \"Student\", \n",
    "    \"WERKSTUDENT\": \"Student\", \n",
    "    \"Doktorand\": \"Student\", \n",
    "    \"Doctoral\": \"Student\", \n",
    "    \"Bachelor\": \"Student\",\n",
    "    \"Studium\": \"Student\",\n",
    "\n",
    "    \"Post Doc\": \"Postdoc\",\n",
    "    \"Postdoc\": \"Postdoc\", \n",
    "    \"PostDoc\": \"Postdoc\",\n",
    "    \"Wissenschaftliche/r Mitarbeiter/in\": \"Postdoc\",\n",
    "    \"Wissenschaftlicher Mitarbeiter\": \"Postdoc\",\n",
    "}\n",
    "\n",
    "df[\"seniority_level_new\"] = pd.NA\n",
    "\n",
    "for search_term, seniority in seniority_dict.items():\n",
    "    df.loc[df[\"title\"].str.contains(search_term, regex=False), \"seniority_level_new\"] = seniority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>seniority_level_new</th>\n",
       "      <th>seniority_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Entry level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Intern</td>\n",
       "      <td>Entry level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Junior Data Scientist / AI Developer (m/w/d)</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Entry level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Junior Engineer Machine Learning / Deep Learni...</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Junior Data Scientist (w/m/d) - Tableau</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Entry level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>Senior Database Engineer (m/w/d) (Data Engineer)</td>\n",
       "      <td>Senior</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>(Senior) Data Engineer (m/w/d) (Informatiker/in)</td>\n",
       "      <td>Senior</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Senior</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>Senior Quant Developer (f/m/d)</td>\n",
       "      <td>Senior</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>Senior Regional Marketing Manager</td>\n",
       "      <td>Senior</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title seniority_level_new   \n",
       "1                                 Junior Data Scientist              Junior  \\\n",
       "3                                 Data Scientist Intern              Intern   \n",
       "6          Junior Data Scientist / AI Developer (m/w/d)              Junior   \n",
       "7     Junior Engineer Machine Learning / Deep Learni...              Junior   \n",
       "10              Junior Data Scientist (w/m/d) - Tableau              Junior   \n",
       "...                                                 ...                 ...   \n",
       "1618   Senior Database Engineer (m/w/d) (Data Engineer)              Senior   \n",
       "1619   (Senior) Data Engineer (m/w/d) (Informatiker/in)              Senior   \n",
       "1620                   Senior Machine Learning Engineer              Senior   \n",
       "1623                     Senior Quant Developer (f/m/d)              Senior   \n",
       "1624                  Senior Regional Marketing Manager              Senior   \n",
       "\n",
       "     seniority_level  \n",
       "1        Entry level  \n",
       "3        Entry level  \n",
       "6        Entry level  \n",
       "7          Associate  \n",
       "10       Entry level  \n",
       "...              ...  \n",
       "1618             NaN  \n",
       "1619             NaN  \n",
       "1620             NaN  \n",
       "1623             NaN  \n",
       "1624             NaN  \n",
       "\n",
       "[699 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"seniority_level_new\"].isna() == False, [\"title\", \"seniority_level_new\", \"seniority_level\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['(Associate) Consultant (Gen) AI & Data Scientist | AI Garage (m/w/d)',\n",
       "       '(Cloud) Data Engineer / BI Developer (m/w/d) (m/w/d)',\n",
       "       '(Wirtschafts-)Mathematiker, Statistiker, Data Scientist für die Tarifentwicklung Komposit',\n",
       "       '1D/2D MATERIAL SCIENTIST (M/F/D)',\n",
       "       '2025 Software Development Engineer - Machine Learning (m/w/d)',\n",
       "       'ACTUARIAL DATA SCIENTIST (M/W/D)', 'AI & Data - Analyst',\n",
       "       'AI (Agent) Engineer (f/m/d) | Jobs at VisionAI - Jobs',\n",
       "       'AI Architect & Optimization Specialist (m/w/d)',\n",
       "       'AI Architect / Machine Learning Engineer (m,f,d)',\n",
       "       'AI Cloud Engineer', 'AI Consultant', 'AI Developer',\n",
       "       'AI Developer (m/w/d)', 'AI Engineer', 'AI Engineer (m/w/d)',\n",
       "       'AI Engineer - Germany (Remote)',\n",
       "       'AI Engineer / AI Developer (m/w/d) bei einem SaaS-Unternehmen aus Würzburg (Full-Remote oder vor Ort)',\n",
       "       'AI Engineer / Data Scientist m|w|d',\n",
       "       'AI Engineer // Data Scientist (all genders)',\n",
       "       'AI Engineer for AI Startup',\n",
       "       'AI Engineer mit Schwerpunkt NLP (m/w/d)',\n",
       "       'AI Experience Researcher (m/f/d)',\n",
       "       'AI Platform Engineer (all genders)',\n",
       "       'AI Research Scientist - Generative AI Red Teaming (London or Paris)',\n",
       "       'AI Researcher', 'AI Software Developer in Test (f/m/d)',\n",
       "       'AI Software Engineer', 'AI Software Engineer (w/m/x)',\n",
       "       'AI consultant  - Energy', 'AI-Engineer/Vollzeit',\n",
       "       'AI/ML Engineer - Biomedical AI (m/f/d)',\n",
       "       'AI\\xa0computational\\xa0\\xa0material\\xa0\\xa0researcher/expert',\n",
       "       'Account Manager:in für Sound Branding, Podcasts und Audiospots',\n",
       "       \"Aignostics' Talent Community\",\n",
       "       'Aktuar (DAV)/Data Scientist (d/w/m) - Krankenversicherungen & Data Warehouse',\n",
       "       'Analyst & Marketing Technology Manager (d/w/m)',\n",
       "       'Analyst (m/w/d) Short Term Trading in Renewable Energies',\n",
       "       'Analyst - Fokus Data Science / AI (m/w/d)', 'Analytics Engineer',\n",
       "       'Analytics Engineer (m/f/d)', 'Analytics Engineer (m/w/d)',\n",
       "       'Analytics Engineer (m|w|d) im Bereich Business Intelligence & Web Analytics',\n",
       "       'Analytics Engineer (w/m/d)',\n",
       "       'Analytics Engineer - Graduate (Hybrid; m/f/x/d)',\n",
       "       'Analytics and Insight Professional, Amazon Advertising, Analytics and Insights',\n",
       "       'Applied Machine Learning Engineers',\n",
       "       'Applied Scientist II (L5), AFT AI, Amazon AFT AI',\n",
       "       'Applied Scientist for Probabilistic Machine Learning and Human-Computer Interaction',\n",
       "       'Applied Scientist, ATS Machine Learning & Engineering',\n",
       "       'Applied Scientist, Amazon Nova',\n",
       "       'Applied Scientist, Amazon Robotics R&D',\n",
       "       'Applied Scientist, Artificial General Intelligence, AGI Information',\n",
       "       'Applied Scientist, Content Systems Science and Engineering, Amazon',\n",
       "       'Applied Scientist, Fintech (Fraud)',\n",
       "       'Artificial Intelligence Engineer',\n",
       "       'Artificial Intelligence Specialist',\n",
       "       'Artificial Intelligence Specialist (w/m/d)',\n",
       "       'Artificial Intelligence and Machine learning Business & Data Analyst',\n",
       "       'Assistant (m/f/d) Databases and Data Analysis',\n",
       "       'Associate - Index Operations (m/f/d)',\n",
       "       'Associate Data Analyst (f/m/d)',\n",
       "       'Associate Data Science & Management Consultant',\n",
       "       'Associate Special Project, Esports',\n",
       "       'Atomic, Molecular, and Optical Physicist',\n",
       "       'BI & Data Modeling Expert (m/f/d)', 'BI Analyst (all genders)',\n",
       "       'BI Analyst (m/w/d)', 'BI Business Analyst (m/f/d)',\n",
       "       'BI Manager (m/w/d) Data Science/Data Analytics',\n",
       "       'Backend Developer (m/f/d)',\n",
       "       'Backend Software Engineer - Remote (m/f/d)',\n",
       "       'Backend/ML Software Engineer (Entry to Mid-Level) - Remote',\n",
       "       'Battery Scientist (m/f/x)', 'Bench Scientist (all genders)',\n",
       "       'Beschäftigte/r Qualitätsmanagement und Datenanalyse (m/w/d)',\n",
       "       'Big Data Architect (m/w/d)',\n",
       "       'Big Data DevOps Engineer (m/w/d) | (DSIDMG)',\n",
       "       'Bilanzmathematiker / Statistiker (m/w/d)',\n",
       "       'Binance Accelarator Program - LLM Data Scientist',\n",
       "       'Bioinformatician',\n",
       "       'Bioinformatician (m/f/d) in immunopeptidomics',\n",
       "       'Bioinformatician (m/f/div) Immunogenetics',\n",
       "       'Breeding Informatics Analyst (d/f/m) Full Time - in Tübingen',\n",
       "       'Business  Development Manger', 'Business & Data Analyst (f/m/x)',\n",
       "       'Business / Data Analyst (m/w/d)',\n",
       "       'Business / Data Analyst (w/m/d) Real Estate Consulting Digitalisierungsberatung',\n",
       "       'Business Analyst',\n",
       "       'Business Analyst (m/w/d) - im Team Data Science Solutions',\n",
       "       'Business Analyst (m/w/d) – Data Analytics Vertriebsplanung | Banking',\n",
       "       'Business Analyst - Marketing Planning und Forecasting (m/w/d)',\n",
       "       'Business Analyst / Controller',\n",
       "       'Business Analyst Data Management (w/m/d)',\n",
       "       'Business Analyst – Data Quality (w/m/d)', 'Business Data Analyst',\n",
       "       'Business Data Analyst & Engineer (m/w/d)',\n",
       "       'Business Data Analyst (m/w/d) im LSZ - Qualität und Support, Referat Stab Reporting und Controlling',\n",
       "       'Business Intelligence & Analytics Manager',\n",
       "       'Business Intelligence / Data Analytics-& Management Consultant',\n",
       "       'Business Intelligence Analyst (m/w/d)',\n",
       "       'Business Intelligence Analyst (w/d/m) mit Schwerpunkt Sales',\n",
       "       'Business Intelligence Consultant',\n",
       "       'Business Intelligence Developer (m/w/d) Tech / E-Commerce',\n",
       "       'Business Intelligence Engineer',\n",
       "       'Business Intelligence Engineer (BIE), Supply Chain Outbound Execution',\n",
       "       'Business Intelligence Engineer (m/w/d)',\n",
       "       'Business Intelligence Engineer (w/m/d)',\n",
       "       'Business Intelligence Engineer*',\n",
       "       'Business Intelligence Engineer, Transportation, Global Transportation Services',\n",
       "       'Business Intelligence Engineer, WHS Data',\n",
       "       'Business Intelligence Expert F-35 (m/w/d)',\n",
       "       'Business Intelligence Manager (m/w/d)',\n",
       "       'Business Intelligence Specialist (m/w/x)',\n",
       "       'Business Intelligence Workshop',\n",
       "       'Business Intelligence und Data Analyst (m/w/d)',\n",
       "       'Business Process Analyst – Marketing & Sales (f/m/d)',\n",
       "       'Business Relationship Manager BI and Data Science (m/w/d)',\n",
       "       'CO-Data Scientist (m/w/d)',\n",
       "       'COMPUTATIONAL GENOMICS SCIENTIST (m/f/d), Referenz: „51004-24-05-WAPRO“',\n",
       "       'CRA/SCRA', 'CRM Data Specialist *',\n",
       "       'Carbon Project Risk Analyst (f/d/m)',\n",
       "       'Certified Strength and Conditioning Specialist',\n",
       "       'Chemical Technical Assistant (f/m/d)', 'Chief AI Engineer',\n",
       "       'Chief Commercial Officer - AI (Berlin)',\n",
       "       'Chief Data Officer (m/w/d)', 'Chief Technology Officer',\n",
       "       'Chief Technology Officer - Must be based in Germany',\n",
       "       'Cloud & Machine Learning Consultant (m/f/d)',\n",
       "       'Cloud Big Data Engineer / DevOps Engineer (m/w/d)',\n",
       "       'Cloud Engineer m/w/d', 'Computational Biologist (m/f/d)',\n",
       "       'Computational Materials Scientist* (m/f/d)',\n",
       "       'Computational Scientist – (Machine Learning) Digital R&D Large Molecule Research',\n",
       "       'Computer Scientist | InformatikerIn | Software EntwicklerIn für klinische KI-Forschung und Anwendung',\n",
       "       'Computer Scientist – Mendel Verlag', 'Computer Vision Engineer',\n",
       "       'Consultant (w/m/d) Energy, Environment & Telecommunication',\n",
       "       'Consultant - Digital Analytics (m/w/d) for Hamburg',\n",
       "       'Consultant AI & Analytics',\n",
       "       'Consultant AI & Data Analytics / Data Science (m/w/d)',\n",
       "       'Consultant AI & Data Analytics / Data Science (m/w/d) in Berlin',\n",
       "       'Consultant AI & Data Analytics / Data Science (m/w/d) in Frankfurt (Main)',\n",
       "       'Consultant AI & Data Analytics / Data Science (m/w/d) in Hamburg',\n",
       "       'Consultant AI & Data Analytics / Data Science (m/w/d) in München',\n",
       "       'Consultant Data Science Credit Risk (m/w/d) in Berlin',\n",
       "       'Consultant Datamanagement & Data Analyst (m/w/d)',\n",
       "       'Consultant Datamanagement & Data Analyst m/w/d',\n",
       "       'Consultant Künstliche Intelligenz / Artificial Intelligence Energy (m/w/d)',\n",
       "       'Consultant im Bereich Energy, Transformation & Sustainability (m/w/x)',\n",
       "       'Create a DataCamp Course - Cloud (Part-Time, Freelance)',\n",
       "       'Customer Data Consultant (m/w/d)', 'DATA ANALYST (M/W/D)',\n",
       "       'DATA ANALYST:IN (m/w/d)', 'DATA ENGINEER (M/W/D)',\n",
       "       'DATA ENGINEER M/W/D', 'DATA SCIENCE MANAGER*',\n",
       "       'DATA SCIENTIST (M/F/D)', 'DATA SCIENTIST (M/W/D)',\n",
       "       'DATA SCIENTIST (M/W/D) SMART PROCESS AUTOMATION',\n",
       "       'DATA SCIENTIST ENGINEER (M/W/D) DIGITAL SOLUTIONS – BRAUNSCHWEIG, BERLIN',\n",
       "       'DH-STUDIERENDE FÜR DATA SCIENCE & KÜNSTLICHE INTELLIGENZ 2025 (M/W/D)',\n",
       "       'DWH Analyst (all genders)', 'DWH-Entwickler (m/w/d)',\n",
       "       'Data & AI Business Consultant (m/w/d)', 'Data & AI Scientist',\n",
       "       'Data & AI Scientist Personalized Computational Genomics (all genders)',\n",
       "       'Data & AI Strategist (m/f/d)',\n",
       "       'Data / Analytics Engineer (m/w/d)',\n",
       "       'Data Analysis / Data Engineering / Data Science (M/F/D)',\n",
       "       'Data Analysis Expert Battery Test Field (all genders)',\n",
       "       'Data Analysis, Modeling & Simulation Engineer (f/m/d)',\n",
       "       'Data Analyst',\n",
       "       'Data Analyst (all gender) – Process Mining und Datenanalyse',\n",
       "       'Data Analyst (all genders)', 'Data Analyst (m/f/d)',\n",
       "       'Data Analyst (m/f/d) Search',\n",
       "       'Data Analyst (m/f/d) at Allianz SE',\n",
       "       'Data Analyst (m/f/d) in IT security company',\n",
       "       'Data Analyst (m/w/d)', 'Data Analyst (m/w/d) (Job-ID 2022099)',\n",
       "       'Data Analyst (m/w/d) / Remote möglich',\n",
       "       'Data Analyst (m/w/d) Berlin, Hamburg, Munich',\n",
       "       'Data Analyst (m/w/d) Telematikdaten', 'Data Analyst (w/m/d)',\n",
       "       'Data Analyst - MS Tech Stack', 'Data Analyst - Product',\n",
       "       'Data Analyst / Data Engineer (m/f/d)',\n",
       "       'Data Analyst / Data Scientist (m/w/d)',\n",
       "       'Data Analyst / Decision Scientist, Digital Marketing',\n",
       "       'Data Analyst / Decision Scientist, Policy',\n",
       "       'Data Analyst / Scientist (Microsoft PowerBI und MS SQL Server)',\n",
       "       'Data Analyst / Scientist (m/w/d) für die Energietransformation',\n",
       "       'Data Analyst Battery Cell Testing (all genders)',\n",
       "       'Data Analyst Campaigning (w/m/d)',\n",
       "       'Data Analyst bei Siemens (m/w/d)', 'Data Analyst m/f/d',\n",
       "       'Data Analyst/Market Researcher',\n",
       "       'Data Analyst/Scientist (m/w/d) für die Energietransformation',\n",
       "       'Data Analyst:in Münster/Köln/Berlin/Remote (DE)',\n",
       "       'Data Analytics Architect (w/m/d)',\n",
       "       'Data Analytics Consultant (m/w/d)',\n",
       "       'Data Analytics Consultant Frontend (m/w/d)',\n",
       "       'Data Analytics Engineer', 'Data Analytics Specialist (d/w/m)',\n",
       "       'Data Analytics Specialist (m/f/d)', 'Data Architect (m/f/d)',\n",
       "       'Data Architect (m/w/d)',\n",
       "       'Data Architect AI/ML (m/w/d) | Jobs bei Pexon Consulting GmbH',\n",
       "       'Data Architekt (m/w/d)',\n",
       "       'Data Architekt / Data Engineer / Data Scientist (m/w/d)',\n",
       "       'Data Assimilation Scientist', 'Data Consultant (m/w/d)',\n",
       "       'Data Consultant (w/m/d)',\n",
       "       'Data Driven Business Consultant - Automotive (m/w/d)',\n",
       "       'Data Engineer', 'Data Engineer (English speaking)(M/F/D)',\n",
       "       'Data Engineer (d/f/m)', 'Data Engineer (f/m/d)',\n",
       "       'Data Engineer (f/m/x)', 'Data Engineer (m/w/d)',\n",
       "       'Data Engineer (m/w/d) Tech / E-Commerce', 'Data Engineer (w/m/d)',\n",
       "       'Data Engineer - Recommendation Systeme (m/w/d)',\n",
       "       'Data Engineer / Analyst', 'Data Engineer / Data Analyst (m/w/d)',\n",
       "       'Data Engineer / Data Scientist (M/F/D)',\n",
       "       'Data Engineer / Scientist (m/w/d)',\n",
       "       'Data Engineer Big Data (all genders)',\n",
       "       'Data Engineer Schwerpunkt Kundenpersonalisierung (m/w/d)',\n",
       "       'Data Engineer* / Machine Learning Engineer*',\n",
       "       'Data Engineering Consultant', 'Data Enthusiast (m/w/d)',\n",
       "       'Data Integrity Specialist Pharma (m/w/d)', 'Data Product Manager',\n",
       "       'Data Quality Manager (m/f/x)', 'Data Reporting Analyst',\n",
       "       'Data Science Analyst (m/w/d)', 'Data Science Consultant (m/w/d)',\n",
       "       'Data Science Consultant - QuantumBlack, AI by McKinsey',\n",
       "       'Data Science Graduate',\n",
       "       'Data Science and AI Mentor (Freelance, Remote)',\n",
       "       'Data Science und KI - Smart Operations Management\\xa0(m/w/d)',\n",
       "       'Data Scientist',\n",
       "       'Data Scientist & Machine Learning Engineer (m/w/d)',\n",
       "       'Data Scientist & Machine Learning Engineer (w|m|d)',\n",
       "       'Data Scientist (Growth Team)', 'Data Scientist (aGw*)',\n",
       "       'Data Scientist (all gender)', 'Data Scientist (all genders)',\n",
       "       'Data Scientist (alle Geschlechter)', 'Data Scientist (d/f/m)',\n",
       "       'Data Scientist (d/m/w) Short-Term Asset Trading',\n",
       "       'Data Scientist (d/w/m)', 'Data Scientist (f/m/d)',\n",
       "       'Data Scientist (f/m/x)', 'Data Scientist (jun. / sen.)',\n",
       "       'Data Scientist (m/f/d)', 'Data Scientist (m/f/x)',\n",
       "       'Data Scientist (m/w/d)',\n",
       "       'Data Scientist (m/w/d) (Data Scientist)',\n",
       "       'Data Scientist (m/w/d) (Job-ID 2023061)',\n",
       "       'Data Scientist (m/w/d) - Sektion für Hämatologische Spezialdiagnostik',\n",
       "       'Data Scientist (m/w/d) Smart Process Automation',\n",
       "       'Data Scientist (m/w/d) in Hamburg | EPROFESSIONAL',\n",
       "       'Data Scientist (m/w/d) in den Bereichen NLP und LLM (Entwicklung/ Betrieb, Kompetenzaufbau und Support)',\n",
       "       'Data Scientist (m/w/d) mit Fokus auf Big Data und KI',\n",
       "       'Data Scientist (m/w/d) zur Auswertung und Analyse von komplexen Messdaten',\n",
       "       'Data Scientist (m/w/x)', 'Data Scientist (mwd)',\n",
       "       'Data Scientist (w/m/d)',\n",
       "       'Data Scientist (w/m/d) - Schwerpunkt Customer Intelligence',\n",
       "       'Data Scientist - 24 month contract',\n",
       "       'Data Scientist - Consumer (Global Discovery)',\n",
       "       'Data Scientist - Customer Data Platform (all genders)',\n",
       "       'Data Scientist - Customer Success Projects (ValueWorks)',\n",
       "       'Data Scientist - Data Engineering (m/w/d)',\n",
       "       'Data Scientist - Datenmanagement (m/w/d)- AOK Bayern - Die Gesundheitskasse',\n",
       "       'Data Scientist - LLM', 'Data Scientist - Lexware Office (w/d/m)',\n",
       "       'Data Scientist - Portfolio Analyst & Product Owner (m/f/d)*',\n",
       "       'Data Scientist - Process Mining (m/w/d)',\n",
       "       'Data Scientist - Ranking', 'Data Scientist - Startup Berlin',\n",
       "       'Data Scientist - Supply Chain & Procurement',\n",
       "       'Data Scientist - Time Estimations, Logistics (all genders)',\n",
       "       'Data Scientist / AI Developer (m/w/d)',\n",
       "       'Data Scientist / Analyst (m/w/d)',\n",
       "       'Data Scientist / Biostatistician (m/f/d)',\n",
       "       'Data Scientist / Data Analyst (m/w/d)',\n",
       "       'Data Scientist / Data Engineer (Python) (m/w/d)',\n",
       "       'Data Scientist / Engineer (gn)',\n",
       "       'Data Scientist / Engineer (m/w/d)',\n",
       "       'Data Scientist / Engineer mit LLM-Fokus (m/w/d)',\n",
       "       'Data Scientist / ML Engineer (m/ f/ d)',\n",
       "       'Data Scientist / Machine Learning Expert (m/w/d)',\n",
       "       'Data Scientist / Softwareentwickler (m/w/d)',\n",
       "       'Data Scientist 100%', 'Data Scientist Automotive (m/w/d)',\n",
       "       'Data Scientist Consultant (m/f/d)',\n",
       "       'Data Scientist Consultant (m/w/d)',\n",
       "       'Data Scientist Datenmanagement',\n",
       "       'Data Scientist Digital Health ‒ Strategie, Analyse & Infrastruktur (m/w/d)',\n",
       "       'Data Scientist NLP and Text Mining (f/m/d)',\n",
       "       'Data Scientist Natural Language Processing (m/w/d)',\n",
       "       'Data Scientist Online Analytics',\n",
       "       'Data Scientist Optical Spectroscopy (w/m/d)',\n",
       "       'Data Scientist Pathologisches Institut',\n",
       "       'Data Scientist als Modellentwickler Einsatzplanung Energiesysteme (w|m|d)',\n",
       "       'Data Scientist and Process Mining Architect',\n",
       "       'Data Scientist für das Pathologische Institut',\n",
       "       'Data Scientist in Energy Tech Start Up - hybrid Berlin based (f/m/d)',\n",
       "       'Data Scientist mit Fokus auf datengetriebenes Marketing',\n",
       "       'Data Scientist mit Schwerpunkt Datenarbeit (m/w/d)',\n",
       "       'Data Scientist mit Schwerpunkt Operationalisierung (m/w/d)',\n",
       "       'Data Scientist w/m/d',\n",
       "       'Data Scientist with focus Clinical Statistics (f/m/d - part/full-time)',\n",
       "       'Data Scientist – AI Engineer (m/w/d)',\n",
       "       'Data Scientist – CRM / Kundenbeziehungsmanagement (m/w/d)',\n",
       "       'Data Scientist – Supply & Demand Modelling',\n",
       "       'Data Scientist*in (m/w/d)',\n",
       "       'Data Scientist*in (m/w/d) - remote oder Karlsruhe',\n",
       "       'Data Scientist*in/Data Analyst*in (m/w/d)',\n",
       "       'Data Scientist, Germany - BCG X',\n",
       "       'Data Scientist, Mathematiker - Dateningenieur (m/w/d)- AOK Bayern - Die Gesundheitskasse',\n",
       "       'Data Scientist/ AI-Architekt (m/w/d)',\n",
       "       'Data Scientist/Analyst prüfungsnahe Beratung/Quants - Assurance (Financial Services) (w/m/d)',\n",
       "       'Data Scientist/Bioinformatiker im Team Molekulargenetik',\n",
       "       'Data Scientist/ML Engineer', 'Data Solutions Specialist (m/w/d)',\n",
       "       'Data Specialist (m/w/d)',\n",
       "       'Data Steward SAP S/4HANA - \"Business Partner\" (w/m/d)',\n",
       "       'Data Team Manager', 'Data and AI Partner',\n",
       "       'Data and AI/ML Engineer (f/m/d)',\n",
       "       'Data and Reporting Analyst (f/m/d)', 'Data-Analyst (m/w/d)',\n",
       "       'Data-Scientist/MLOps - KI-basiertes Recycling',\n",
       "       'Data/Software Engineer (f/m/d)', 'Datenanalyst (m/w/d)',\n",
       "       'Datenanalyst (m/w/d) / Data Analyst (m/f/d)',\n",
       "       'Datenanalyst (m/w/d) im Bereich Energiewirtschaft',\n",
       "       'Datenanalyst (m/w/d) im Vertriebsmanagement',\n",
       "       'Datenanalyst / Data Analyst Risikomanagement (w/m/d)',\n",
       "       'Datenanalyst für Logistikprozesse (m/w/d)',\n",
       "       'Datenanalyst:in Metering',\n",
       "       'Datenanalysten/in (m/w/d) für Modelle in der konjunkturstatistischen Erhebung im Gastgewerbe',\n",
       "       'Datenarchitekt Versicherungsplattform (m/w/d)',\n",
       "       'Decision Scientist (m/w/d)', 'Deep Learning Researcher',\n",
       "       'Detector Calibration and Characterisation Scientist (m/f/w)',\n",
       "       'Deutsche Bank Graduate Programme (f/m/x) Technology, Data & Innovation 2025',\n",
       "       'DevOps & Cloud Engineer - Data Analytics & AI',\n",
       "       'DevOps/ML Engineer (m/f/d)', 'Digital Data Scientist (w|m|d)',\n",
       "       'Digital Marketing & Data Analytics Manager (m/w/d)',\n",
       "       'Digital Trust and Safety Analyst with German (m/f/d)',\n",
       "       'Dr. rer. nat. Physik / Chemie / Materialwissenschaften - Teamleitung & Projektmanagement (m/w/d)',\n",
       "       'E-Commerce Analyst & Marketing Support Manager (Kaufmann/-frau - E-Commerce)',\n",
       "       'EMEA - Solutions Engineer',\n",
       "       'ERP Business Analyst, Microsoft Business Central (m/f/d) Digital Development',\n",
       "       'ERP Business Analyst, SAP (m/f/d) Digital Development',\n",
       "       'ETL-Entwickler (m/w/d) Azure Data Factory',\n",
       "       'Economic Modeller / Contract Role (m/f/x) Full Remote',\n",
       "       'Electrical Engineer or Computer Scientist (m/f/d) in Technical Support / Automation Technology',\n",
       "       'Engagement Manager (Data & AI)', 'Engineer AI (m/w/d)',\n",
       "       'Engineering Manager - Applied Generative AI (all genders) @ Babbel | NGP Capital Job Board',\n",
       "       'Enterprise Solutions Engineer, Germany',\n",
       "       'Experte für Fahrzeug Telematikdaten und Datenanalysen (gn)',\n",
       "       'Experte für Fahrzeug-Telematikdaten und Datenanalysen (m/w/d) - hybrides Arbeiten (Remote & Präsenz)',\n",
       "       'Fachkraft für den Bereich Einnahmeaufteilung & Statistik (m/w/d)',\n",
       "       'Fachreferent/in für Künstliche Intelligenz A13/E13 (w/m/d)',\n",
       "       'Festanstellung im Bereich Data Analytics und Machine Learning für Datenanalyse-Startup in München (m/w/d)',\n",
       "       'Field Application Scientist, EMEA',\n",
       "       'Financial Data Specialist (m/w/d) Corporate Actions Shares & Funds',\n",
       "       'Financial Data Specialist (m/w/d) – Masterdata Shares / Funds',\n",
       "       'Financial Data Specialist – Bonds / Wertpapiere (m/w/d)',\n",
       "       'Financial Engineer Expert (m/w/d)', 'Financial Engineer m/w/d',\n",
       "       'Forecasting Data Scientist SCM (m/w/d)',\n",
       "       'Founding Software Engineer (m/w/d)', 'Fraud Analyst',\n",
       "       'Fraud Fighter Wanted (d/m/w)',\n",
       "       'Fraud Operations Specialist (f/m/x)',\n",
       "       'Freelance Machine Learning Engineer',\n",
       "       'Full Stack Entwickler (w/m/d)', 'Full-Stack Data Analyst (f/m/d)',\n",
       "       'Full-Stack Data Analytics/Data Science Expert im Competence Center Digital Accelerator (d/m/w/x)',\n",
       "       'GenAI-Developer/Data Scientist (m/w/d)', 'Generative AI Engineer',\n",
       "       'Generative AI Explorer (Stable Diffusion, ControlNet...)',\n",
       "       'Generative Machine Learning Engineer',\n",
       "       'Genomics Data Scientist (f/m/x)',\n",
       "       'Geospatial Data Scientist with focus on remote sensing',\n",
       "       'Gesundheitsökonom / Data Scientist im Gesundheitswesen (D/M/W)',\n",
       "       'Global Engineer - Real World Evidence - Europe',\n",
       "       'Google Cloud AI/ML Consultant (m/w/d)',\n",
       "       'Government Affairs Specialist',\n",
       "       'Gruppenleiter (w/m/d) Sach-Firmen SF - Strategie, Steuerung, Pricing und Produktmanagement für das Geschäftsfeld Sach-Firmen',\n",
       "       'HR Analytics Specialist (m/f/d)', 'HR Business Partner (d/f/m)',\n",
       "       'HR Data Analytics (m/w/d) - Gigafactory Berlin-Brandenburg',\n",
       "       'HYDROGEN TECHNOLOGY RESEARCH ENGINEER (M/F/D)',\n",
       "       'Health Data Analyst*in (m/w/div)',\n",
       "       'IIoT Research Developer – Young Professional (m/w/d)',\n",
       "       'INTERDISCIPLINARY ENGINEER/SCIENTIST',\n",
       "       'IT Business Analyst for Research Labs (f/m/d)',\n",
       "       'IT Business Analyst*in Data Warehouse & Business Intelligence (in Voll- oder Teilzeit)',\n",
       "       'IT Consultant - SAP Fiori / ABAP / User Experience / CDS Views (m/w/d)',\n",
       "       'IT Consultant Energy & Utilities (m/w/d)',\n",
       "       'IT Consultant Energy (m/w/d)',\n",
       "       'IT Entwickler / Data Scientist (m/w/d) – Systembetrieb (befristet auf 2 Jahre)',\n",
       "       'IT Projektleiter / Projektmanager (mwd) DevOps',\n",
       "       'IT-Business / Data Analyst (m/f/d)',\n",
       "       'Informatiker*in (m/w/div) für den Bereich High Performance Computing (HPC) / Infrastruktur',\n",
       "       'Information Security Management Consultant mit Schwerpunkt DORA',\n",
       "       'Ingenieur (m/w/d) technische Integritätsbewertung und Datenanalyse',\n",
       "       'Ingenieur / Data-Scientist (w/m/d)',\n",
       "       'Inhouse Consultant - Schwerpunkt Datamanagement (m/w/d)',\n",
       "       'Inhouse Consultant Master Data Management Kunde/Lieferant (w/m/div.)',\n",
       "       'Initiativbewerbung', 'Initiativbewerbung (m/w/d)',\n",
       "       'Initiativbewerbung (w/m/d)',\n",
       "       'Initiativbewerbung Data Science /BI',\n",
       "       'Initiativbewerbung Graduates Consulting @ MHP – A Porsche Company (f/m/d)',\n",
       "       'Initiativbewerbung: Wissenschaftliche Mitarbeitende (m/w/d)',\n",
       "       'Innovation Cup 2025 - Team Drug Discovery (all genders)',\n",
       "       'Innovation Cup 2025 - Team Neuroinspired AI inference acceleration (all genders)',\n",
       "       'Insights Analyst',\n",
       "       'Instrument Scientist (Gamma Rays and UV) in Astroparticle Physics',\n",
       "       'Job Offer: Account Manager (f/m/d) * - Lipotype GmbH',\n",
       "       'KI Data Scientist (m/w/d)',\n",
       "       'KI-Entwickler/in - Mitarbeiter/in Künstliche Intelligenz (m/w/d)',\n",
       "       'Laboratory management (m/f/d)',\n",
       "       'Leitung (m/w/d) für den Sachbereich Personalmanagement und Zentralaufgaben',\n",
       "       'Life Scientist as Global Technical Support Specialist (m|f|d) French Speaking',\n",
       "       'ML Architect Engineer', 'ML Engineer', 'ML Engineer (f/m/d)',\n",
       "       'ML Engineer (m/f/x)', 'ML Ops Engineer',\n",
       "       'ML Ops Engineer - Berlin',\n",
       "       'ML Software Engineer / Data Scientist (m/w/d)', 'MLOps Engineer',\n",
       "       'MLOps Engineer (w/m/d) 100% remote', 'MRI Scientist (f/m/d)',\n",
       "       'Machine Learning / AI - Engineer (F/M/D) - Hybrid Working',\n",
       "       'Machine Learning Consultant (m/f/d)', 'Machine Learning Engineer',\n",
       "       'Machine Learning Engineer (LLM/RAG)',\n",
       "       'Machine Learning Engineer (NLP)',\n",
       "       'Machine Learning Engineer (NLP) - Climate Tech',\n",
       "       'Machine Learning Engineer (m/f/d)',\n",
       "       'Machine Learning Engineer (m/f/x)',\n",
       "       'Machine Learning Engineer (m/w/d)',\n",
       "       'Machine Learning Engineer - Freelance',\n",
       "       'Machine Learning Engineer Autonomous Driving (m/w/d)',\n",
       "       'Machine Learning Engineer, Applied AI',\n",
       "       'Machine Learning Engineer, Fraud Prevention',\n",
       "       'Machine Learning Engineer, Search',\n",
       "       'Machine Learning Platform Engineers',\n",
       "       'Machine Learning Software Developer (Karlsruhe)',\n",
       "       'Machine Learning Software Engineer – Optimization & LLM Development (m/f/x)',\n",
       "       'Machine Vision Engineer (Halcon)', 'Manufacturing Data Analyst',\n",
       "       'Manufacturing Data Analyst @ Deltia (Remote within Europe)',\n",
       "       'Market Researcher', 'Marketing Data Analyst',\n",
       "       'Marketing Data Analyst (f/m/x)', 'Marketing Researcher',\n",
       "       'Master Data Assistant m/w/d',\n",
       "       'Master Data Operator (Schwerpunkt: Liquor, Tobacco & Confectionary) (m/w/d)',\n",
       "       'Master Student Cryopreserved Natural Killer (NK) cell research (m|f|d)',\n",
       "       'Master of Science (M.Sc.) (m/w/d) Start 2025 Location Berlin-Potsdam (VT/STAR)',\n",
       "       'Masterarbeit',\n",
       "       'Masterarbeit im Bereich Data Science und AI Development ab Januar 2025',\n",
       "       'Masterarbeit: Schnelleres Erkennen unbekannter Gegenstände unter Wasser dank Few Shot Learning (m/w/d)',\n",
       "       'Masterprogramm Data Science & Business Analytics (all genders)',\n",
       "       'Material Development Engineer, Formulation Scientist (m/f/d)',\n",
       "       'Mathematiker:in / Physiker:in Aktuarielles Controlling',\n",
       "       'Medical Research Coordinator - MedTech Venture',\n",
       "       'Middleware Analyst / SAP Consultant PO/IS (m/w/d)',\n",
       "       'Mitarbeiter Datenanalyse im HomeOffice (m/w/d)',\n",
       "       'Mitarbeiter im Qualitätsmanagement (m/w/d) (Fachinformatiker/in - Daten- und Prozessanalyse)',\n",
       "       'Mitarbeiter/-in Projektmanagement digitaler Service / Datenanalyse (m/w/d)',\n",
       "       'Mitarbeiterin/Mitarbeiter im Bereich Zahlen- und Datenanalyse (m/w/d)',\n",
       "       'NGS Data Analyst for Molecular Oncology', 'NLP Engineer (m/w/d)',\n",
       "       'Network Engineers (m/f/div)', 'Operations & Marketing Associate',\n",
       "       'Performance Engineer - Laundry Care',\n",
       "       'Pflichtpraktikum im eBusiness - Business Intelligence & Digital Analyst',\n",
       "       'PhD Candidate', 'PhD Candidate (m/f/d): Spatial Metabolomics',\n",
       "       'Physicist Dosimetry Expert',\n",
       "       'Planer*in (m/w/d) für das Sachgebiet -Räumliche Entwicklungsplanung- im Amt für Stadtentwicklung und Statistik',\n",
       "       'Portfolio Analyst (f/m/d)', 'Postdoktorand:in (m/w/d)',\n",
       "       'Pre-Sales Consultant Datacenter - Süd (m/w/d) (Data-Consultant)',\n",
       "       'Pricing Actuary', 'Process Data Analyst (m/w/d)',\n",
       "       'Process Development Engineer (m/f/d)',\n",
       "       'Process Engineer (relocation to St. Gallen, Switzerland)',\n",
       "       'Product Analyst', 'Product Analyst - Shopping Experience (m/f/d)',\n",
       "       'Product Analyst - Social Discovery app',\n",
       "       'Product Analyst – Business Data & Insights (m/f/d)',\n",
       "       'Product Analytics Associate (Based in Dubai)',\n",
       "       'Product Associate',\n",
       "       'Product Data Analyst (Banking + Data Quality) (w/m/d) mit 100% Homeoffice',\n",
       "       'Product Data Analyst (Savings and Contract Optimization) mit 100% Homeoffice',\n",
       "       'Product Data Science Managers', 'Product Manager',\n",
       "       'Product Manager (DeFi / Earn) - Web3', 'Product Manager (m/f/x)',\n",
       "       'Product Manager Pricing & Analytics (x/f/m)',\n",
       "       'Product Manager, DashOps (f/m/x)',\n",
       "       'Product Owner (w/d/m) - Buchhaltung & Berichte',\n",
       "       'Product Safety Specialist *',\n",
       "       'Production Technology Engineer (m/w/d)',\n",
       "       'Produkt- und Datenanalyst/in (m/w/d) (Kaufmann/-frau - Versicherungen u. Finanzen - Versicherung)',\n",
       "       'Professor for Data Science (m/f/d)',\n",
       "       'Project Management Assistant (Real World Data)',\n",
       "       'Projektingenieur - Data Scientist (m/w/d)',\n",
       "       'Projektleiter:in Künstliche Intelligenz',\n",
       "       'Projektmanager AI & Data Science',\n",
       "       'Prozess-und Betriebsdatenspezialist (m,w,d) (Berufsspezialist/in - Datenanalyse)',\n",
       "       'Prüfungsassistent / Consultant Audit & Advisory (m/w/d) mit Schwerpunkt Energy & Public',\n",
       "       'Python Developer',\n",
       "       'Python Developer (m/f/d) in the field of ML and AI',\n",
       "       'Python Developer / Data Scientist - Remote or Berlin based',\n",
       "       'Python Full Stack Developer', 'Quant Developer (f/m/d)',\n",
       "       'Quantitative Power Trading Analyst',\n",
       "       'Quantum Scientist - Superconducting Qubits (remote-ish)',\n",
       "       'R&D Scientist (m/w/d)',\n",
       "       'RESEARCH SCIENTIST (gn) PROTEIN CRYO-EM WITH PROJECT MANAGEMENT SKILLS',\n",
       "       'Referent Netzplanungsdatenmanagement (m/w/d)',\n",
       "       'Research And Development Engineer',\n",
       "       'Research Assistant, Molecular Diagnostics (m/f/d)',\n",
       "       'Research Assistant/Associate (f/m/d)',\n",
       "       'Research Assistant/Associate (f/m/d) PhD students for \"Research and Development in the Field of Combustion Systems with Optical Flow Diagnostics\" (TME 130_241100)',\n",
       "       'Research Assistant/Associate (f/m/d) PhD students for \"Research and Development in the Field of Optical Flow Diagnostics\" (TME 129_241100)',\n",
       "       'Research Associate for the Project “DASHH - Data Science in Hamburg - Helmholtz Graduate School for the Structure of Matter, Particle Physics with the CMS Experiment” § 28 Subsection 3 HmbHG',\n",
       "       'Research Associate for the Project “DASHH - Data Science in Hamburg - Helmholtz Graduate School for the Structure of Matter, dAIbetes” § 28 Subsection 3 HmbHG',\n",
       "       'Research Engineer (m/w/d)', 'Research Engineer, Applied AI',\n",
       "       'Research Engineer/Analyst',\n",
       "       'Research Scientist (PhD m/f/d) in Nuclear Physics',\n",
       "       'Research Scientist (f/m/d)',\n",
       "       'Research Scientist BIOCHEMISTRY/BIOPHYSICS (gn)',\n",
       "       'Research Scientist BIOPHYSICS WITH FOCUS PLATE-BASED ASSAYS (gn)',\n",
       "       'Research Scientist I, Germany',\n",
       "       'Research assistant (f/m/d) - Department of Mathematics and Natural Science - Mathematics of Data Science Group - ID 142/2024',\n",
       "       'Research assistant (m/f/d)',\n",
       "       'Research assistant (m/f/d) with 75%part-time job limited to 30.09.2027 salary grade (Entgeltgruppe) 13 TV-L FU reference code: WiMi_Clementi_FAIME_2025',\n",
       "       'Research assistant for AAI and federated services project ROCK-IT',\n",
       "       'Researcher / Project Manager',\n",
       "       'Robotics Software Engineer all levels (m/w/d)',\n",
       "       'Robotics and Autonomous Systems / Robotics and AI Engineer',\n",
       "       'SAP Analytics Architect (gn*)', 'SAP Analytics Expert (gn*)',\n",
       "       'SAP Business Analyst (m/f/d) Data Migrations',\n",
       "       'SAP Consultant - Energy / Utilities / Remote (m/w/d)',\n",
       "       'SENIOR DATA SCIENTIST (F/M/D)', 'SEO - Data Analyst:in',\n",
       "       'Sales / Vertrieb Weiterbildung (m/w/d) - Jobchance für Remote-Workers (Teilzeit)',\n",
       "       'Sales Consultant Digital Solutions (w/m/d)',\n",
       "       'Sales Manager / Sales Development Representative (m/w/d)',\n",
       "       'Salesforce Data Analyst CRM-Marketing (m/w/d)',\n",
       "       'Scientific Software Engineer (f/m/x)',\n",
       "       'Scientist (f/m/d) in vitro DMPK',\n",
       "       'Scientist (f/m/d)- LC-MS: Drug Product Characterization for Biopharmaceuticals',\n",
       "       'Scientist (m/f/d) for the area Immunoassays (full-time)',\n",
       "       'Scientist (m/f/div) Bioprocess Development RDI-Projects',\n",
       "       'Scientist - In vivo Pharmacology (m/w/x)',\n",
       "       'Scientist - Protein Analytics',\n",
       "       'Scientist Biotic Stress Trait Development (m/f/d)',\n",
       "       'Scientist Digital Imaging (m/f/d), Referenz: „51001-24-03-WAPRO“',\n",
       "       'Scientist III, Field Applications',\n",
       "       'Scientist Viral Vector Production',\n",
       "       'Scientist at innoFSPEC, AIP Technology Transfer',\n",
       "       'Scientist in the field of fiber drawing technology for active fibers',\n",
       "       'Scientist in the field of fiber drawing technology for active fluoride fibers',\n",
       "       'Scientist in the field of fiber preform development for active fibers',\n",
       "       'Scientist – DNA-, RNA- Oligonucleotide Synthesis (x/f/m)',\n",
       "       'Scientist – Optical Design and Simulation',\n",
       "       'Scientist/DevOps Position in EScience Section (w/m/d)',\n",
       "       'Scientist/DevOps in EScience Section (w/m/d)',\n",
       "       'Scientist/Research-Associate – Retinal Gene Therapy (m/f/x)',\n",
       "       'Semantics Engineer (f/m/x)',\n",
       "       'Simulation and Machine Learning Engineer (d/m/w)',\n",
       "       'Software & AI Engineer in Health (all genders)',\n",
       "       'Software Engineer (Data & Python) (all genders)',\n",
       "       'Software Engineer (Python)',\n",
       "       'Software Engineer (Python, Machine Learning, Cloud) - Remote',\n",
       "       'Software Engineer (m/f/div) – Data Lake Architect',\n",
       "       'Software Engineer - Machine Learning (all genders)',\n",
       "       'Software Engineer mit Data Science Background (m/w/d)',\n",
       "       'Softwareentwickler/Data-Scientist für MES Integration (m/w/d) im Bereich Li-Ion Large Cells',\n",
       "       'Solutions Engineer',\n",
       "       'Spezialist (m/w/d) Data Engineering & Data Science',\n",
       "       'Spezialist Customer Data Governance',\n",
       "       'Spezialist Risikocontrolling CO2-Accounting / Data Scientist (m/w/d)',\n",
       "       'Spezialist für Verkehrsdatenanalyse (d/m/w)',\n",
       "       'Sports Scientist (m/f/x)', 'Sr Data Scientist - LLM',\n",
       "       'Sr Scientist I, AI / ML', 'Staff Data Scientist (f/m/d)',\n",
       "       'Staff Data Scientist - Ad Tech (all genders)',\n",
       "       'Staff Data Scientist - Consumer Insights & Marketing Technology (CIMT) ( All genders )',\n",
       "       'Staff Data Scientist, Investment Modelling',\n",
       "       'Staff Engineer - Machine Learning', 'Staff ML / AI Engineer',\n",
       "       'Staff ML Engineer', 'Staff Scientist (m/f/d)',\n",
       "       'Staff Scientist Cell Therapy-Type 1 Diabetes (f/m/x)',\n",
       "       'Strategy Manager Life Science (all genders)',\n",
       "       'Student Data Scientist', 'Student Data Scientist (m/f/d)',\n",
       "       'Student Engineering, Natural Sciences, Data Science or similar (f/m/x)',\n",
       "       'Student Researcher, 2025',\n",
       "       'Supply- Chain- Daten Analyst:in (m/w/d) - unbefristet',\n",
       "       'TOP TECHNOLOGIES CONSULTING GmbH – Berater (Mensch) Data Lifecycle Management',\n",
       "       'Talent Day - Explore a Tech Career with Netlight', 'Talent Pool',\n",
       "       'Technical Assistant - Biotechnology',\n",
       "       'Technical Investigator / Data Scientist - AI Safety',\n",
       "       'Technical Solutions Engineer - Data (Remote)',\n",
       "       'Technical Support Consultant (m/w/d) Data Center Operational Technology Management Software',\n",
       "       'UX Mixed Methods Researcher',\n",
       "       'Unsolicited Application / Initiativbewerbung (m/f/d)',\n",
       "       'Unsolicited application (Full time)',\n",
       "       'Unterstützung im Bereich Einnahmeaufteilung & Statistik',\n",
       "       'VP of Data & Analytics',\n",
       "       'VPP Modeling Engineer / Data Scientist (m/f/d)',\n",
       "       'Venture Development Tech Analyst (w/m/d)',\n",
       "       'Visiting Analyst (January 2025 and onwards)',\n",
       "       'Werkstudierende - Tutoring im Data Science (all genders)',\n",
       "       'Wirtschaftsinformatiker für Demand Planning Diagnostics (m/w/d)',\n",
       "       '_Softwareentwicklung Jobs im Landkreis Bodenseekreis',\n",
       "       'eine/n Data Scientist/in (m/w/d)'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check listings which did not get categorized by code above.\n",
    "np.sort(df.loc[df[\"seniority_level_new\"].isna()][\"title\"].unique())\n",
    "# -> Looks ok; no specification regarding seniority provided in title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set remaining unclassified listings to \"Assiciate/Mid-Level\"\n",
    "df.loc[df[\"seniority_level_new\"].isna(), \"seniority_level_new\"] = \"Associate/Mid-Level\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seniority_level_new\n",
       "Associate/Mid-Level    926\n",
       "Senior                 299\n",
       "Student                109\n",
       "Director                84\n",
       "Junior                  80\n",
       "Intern                  80\n",
       "Postdoc                 25\n",
       "Trainee                 22\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"seniority_level_new\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare seniority levels with those provided on the job platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Associate', 'Entry level', 'Mid-Senior level', 'Not Applicable',\n",
       "       'Internship', 'Director', 'Executive', nan], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"seniority_level\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(Global) Senior Applied Research Scientist',\n",
       " '(Junior) AI Engineer (m/w/d)',\n",
       " '(Junior) Data Engineer (m/w/d)',\n",
       " '(Junior) Data Engineer (m/w/x)',\n",
       " '(Junior) Data Product Associate (f/m/x)',\n",
       " '(Senior) Data Analyst / Data Scientist (f/m/d) in Data Division',\n",
       " '(Senior) Data Scientist (Analytics), Merchant',\n",
       " '(Senior) Data Scientist / ML Engineer (m/w/d)',\n",
       " '(Senior) Machine Learning Data Scientist (d/f/m)',\n",
       " '(Senior) Machine Learning Engineer (m/f/d)',\n",
       " '2025 Software Development Engineer - Machine Learning (m/w/d)',\n",
       " 'AI Consultant',\n",
       " 'AI Engineer / AI Developer (m/w/d) bei einem SaaS-Unternehmen aus Würzburg (Full-Remote oder vor Ort)',\n",
       " 'AI Engineer // Data Scientist (all genders)',\n",
       " 'AI Lead',\n",
       " 'AI Platform Engineer (all genders)',\n",
       " 'AI Researcher',\n",
       " 'AI consultant  - Energy',\n",
       " 'AI\\xa0computational\\xa0\\xa0material\\xa0\\xa0researcher/expert',\n",
       " 'Analyst - Fokus Data Science / AI (m/w/d)',\n",
       " 'Analytics Engineer (m/f/d)',\n",
       " 'Analytics Engineering Lead',\n",
       " 'Applied Scientist for Probabilistic Machine Learning and Human-Computer Interaction',\n",
       " 'Applied Scientist, Fintech (Fraud)',\n",
       " 'Artificial Intelligence Engineer',\n",
       " 'Associate Data Analyst (f/m/d)',\n",
       " 'Associate Special Project, Esports',\n",
       " 'Atomic, Molecular, and Optical Physicist',\n",
       " 'BI Analyst (all genders)',\n",
       " 'BI Analyst (m/w/d)',\n",
       " 'BI Business Analyst (m/f/d)',\n",
       " 'BI Manager (m/w/d) Data Science/Data Analytics',\n",
       " 'Battery Scientist (m/f/x)',\n",
       " 'Bioinformatician',\n",
       " 'Bioinformatician (m/f/d) in immunopeptidomics',\n",
       " 'Business  Development Manger',\n",
       " 'Business Analyst',\n",
       " 'Business Analyst / Controller',\n",
       " 'Business Analyst / Controller',\n",
       " 'Business Intelligence & Analytics Manager',\n",
       " 'Business Intelligence Analyst (m/w/d)',\n",
       " 'Business Intelligence Consultant',\n",
       " 'Business Intelligence Manager (m/w/d)',\n",
       " 'Business Intelligence Specialist (m/w/x)',\n",
       " 'Business Intelligence und Data Analyst (m/w/d)',\n",
       " 'Carbon Project Risk Analyst (f/d/m)',\n",
       " 'Certified Strength and Conditioning Specialist',\n",
       " 'Certified Strength and Conditioning Specialist',\n",
       " 'Chief AI Engineer',\n",
       " 'Chief Technology Officer',\n",
       " 'Computational Biologist (m/f/d)',\n",
       " 'Computational Chemist Lead',\n",
       " 'Computational Scientist – (Machine Learning) Digital R&D Large Molecule Research',\n",
       " 'Computer Scientist | InformatikerIn | Software EntwicklerIn für klinische KI-Forschung und Anwendung',\n",
       " 'Computer Vision Engineer',\n",
       " 'Consultant - Digital Analytics (m/w/d) for Hamburg',\n",
       " 'Consultant AI & Analytics',\n",
       " 'DATA ANALYST (M/W/D)',\n",
       " 'DATA ANALYST:IN (m/w/d)',\n",
       " 'Data & AI Scientist Personalized Computational Genomics (all genders)',\n",
       " 'Data Analysis, Modeling & Simulation Engineer (f/m/d)',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst (m/f/d) at Allianz SE',\n",
       " 'Data Analyst (m/w/d)',\n",
       " 'Data Analyst (m/w/d) Berlin, Hamburg, Munich',\n",
       " 'Data Analyst - MS Tech Stack',\n",
       " 'Data Analyst - Product',\n",
       " 'Data Analyst / Scientist (m/w/d) für die Energietransformation',\n",
       " 'Data Analyst:in Münster/Köln/Berlin/Remote (DE)',\n",
       " 'Data Analytics Engineer',\n",
       " 'Data Analytics Specialist (m/f/d)',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer (English speaking)(M/F/D)',\n",
       " 'Data Engineer (d/f/m)',\n",
       " 'Data Engineer (f/m/x)',\n",
       " 'Data Engineer (m/w/d)',\n",
       " 'Data Engineer (m/w/d)',\n",
       " 'Data Engineer (m/w/d)',\n",
       " 'Data Engineering Consultant',\n",
       " 'Data Product Manager',\n",
       " 'Data Reporting Analyst',\n",
       " 'Data Science Consultant (m/w/d)',\n",
       " 'Data Science Consultant (m/w/d)',\n",
       " 'Data Science Consultant - QuantumBlack, AI by McKinsey',\n",
       " 'Data Science and AI Mentor (Freelance, Remote)',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist & Machine Learning Engineer (m/w/d)',\n",
       " 'Data Scientist (Growth Team)',\n",
       " 'Data Scientist (m/f/d)',\n",
       " 'Data Scientist (m/w/d)',\n",
       " 'Data Scientist (w/m/d)',\n",
       " 'Data Scientist (w/m/d)',\n",
       " 'Data Scientist (w/m/d)',\n",
       " 'Data Scientist (w/m/d)',\n",
       " 'Data Scientist (w/m/d)',\n",
       " 'Data Scientist (w/m/d)',\n",
       " 'Data Scientist (w/m/d)',\n",
       " 'Data Scientist (w/m/d)',\n",
       " 'Data Scientist - Datenmanagement (m/w/d)- AOK Bayern - Die Gesundheitskasse',\n",
       " 'Data Scientist - LLM',\n",
       " 'Data Scientist - Ranking',\n",
       " 'Data Scientist Consultant (m/f/d)',\n",
       " 'Data Scientist Lead and Team Lead \"Customer Intelligence Team\" (m/f/d)',\n",
       " 'Data Scientist – Supply & Demand Modelling',\n",
       " 'Data Scientist*in (m/w/d) - remote oder Karlsruhe',\n",
       " 'Data Scientist*in/Data Analyst*in (m/w/d)',\n",
       " 'Data Scientist, Mathematiker - Dateningenieur (m/w/d)- AOK Bayern - Die Gesundheitskasse',\n",
       " 'Data Team Manager',\n",
       " 'Data and Reporting Analyst (f/m/d)',\n",
       " 'DevOps/ML Engineer (m/f/d)',\n",
       " 'Digital Marketing & Data Analytics Manager (m/w/d)',\n",
       " 'Economic Modeller / Contract Role (m/f/x) Full Remote',\n",
       " 'Engagement Manager (Data & AI)',\n",
       " 'Fraud Analyst',\n",
       " 'Fraud Fighter Wanted (d/m/w)',\n",
       " 'Fraud Operations Specialist (f/m/x)',\n",
       " 'Freelance Machine Learning Engineer',\n",
       " 'Generative AI Engineer',\n",
       " 'Gesundheitsökonom / Data Scientist im Gesundheitswesen (D/M/W)',\n",
       " 'Head Applied Data & Genetics Science – Seeds Field Crops Europe (M/F/D)',\n",
       " 'Head of AI',\n",
       " 'Head of AI (m / f / d)',\n",
       " 'Head of Artificial Intelligence',\n",
       " 'Head of Artificial Intelligence',\n",
       " 'Head of Clinical Data Management & IT (m/f/d)',\n",
       " 'Head of Data & Analytics (m/w/d)',\n",
       " 'Head of Data & Analytics - Medical Cannabis Industry',\n",
       " 'Head of Data Science and AI (m/w/d)',\n",
       " 'Head of Data Science and AI (m/w/d)',\n",
       " 'IT Business Analyst for Research Labs (f/m/d)',\n",
       " 'Initiativbewerbung',\n",
       " 'Junior AI Platform Engineer or Working Student (all genders)',\n",
       " 'Junior Business Intelligence Engineer (All Genders)',\n",
       " 'Junior Data Engineer (m/w/d)',\n",
       " 'Junior Managers Program - Business Intelligence und Analytics - Trainee programm (f/m/div.)',\n",
       " 'Junior Professor of Artificial Intelligence and Machine Learning',\n",
       " 'Lead AI Engineer (Cloud, Machine Learning)',\n",
       " 'Lead Consultant AI (Ref:IgLWy)',\n",
       " 'Lead Data Scientist',\n",
       " 'Lead Data Scientist (Deep Learning)',\n",
       " 'Lead Data Scientist (Deep Learning)',\n",
       " 'Lead Data Scientist (Deep Learning)',\n",
       " 'Lead Data Scientist (all genders)',\n",
       " 'Lead Data Scientist (m/f/d)',\n",
       " 'Lead Data Scientist NLP',\n",
       " 'Lead ML Engineer',\n",
       " 'Lead ML Engineer (m/f/d)',\n",
       " 'Lead Machine Learning Engineer – Generative AI',\n",
       " 'ML Architect Engineer',\n",
       " 'ML Architect Engineer',\n",
       " 'Machine Learning Engineer',\n",
       " 'Machine Learning Engineer',\n",
       " 'Machine Learning Engineer',\n",
       " 'Machine Learning Engineer',\n",
       " 'Machine Learning Engineer',\n",
       " 'Machine Learning Engineer',\n",
       " 'Machine Learning Engineer',\n",
       " 'Machine Learning Engineer (m/f/d)',\n",
       " 'Machine Learning Engineer (m/w/d)',\n",
       " 'Machine Learning Engineer - Freelance',\n",
       " 'Machine Learning Engineer, Applied AI',\n",
       " 'Machine Learning Engineer, Search',\n",
       " 'Machine Learning Software Engineer – Optimization & LLM Development (m/f/x)',\n",
       " 'Machine Vision Engineer (Halcon)',\n",
       " 'Market Researcher',\n",
       " 'Marketing Data Analyst',\n",
       " 'Marketing Researcher',\n",
       " 'Medical Research Coordinator - MedTech Venture',\n",
       " 'Performance Engineer - Laundry Care',\n",
       " 'Pricing Actuary',\n",
       " 'Principal Data Scientist (d/f/m)',\n",
       " 'Principal Data Scientist (d/f/m)',\n",
       " 'Process Engineer (relocation to St. Gallen, Switzerland)',\n",
       " 'Product Analyst – Business Data & Insights (m/f/d)',\n",
       " 'Product Data Analyst (Banking + Data Quality) (w/m/d) mit 100% Homeoffice',\n",
       " 'Product Data Analyst (Savings and Contract Optimization) mit 100% Homeoffice',\n",
       " 'Product Lead, Platform Products',\n",
       " 'Product Lead, Pricing',\n",
       " 'Product Lead, Search',\n",
       " 'Product Manager',\n",
       " 'Product Manager Pricing & Analytics (x/f/m)',\n",
       " 'Professor for Data Science (m/f/d)',\n",
       " 'Program/Product Manager Intern',\n",
       " 'Python Developer',\n",
       " 'Python Developer',\n",
       " 'Python Full Stack Developer',\n",
       " 'Quantitative Power Trading Analyst',\n",
       " 'Remote (Sr.) Python Data Scientist (m/f/d)',\n",
       " 'Research And Development Engineer',\n",
       " 'Research Associate for the Project “DASHH - Data Science in Hamburg - Helmholtz Graduate School for the Structure of Matter, Particle Physics with the CMS Experiment” § 28 Subsection 3 HmbHG',\n",
       " 'Research Associate for the Project “DASHH - Data Science in Hamburg - Helmholtz Graduate School for the Structure of Matter, dAIbetes” § 28 Subsection 3 HmbHG',\n",
       " 'Research Engineer (m/w/d)',\n",
       " 'Research, Analytics, and Knowledge Management Team Lead',\n",
       " 'Researcher / Project Manager',\n",
       " 'Robotics Software Engineer all levels (m/w/d)',\n",
       " 'Scientific Data Architect / Senior Scientific Data Architect- EMEA Remote',\n",
       " 'Senior AI Developer f/m/d',\n",
       " 'Senior AI Engineer',\n",
       " 'Senior AI Engineer (m/f/d)',\n",
       " 'Senior Analytics Engineer (m/f/d)',\n",
       " 'Senior Applied Scientist, Logistics',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst (m/f/d)',\n",
       " 'Senior Data Analyst (m/f/d)',\n",
       " 'Senior Data Engineer (Python)',\n",
       " 'Senior Data Science Consultant',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist (SOC / carbon modelling)',\n",
       " 'Senior Data Scientist (d/f/m)',\n",
       " 'Senior Data Scientist (d/f/m) - Large-scale Machine Learning',\n",
       " 'Senior Data Scientist (f/m/d)',\n",
       " 'Senior Data Scientist (f/m/x)',\n",
       " 'Senior Data Scientist (m/f/d)',\n",
       " 'Senior Data Scientist (m/f/d)',\n",
       " 'Senior Data Scientist (m/f/d)',\n",
       " 'Senior Data Scientist (m/w/d)',\n",
       " 'Senior Data Scientist (m/w/d)',\n",
       " 'Senior Data Scientist (m/w/d)',\n",
       " 'Senior Data Scientist (m/w/d)',\n",
       " 'Senior Data Scientist (m/w/d)',\n",
       " 'Senior Data Scientist (w/m/d)',\n",
       " 'Senior Data Scientist - Remote from Germany',\n",
       " 'Senior Data Scientist - Time Estimations, Logistics (all genders)',\n",
       " 'Senior Data Scientist / AI Developer (m/w/d)',\n",
       " 'Senior Data Scientist – Supply & Demand Modelling',\n",
       " 'Senior Data Scientist, Campaigns',\n",
       " 'Senior Data Scientist, Payments Product',\n",
       " 'Senior Data Scientist, gTech Ads',\n",
       " 'Senior Data Scientist, gTech Ads',\n",
       " 'Senior Data Scientist- Optimization (d/f/m)',\n",
       " 'Senior ML / AI Engineer',\n",
       " 'Senior Machine Learning Data Scientist (d/m/f)',\n",
       " 'Senior Machine Learning Engineer',\n",
       " 'Senior Machine Learning Engineer',\n",
       " 'Senior Machine Learning Engineer',\n",
       " 'Senior Product Manager (m/f/d)',\n",
       " 'Senior Product Manager - Fraud Prevention',\n",
       " 'Senior Python Developer (LLM-based applications, SME)',\n",
       " 'Senior Research Scientist (permanent, E15 pay scale)',\n",
       " 'Senior Scientist (m/f/d) Molecular Complex Development',\n",
       " 'Senior Software Developer Data & ML (M/W/D)',\n",
       " 'Senior Software Engineer (Python)',\n",
       " 'Senior Staff AI Engineer',\n",
       " 'Senior/Lead ML Engineer (AI-Powered Platform) - REMOTE UK/EUROPE/AMER',\n",
       " 'Simulation and Machine Learning Engineer (d/m/w)',\n",
       " 'Software Engineer (Data & Python) (all genders)',\n",
       " 'Sr Data Scientist - LLM',\n",
       " 'Sr Scientist I, AI / ML',\n",
       " 'Staff ML Engineer',\n",
       " 'Strategy Manager Life Science (all genders)',\n",
       " 'Talent Pool',\n",
       " 'Teamlead Data Science und Data Engineering (m/w/d)',\n",
       " 'UX Mixed Methods Researcher',\n",
       " 'Unsolicited Application / Initiativbewerbung (m/f/d)',\n",
       " 'Unsolicited Application / Initiativbewerbung (m/f/d)',\n",
       " 'Working Student AI/ML (all genders) - (Any location in Germany)']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(df.loc[df[\"seniority_level\"] == \"Mid-Senior level\", \"title\"]).tolist()\n",
    "# some junior positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(Senior) BI Analyst (all genders)',\n",
       " '(Senior) Consultant Data Science & MLOps, d/f/m',\n",
       " 'AI Consultant',\n",
       " 'AI Developer (m/w/d)',\n",
       " 'AI Engineer (Senior)',\n",
       " 'AI Engineer (m/w/d)',\n",
       " 'AI Software Developer in Test (f/m/d)',\n",
       " 'Analyst - Fokus Data Science / AI (m/w/d)',\n",
       " 'Analytics Engineer (m/w/d)',\n",
       " 'Artificial Intelligence Engineer',\n",
       " 'Artificial Intelligence Engineer',\n",
       " 'Artificial Intelligence Specialist',\n",
       " 'Artificial Intelligence Specialist (w/m/d)',\n",
       " 'Associate - Index Operations (m/f/d)',\n",
       " 'Associate / (Senior) AI Technology Consultant (m/w/d)',\n",
       " 'BI & Data Modeling Expert (m/f/d)',\n",
       " 'Bench Scientist (all genders)',\n",
       " 'Breeding Informatics Analyst (d/f/m) Full Time - in Tübingen',\n",
       " 'Business Intelligence Developer (m/w/d) Tech / E-Commerce',\n",
       " 'CRA/SCRA',\n",
       " 'DWH Analyst (all genders)',\n",
       " 'Data & AI Business Consultant (m/w/d)',\n",
       " 'Data & AI Strategist (m/f/d)',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst (m/f/d) in IT security company',\n",
       " 'Data Analyst (m/w/d)',\n",
       " 'Data Analyst (m/w/d)',\n",
       " 'Data Analyst (m/w/d)',\n",
       " 'Data Analyst (m/w/d)',\n",
       " 'Data Analyst (m/w/d)',\n",
       " 'Data Analyst (m/w/d)',\n",
       " 'Data Analyst (m/w/d) Telematikdaten',\n",
       " 'Data Analyst / Data Engineer (m/f/d)',\n",
       " 'Data Analyst / Data Scientist (m/w/d)',\n",
       " 'Data Analyst / Decision Scientist, Digital Marketing',\n",
       " 'Data Analyst / Decision Scientist, Policy',\n",
       " 'Data Analytics Engineer',\n",
       " 'Data Engineer (m/w/d)',\n",
       " 'Data Engineer (m/w/d) Tech / E-Commerce',\n",
       " 'Data Engineer / Analyst',\n",
       " 'Data Engineer / Scientist (m/w/d)',\n",
       " 'Data Science Graduate',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist (all gender)',\n",
       " 'Data Scientist (all genders)',\n",
       " 'Data Scientist (f/m/d)',\n",
       " 'Data Scientist (f/m/d)',\n",
       " 'Data Scientist (f/m/d)',\n",
       " 'Data Scientist (m/w/d)',\n",
       " 'Data Scientist (m/w/d)',\n",
       " 'Data Scientist (m/w/d)',\n",
       " 'Data Scientist - Customer Success Projects (ValueWorks)',\n",
       " 'Data Scientist Lead and Team Lead \"Customer Intelligence Team\" (m/f/d)',\n",
       " 'Data Scientist in Energy Tech Start Up - hybrid Berlin based (f/m/d)',\n",
       " 'Data Scientist with focus Clinical Statistics (f/m/d - part/full-time)',\n",
       " 'Data Scientist/ AI-Architekt (m/w/d)',\n",
       " 'Data-Analyst (m/w/d)',\n",
       " 'Data/Software Engineer (f/m/d)',\n",
       " 'Deep Learning Researcher',\n",
       " 'Engineer AI (m/w/d)',\n",
       " 'Government Affairs Specialist',\n",
       " 'Head of Data (all genders)',\n",
       " 'IT-Business / Data Analyst (m/f/d)',\n",
       " 'Junior Engineer Machine Learning / Deep Learning (w/m/d)',\n",
       " 'Junior Machine Learning Engineer (Leipzig)',\n",
       " 'MLOps Engineer (w/m/d) 100% remote',\n",
       " 'Machine Learning Engineer',\n",
       " 'Machine Learning Engineer (LLM/RAG)',\n",
       " 'Mathematiker:in / Physiker:in Aktuarielles Controlling',\n",
       " 'Operations & Marketing Associate',\n",
       " 'Portfolio Analyst (f/m/d)',\n",
       " 'Praktikant (m/w/d) Data Science',\n",
       " 'Process Development Engineer (m/f/d)',\n",
       " 'Product Analyst - Shopping Experience (m/f/d)',\n",
       " 'Product Analytics Associate (Based in Dubai)',\n",
       " 'Product Associate',\n",
       " 'Product Safety Specialist *',\n",
       " 'Project Management Assistant (Real World Data)',\n",
       " 'Publicis Media - (Junior) Data Scientist (m/w/d)',\n",
       " 'SEO - Data Analyst:in',\n",
       " 'Senior Data / Machine-Learning Engineer (w/m/d)',\n",
       " 'Senior Data Engineer Python/ML/AWS (m/f/d)- Remote',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist (m/w/d)',\n",
       " 'Senior Data Scientist (m/w/d) - ID: 233',\n",
       " 'Senior Data Scientist – Energy Storage / Li-ion / Battery Technologies',\n",
       " 'Senior Engineer Machine Learning / Deep Learning (w/m/d)',\n",
       " 'Senior ML Engineer',\n",
       " 'Senior Scientist Machine Learning - Causal Machine Learning (w/m/d)',\n",
       " 'Senior Scientist Machine Learning - Risikomodellierung und Pricing (w/m/d)',\n",
       " 'Software Engineer (Python, Machine Learning, Cloud) - Remote',\n",
       " 'Sports Scientist (m/f/x)',\n",
       " 'Sr. Machine Learning Engineer (f/m/x)',\n",
       " 'Teamlead Data Intelligence (m/w/d)',\n",
       " 'Technical Assistant - Biotechnology',\n",
       " 'Venture Development Tech Analyst (w/m/d)',\n",
       " 'Working Student (m/f/d) – Customer Intelligence',\n",
       " 'Working Student Data Analyst (x/f/m)']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(df.loc[df[\"seniority_level\"] == \"Associate\", \"title\"]).tolist()\n",
    "# Some senior, some working student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>seniority_level_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Associate</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entry level</td>\n",
       "      <td>Junior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Entry level</td>\n",
       "      <td>Intern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Associate</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>Associate</td>\n",
       "      <td>Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Director</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>Entry level</td>\n",
       "      <td>Junior</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>786 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      seniority_level  seniority_level_new\n",
       "0           Associate  Associate/Mid-Level\n",
       "1         Entry level               Junior\n",
       "2    Mid-Senior level  Associate/Mid-Level\n",
       "3         Entry level               Intern\n",
       "4           Associate  Associate/Mid-Level\n",
       "..                ...                  ...\n",
       "791         Associate               Senior\n",
       "792  Mid-Senior level  Associate/Mid-Level\n",
       "793  Mid-Senior level               Senior\n",
       "794  Mid-Senior level             Director\n",
       "795       Entry level               Junior\n",
       "\n",
       "[786 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_condition = (df[\"seniority_level\"] != df[\"seniority_level_new\"]) \\\n",
    "    & (df[\"seniority_level\"].isna() == False)\n",
    "\n",
    "df.loc[filter_condition, [\"seniority_level\", \"seniority_level_new\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "Rather inconclusive... However, seniority levels will likely match closer if entry level seniority levels are further grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create column with 5 groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group entry level positions together\n",
    "df[\"seniority_level_5\"] = df[\"seniority_level_new\"]\n",
    "\n",
    "entry_positions = [\"Junior\", \"Intern\", \"Student\", \"Trainee\"]\n",
    "\n",
    "df.loc[df[\"seniority_level_new\"].isin(entry_positions), \"seniority_level_5\"] = \"Entry level\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seniority_level_5\n",
       "Associate/Mid-Level    926\n",
       "Senior                 299\n",
       "Entry level            291\n",
       "Director                84\n",
       "Postdoc                 25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"seniority_level_5\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>seniority_level_new</th>\n",
       "      <th>seniority_level_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Associate</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Associate</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Associate</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Entry level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>Internship</td>\n",
       "      <td>Student</td>\n",
       "      <td>Entry level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>Associate</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Director</td>\n",
       "      <td>Director</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>724 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      seniority_level  seniority_level_new    seniority_level_5\n",
       "0           Associate  Associate/Mid-Level  Associate/Mid-Level\n",
       "2    Mid-Senior level  Associate/Mid-Level  Associate/Mid-Level\n",
       "4           Associate  Associate/Mid-Level  Associate/Mid-Level\n",
       "5    Mid-Senior level  Associate/Mid-Level  Associate/Mid-Level\n",
       "7           Associate               Junior          Entry level\n",
       "..                ...                  ...                  ...\n",
       "790        Internship              Student          Entry level\n",
       "791         Associate               Senior               Senior\n",
       "792  Mid-Senior level  Associate/Mid-Level  Associate/Mid-Level\n",
       "793  Mid-Senior level               Senior               Senior\n",
       "794  Mid-Senior level             Director             Director\n",
       "\n",
       "[724 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_condition = (df[\"seniority_level\"] != df[\"seniority_level_5\"]) \\\n",
    "    & (df[\"seniority_level\"].isna() == False)\n",
    "\n",
    "df.loc[filter_condition, [\"seniority_level\", \"seniority_level_new\", \"seniority_level_5\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect and Drop Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I'll check whether duplicates can be detected by using the entirety or the most relevant columns.\n",
    "\n",
    "These include job title, company name, seniority and location.\n",
    "\n",
    "Why? The same job could be advertised for different branches/locations.\n",
    "A similar job posting might have been posted targeting different levels of seniority\n",
    "\n",
    "I'll also use the job description, however, this will likely not proof to be efficient as simple matching fails \n",
    "\n",
    "even if one character differs. This could be a \"\\n\" or an additional heading, e.g. \"Benefits:\n",
    "\n",
    "Hence, string similarity meausures will be applied in the upcoming steps as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>date_accessed</th>\n",
       "      <th>days_online</th>\n",
       "      <th>number_applicants</th>\n",
       "      <th>job_type_Vollzeit</th>\n",
       "      <th>...</th>\n",
       "      <th>job_type_Praktikum</th>\n",
       "      <th>job_type_Werkstudent</th>\n",
       "      <th>job_description_anonymized</th>\n",
       "      <th>source_id</th>\n",
       "      <th>location_clean</th>\n",
       "      <th>company_clean_ish</th>\n",
       "      <th>company_clean</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>seniority_level_new</th>\n",
       "      <th>seniority_level_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>Applied Scientist, Artificial General Intellig...</td>\n",
       "      <td>Amazon Development Center Germany GmbH</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PhD, or a Master's degree and experience in CS...</td>\n",
       "      <td>2</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>AMAZON DEVELOPMENT CENTER GERMANY</td>\n",
       "      <td>Amazon Development Center Germany GmbH</td>\n",
       "      <td>Applied Scientist, Artificial General Intellig...</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>Applied Scientist, Artificial General Intellig...</td>\n",
       "      <td>Amazon Development Center Germany GmbH</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PhD, or a Master's degree and experience in CS...</td>\n",
       "      <td>2</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>AMAZON DEVELOPMENT CENTER GERMANY</td>\n",
       "      <td>Amazon Development Center Germany GmbH</td>\n",
       "      <td>Applied Scientist, Artificial General Intellig...</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>Senior Consultant IT Regulatory Risk / Risikom...</td>\n",
       "      <td>Deloitte GmbH</td>\n",
       "      <td>Köln</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Du machst den Unterschied. Ob im Business Audi...</td>\n",
       "      <td>2</td>\n",
       "      <td>Köln</td>\n",
       "      <td>DELOITTE</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Senior Consultant IT Regulatory Risk / Risikom...</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>Senior Consultant IT Regulatory Risk / Risikom...</td>\n",
       "      <td>Deloitte GmbH</td>\n",
       "      <td>Köln</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Du machst den Unterschied. Ob im Business Audi...</td>\n",
       "      <td>2</td>\n",
       "      <td>Köln</td>\n",
       "      <td>DELOITTE</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Senior Consultant IT Regulatory Risk / Risikom...</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>Data Architekt / Data Engineer / Data Scientis...</td>\n",
       "      <td>Wego Systembaustoffe GmbH</td>\n",
       "      <td>Hanau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>für unsere Zentrale in Hanau-Steinheim\\nDeine ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Hanau</td>\n",
       "      <td>WEGO SYSTEMBAUSTOFFE</td>\n",
       "      <td>Wego Systembaustoffe GmbH</td>\n",
       "      <td>Data Architekt / Data Engineer / Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>Data Architekt / Data Engineer / Data Scientis...</td>\n",
       "      <td>Wego Systembaustoffe GmbH</td>\n",
       "      <td>Hanau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>für unsere Zentrale in Hanau-Steinheim\\nDeine ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Hanau</td>\n",
       "      <td>WEGO SYSTEMBAUSTOFFE</td>\n",
       "      <td>Wego Systembaustoffe GmbH</td>\n",
       "      <td>Data Architekt / Data Engineer / Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title   \n",
       "955   Applied Scientist, Artificial General Intellig...  \\\n",
       "1032  Applied Scientist, Artificial General Intellig...   \n",
       "1076  Senior Consultant IT Regulatory Risk / Risikom...   \n",
       "1077  Senior Consultant IT Regulatory Risk / Risikom...   \n",
       "1178  Data Architekt / Data Engineer / Data Scientis...   \n",
       "1237  Data Architekt / Data Engineer / Data Scientis...   \n",
       "\n",
       "                                     company location salary seniority_level   \n",
       "955   Amazon Development Center Germany GmbH   Berlin    NaN             NaN  \\\n",
       "1032  Amazon Development Center Germany GmbH   Berlin    NaN             NaN   \n",
       "1076                           Deloitte GmbH     Köln    NaN             NaN   \n",
       "1077                           Deloitte GmbH     Köln    NaN             NaN   \n",
       "1178               Wego Systembaustoffe GmbH    Hanau    NaN             NaN   \n",
       "1237               Wego Systembaustoffe GmbH    Hanau    NaN             NaN   \n",
       "\n",
       "     date_posted date_accessed  days_online  number_applicants   \n",
       "955          NaN    2024-12-12          NaN                NaN  \\\n",
       "1032         NaN    2024-12-12          NaN                NaN   \n",
       "1076         NaN    2024-12-12          NaN                NaN   \n",
       "1077         NaN    2024-12-12          NaN                NaN   \n",
       "1178         NaN    2024-12-12          NaN                NaN   \n",
       "1237         NaN    2024-12-12          NaN                NaN   \n",
       "\n",
       "      job_type_Vollzeit  ...  job_type_Praktikum  job_type_Werkstudent   \n",
       "955                   1  ...                   0                     0  \\\n",
       "1032                  1  ...                   0                     0   \n",
       "1076                  1  ...                   0                     0   \n",
       "1077                  1  ...                   0                     0   \n",
       "1178                  0  ...                   0                     0   \n",
       "1237                  0  ...                   0                     0   \n",
       "\n",
       "                             job_description_anonymized  source_id   \n",
       "955   PhD, or a Master's degree and experience in CS...          2  \\\n",
       "1032  PhD, or a Master's degree and experience in CS...          2   \n",
       "1076  Du machst den Unterschied. Ob im Business Audi...          2   \n",
       "1077  Du machst den Unterschied. Ob im Business Audi...          2   \n",
       "1178  für unsere Zentrale in Hanau-Steinheim\\nDeine ...          2   \n",
       "1237  für unsere Zentrale in Hanau-Steinheim\\nDeine ...          2   \n",
       "\n",
       "      location_clean                  company_clean_ish   \n",
       "955           Berlin  AMAZON DEVELOPMENT CENTER GERMANY  \\\n",
       "1032          Berlin  AMAZON DEVELOPMENT CENTER GERMANY   \n",
       "1076            Köln                           DELOITTE   \n",
       "1077            Köln                           DELOITTE   \n",
       "1178           Hanau               WEGO SYSTEMBAUSTOFFE   \n",
       "1237           Hanau               WEGO SYSTEMBAUSTOFFE   \n",
       "\n",
       "                               company_clean   \n",
       "955   Amazon Development Center Germany GmbH  \\\n",
       "1032  Amazon Development Center Germany GmbH   \n",
       "1076                                Deloitte   \n",
       "1077                                Deloitte   \n",
       "1178               Wego Systembaustoffe GmbH   \n",
       "1237               Wego Systembaustoffe GmbH   \n",
       "\n",
       "                                            title_clean  seniority_level_new   \n",
       "955   Applied Scientist, Artificial General Intellig...  Associate/Mid-Level  \\\n",
       "1032  Applied Scientist, Artificial General Intellig...  Associate/Mid-Level   \n",
       "1076  Senior Consultant IT Regulatory Risk / Risikom...               Senior   \n",
       "1077  Senior Consultant IT Regulatory Risk / Risikom...               Senior   \n",
       "1178    Data Architekt / Data Engineer / Data Scientist  Associate/Mid-Level   \n",
       "1237    Data Architekt / Data Engineer / Data Scientist  Associate/Mid-Level   \n",
       "\n",
       "        seniority_level_5  \n",
       "955   Associate/Mid-Level  \n",
       "1032  Associate/Mid-Level  \n",
       "1076               Senior  \n",
       "1077               Senior  \n",
       "1178  Associate/Mid-Level  \n",
       "1237  Associate/Mid-Level  \n",
       "\n",
       "[6 rows x 27 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See whether there are duplicates when taking into account all columns\n",
    "df[df.duplicated(keep=False)].sort_values(by=\"company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to only a few selected columns\n",
    "columns_selected = [\"title_clean\", \n",
    "                    \"company_clean\", \n",
    "                    \"location_clean\", \n",
    "                    \"seniority_level_5\", \n",
    "                    \"job_description_anonymized\"]\n",
    "sum(df.filter(columns_selected).duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_clean</th>\n",
       "      <th>company_clean</th>\n",
       "      <th>location_clean</th>\n",
       "      <th>seniority_level_5</th>\n",
       "      <th>job_description_anonymized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>Applied Scientist, Artificial General Intellig...</td>\n",
       "      <td>Amazon Development Center Germany GmbH</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>PhD, or a Master's degree and experience in CS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>Applied Scientist, Artificial General Intellig...</td>\n",
       "      <td>Amazon Development Center Germany GmbH</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>PhD, or a Master's degree and experience in CS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>DATA ANALYST</td>\n",
       "      <td>Instaffo</td>\n",
       "      <td>München</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Du bist interessiert an der Stelle als DATA AN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>DATA ANALYST</td>\n",
       "      <td>Instaffo</td>\n",
       "      <td>München</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Du bist interessiert an der Stelle als DATA AN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>CBTW</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Willkommen bei CBTW! Wir sind ein innovatives ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>CBTW</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Willkommen bei CBTW! Wir sind ein innovatives ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>CBTW</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Willkommen bei CBTW! Wir sind ein innovatives ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>CBTW</td>\n",
       "      <td>München</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Willkommen bei CBTW! Wir sind ein innovatives ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>CBTW</td>\n",
       "      <td>München</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Willkommen bei CBTW! Wir sind ein innovatives ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>Data Architekt / Data Engineer / Data Scientist</td>\n",
       "      <td>Wego Systembaustoffe GmbH</td>\n",
       "      <td>Hanau</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>für unsere Zentrale in Hanau-Steinheim\\nDeine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>Data Architekt / Data Engineer / Data Scientist</td>\n",
       "      <td>Wego Systembaustoffe GmbH</td>\n",
       "      <td>Hanau</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>für unsere Zentrale in Hanau-Steinheim\\nDeine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>cosnova</td>\n",
       "      <td>Sulzbach</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>cosnova GmbHLimesparkBerufserfahrungITSoftware...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>cosnova</td>\n",
       "      <td>Sulzbach</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>cosnova GmbHLimesparkBerufserfahrungITSoftware...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Data Scientist Lead and Team Lead \"Customer In...</td>\n",
       "      <td>Axel Springer</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Director</td>\n",
       "      <td>Axel Springer National Media &amp; Tech is respons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Data Scientist Lead and Team Lead \"Customer In...</td>\n",
       "      <td>Axel Springer</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Director</td>\n",
       "      <td>Axel Springer National Media &amp; Tech is respons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>MLOps Engineer</td>\n",
       "      <td>Centric Software</td>\n",
       "      <td>Düsseldorf</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>As an MLOps Engineer at Centric Software, you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>MLOps Engineer</td>\n",
       "      <td>Centric Software</td>\n",
       "      <td>Düsseldorf</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>As an MLOps Engineer at Centric Software, you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>Senior Consultant IT Regulatory Risk / Risikom...</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Köln</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Du machst den Unterschied. Ob im Business Audi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>Senior Consultant IT Regulatory Risk / Risikom...</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Köln</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Du machst den Unterschied. Ob im Business Audi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>Working Student  – Customer Intelligence</td>\n",
       "      <td>Axel Springer</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Axel Springer National Media &amp; Tech is respons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>Working Student  – Customer Intelligence</td>\n",
       "      <td>Axel Springer</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Axel Springer National Media &amp; Tech is respons...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title_clean   \n",
       "955   Applied Scientist, Artificial General Intellig...  \\\n",
       "1032  Applied Scientist, Artificial General Intellig...   \n",
       "710                                        DATA ANALYST   \n",
       "716                                        DATA ANALYST   \n",
       "536                                        Data Analyst   \n",
       "599                                        Data Analyst   \n",
       "682                                        Data Analyst   \n",
       "609                                        Data Analyst   \n",
       "666                                        Data Analyst   \n",
       "1178    Data Architekt / Data Engineer / Data Scientist   \n",
       "1237    Data Architekt / Data Engineer / Data Scientist   \n",
       "108                                      Data Scientist   \n",
       "197                                      Data Scientist   \n",
       "279   Data Scientist Lead and Team Lead \"Customer In...   \n",
       "324   Data Scientist Lead and Team Lead \"Customer In...   \n",
       "182                                      MLOps Engineer   \n",
       "243                                      MLOps Engineer   \n",
       "1076  Senior Consultant IT Regulatory Risk / Risikom...   \n",
       "1077  Senior Consultant IT Regulatory Risk / Risikom...   \n",
       "379            Working Student  – Customer Intelligence   \n",
       "535            Working Student  – Customer Intelligence   \n",
       "\n",
       "                               company_clean     location_clean   \n",
       "955   Amazon Development Center Germany GmbH             Berlin  \\\n",
       "1032  Amazon Development Center Germany GmbH             Berlin   \n",
       "710                                 Instaffo            München   \n",
       "716                                 Instaffo            München   \n",
       "536                                     CBTW  Frankfurt am Main   \n",
       "599                                     CBTW  Frankfurt am Main   \n",
       "682                                     CBTW  Frankfurt am Main   \n",
       "609                                     CBTW            München   \n",
       "666                                     CBTW            München   \n",
       "1178               Wego Systembaustoffe GmbH              Hanau   \n",
       "1237               Wego Systembaustoffe GmbH              Hanau   \n",
       "108                                  cosnova           Sulzbach   \n",
       "197                                  cosnova           Sulzbach   \n",
       "279                            Axel Springer             Berlin   \n",
       "324                            Axel Springer             Berlin   \n",
       "182                         Centric Software         Düsseldorf   \n",
       "243                         Centric Software         Düsseldorf   \n",
       "1076                                Deloitte               Köln   \n",
       "1077                                Deloitte               Köln   \n",
       "379                            Axel Springer             Berlin   \n",
       "535                            Axel Springer             Berlin   \n",
       "\n",
       "        seniority_level_5                         job_description_anonymized  \n",
       "955   Associate/Mid-Level  PhD, or a Master's degree and experience in CS...  \n",
       "1032  Associate/Mid-Level  PhD, or a Master's degree and experience in CS...  \n",
       "710   Associate/Mid-Level  Du bist interessiert an der Stelle als DATA AN...  \n",
       "716   Associate/Mid-Level  Du bist interessiert an der Stelle als DATA AN...  \n",
       "536   Associate/Mid-Level  Willkommen bei CBTW! Wir sind ein innovatives ...  \n",
       "599   Associate/Mid-Level  Willkommen bei CBTW! Wir sind ein innovatives ...  \n",
       "682   Associate/Mid-Level  Willkommen bei CBTW! Wir sind ein innovatives ...  \n",
       "609   Associate/Mid-Level  Willkommen bei CBTW! Wir sind ein innovatives ...  \n",
       "666   Associate/Mid-Level  Willkommen bei CBTW! Wir sind ein innovatives ...  \n",
       "1178  Associate/Mid-Level  für unsere Zentrale in Hanau-Steinheim\\nDeine ...  \n",
       "1237  Associate/Mid-Level  für unsere Zentrale in Hanau-Steinheim\\nDeine ...  \n",
       "108   Associate/Mid-Level  cosnova GmbHLimesparkBerufserfahrungITSoftware...  \n",
       "197   Associate/Mid-Level  cosnova GmbHLimesparkBerufserfahrungITSoftware...  \n",
       "279              Director  Axel Springer National Media & Tech is respons...  \n",
       "324              Director  Axel Springer National Media & Tech is respons...  \n",
       "182   Associate/Mid-Level  As an MLOps Engineer at Centric Software, you ...  \n",
       "243   Associate/Mid-Level  As an MLOps Engineer at Centric Software, you ...  \n",
       "1076               Senior  Du machst den Unterschied. Ob im Business Audi...  \n",
       "1077               Senior  Du machst den Unterschied. Ob im Business Audi...  \n",
       "379           Entry level  Axel Springer National Media & Tech is respons...  \n",
       "535           Entry level  Axel Springer National Media & Tech is respons...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show those duplicate listings.\n",
    "df[df.filter(columns_selected).duplicated(keep=False)] \\\n",
    "    .filter(columns_selected) \\\n",
    "    .sort_values(by=[\"title_clean\", \"location_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns before removing duplicates: 1625\n",
      "Columns after removing duplicates: 1614\n"
     ]
    }
   ],
   "source": [
    "# These are clearly duplicates. Drop the duplicate row; i.e. Keep the first occurance of these listings\n",
    "columns_selected = [\"title_clean\", \n",
    "                    \"company_clean\", \n",
    "                    \"location_clean\", \n",
    "                    \"seniority_level_5\", \n",
    "                    \"job_description_anonymized\"]\n",
    "\n",
    "print(\"Columns before removing duplicates:\", len(df))\n",
    "df = df.drop_duplicates(subset=columns_selected)\n",
    "\n",
    "print(\"Columns after removing duplicates:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine columns to detect duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_selected = [\"title_clean\", \n",
    "                    \"company_clean\", \n",
    "                    \"location_clean\", \n",
    "                    \"seniority_level_5\"]\n",
    "\n",
    "sum(df.filter(columns_selected).duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'company', 'location', 'salary', 'seniority_level',\n",
       "       'date_posted', 'date_accessed', 'days_online', 'number_applicants',\n",
       "       'job_type_Vollzeit', 'job_type_Teilzeit', 'job_type_Festanstellung',\n",
       "       'job_type_BefristeterVertrag', 'job_type_Homeoffice',\n",
       "       'job_type_FreieMitarbeit', 'job_type_Traineeprogramm',\n",
       "       'job_type_Berufsausbildung', 'job_type_Praktikum',\n",
       "       'job_type_Werkstudent', 'job_description_anonymized', 'source_id',\n",
       "       'location_clean', 'company_clean_ish', 'company_clean', 'title_clean',\n",
       "       'seniority_level_new', 'seniority_level_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_clean</th>\n",
       "      <th>company_clean</th>\n",
       "      <th>location_clean</th>\n",
       "      <th>seniority_level_5</th>\n",
       "      <th>source_id</th>\n",
       "      <th>job_description_anonymized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ACONEXT</td>\n",
       "      <td>Fellbach</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>1</td>\n",
       "      <td>Willst du die InnovatiWEITERE STELLENANGEBOTES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ACONEXT</td>\n",
       "      <td>Fellbach</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>2</td>\n",
       "      <td>Willst du die Innovationen voe\\nBewerbung WEIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ACONEXT</td>\n",
       "      <td>Fellbach</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>3</td>\n",
       "      <td>MITTELSTÄNDISCH • PRAGMATISCH • LEIDENSCHAFTLI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Data Scientist Automotive</td>\n",
       "      <td>ACONEXT</td>\n",
       "      <td>Fellbach</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>1</td>\n",
       "      <td>Willst du die Innovationen vog WEITERE STELLEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>Data Scientist Automotive</td>\n",
       "      <td>ACONEXT</td>\n",
       "      <td>Fellbach</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>2</td>\n",
       "      <td>Willst du die Innovationen von morgen mitewerb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>Trainee Data Science  - 12 Monate</td>\n",
       "      <td>taod Consulting GmbH</td>\n",
       "      <td>Köln</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>2</td>\n",
       "      <td>Wir suchen dataful minds. Mit unserer Leidensc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Data Scientist - Ranking</td>\n",
       "      <td>trivago</td>\n",
       "      <td>Düsseldorf</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>1</td>\n",
       "      <td>When travelers are searching for a hotel, we w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>Data Scientist - Ranking</td>\n",
       "      <td>trivago</td>\n",
       "      <td>Düsseldorf</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>2</td>\n",
       "      <td>When travelers are searching for a hotel, we w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>Senior Data Scientist * Generative AI</td>\n",
       "      <td>valantic Software &amp; Technology Innovations GmbH</td>\n",
       "      <td>Eschborn</td>\n",
       "      <td>Senior</td>\n",
       "      <td>2</td>\n",
       "      <td>Beschreibung\\nWir suchen einen Senior Data Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>Senior Data Scientist * Generative AI</td>\n",
       "      <td>valantic Software &amp; Technology Innovations GmbH</td>\n",
       "      <td>Eschborn</td>\n",
       "      <td>Senior</td>\n",
       "      <td>3</td>\n",
       "      <td>Die valantic Software &amp; Technology Innovations...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title_clean   \n",
       "154                          Data Scientist  \\\n",
       "823                          Data Scientist   \n",
       "1288                         Data Scientist   \n",
       "163               Data Scientist Automotive   \n",
       "809               Data Scientist Automotive   \n",
       "...                                     ...   \n",
       "1239      Trainee Data Science  - 12 Monate   \n",
       "301                Data Scientist - Ranking   \n",
       "839                Data Scientist - Ranking   \n",
       "1225  Senior Data Scientist * Generative AI   \n",
       "1331  Senior Data Scientist * Generative AI   \n",
       "\n",
       "                                        company_clean location_clean   \n",
       "154                                           ACONEXT       Fellbach  \\\n",
       "823                                           ACONEXT       Fellbach   \n",
       "1288                                          ACONEXT       Fellbach   \n",
       "163                                           ACONEXT       Fellbach   \n",
       "809                                           ACONEXT       Fellbach   \n",
       "...                                               ...            ...   \n",
       "1239                             taod Consulting GmbH           Köln   \n",
       "301                                           trivago     Düsseldorf   \n",
       "839                                           trivago     Düsseldorf   \n",
       "1225  valantic Software & Technology Innovations GmbH       Eschborn   \n",
       "1331  valantic Software & Technology Innovations GmbH       Eschborn   \n",
       "\n",
       "        seniority_level_5  source_id   \n",
       "154   Associate/Mid-Level          1  \\\n",
       "823   Associate/Mid-Level          2   \n",
       "1288  Associate/Mid-Level          3   \n",
       "163   Associate/Mid-Level          1   \n",
       "809   Associate/Mid-Level          2   \n",
       "...                   ...        ...   \n",
       "1239          Entry level          2   \n",
       "301   Associate/Mid-Level          1   \n",
       "839   Associate/Mid-Level          2   \n",
       "1225               Senior          2   \n",
       "1331               Senior          3   \n",
       "\n",
       "                             job_description_anonymized  \n",
       "154   Willst du die InnovatiWEITERE STELLENANGEBOTES...  \n",
       "823   Willst du die Innovationen voe\\nBewerbung WEIT...  \n",
       "1288  MITTELSTÄNDISCH • PRAGMATISCH • LEIDENSCHAFTLI...  \n",
       "163   Willst du die Innovationen vog WEITERE STELLEN...  \n",
       "809   Willst du die Innovationen von morgen mitewerb...  \n",
       "...                                                 ...  \n",
       "1239  Wir suchen dataful minds. Mit unserer Leidensc...  \n",
       "301   When travelers are searching for a hotel, we w...  \n",
       "839   When travelers are searching for a hotel, we w...  \n",
       "1225  Beschreibung\\nWir suchen einen Senior Data Sci...  \n",
       "1331  Die valantic Software & Technology Innovations...  \n",
       "\n",
       "[285 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform some manual checks in excel file\n",
    "columns_selected = [\"title_clean\", \n",
    "                    \"company_clean\", \n",
    "                    \"location_clean\", \n",
    "                    \"seniority_level_5\"]\n",
    "\n",
    "display_columns = columns_selected + [\"source_id\", \"job_description_anonymized\"]\n",
    "\n",
    "row_selection = df.filter(columns_selected).duplicated(keep=False)\n",
    "\n",
    "df_out = df.loc[row_selection, display_columns] \\\n",
    "    .sort_values(by=[\"company_clean\", \"title_clean\", \"location_clean\"])\n",
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store original index for upcoming aggregation\n",
    "df[\"index_pre_agg\"] = df.index\n",
    "df[\"index_agg_list\"] = df.index # to store all ids that were aggregated into 1 row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows before aggregation: 1614\n",
      "number of rows after aggregation: 1468 (dif: 146)\n"
     ]
    }
   ],
   "source": [
    "group_by_columns = [\"title_clean\", \"company_clean\", \"location_clean\"]\n",
    "\n",
    "# set aggregation functions to: \n",
    "# - max for numeric values (except index), \n",
    "# - first for object types (except source, which will be stored in a set)\n",
    "aggregation_functions = {col: \"first\" if df[col].dtype == \"O\" else \"max\" for col in df.columns}\n",
    "aggregation_functions.update(index_pre_agg = min)\n",
    "aggregation_functions.update(index_agg_list = list)\n",
    "aggregation_functions.update(source_id = list)\n",
    "\n",
    "df_len_pre = len(df)\n",
    "print(\"number of rows before aggregation:\", df_len_pre)\n",
    "\n",
    "# Aggregate; Restore original index and order\n",
    "df = df.groupby(group_by_columns, as_index=False).agg(aggregation_functions).reset_index(drop=True)\n",
    "df.index = df[\"index_pre_agg\"].to_list()\n",
    "df = df.sort_index()\n",
    "\n",
    "print(f\"number of rows after aggregation: {len(df)} (dif: {df_len_pre - len(df)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>date_accessed</th>\n",
       "      <th>days_online</th>\n",
       "      <th>number_applicants</th>\n",
       "      <th>job_type_Vollzeit</th>\n",
       "      <th>...</th>\n",
       "      <th>job_description_anonymized</th>\n",
       "      <th>source_id</th>\n",
       "      <th>location_clean</th>\n",
       "      <th>company_clean_ish</th>\n",
       "      <th>company_clean</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>seniority_level_new</th>\n",
       "      <th>seniority_level_5</th>\n",
       "      <th>index_pre_agg</th>\n",
       "      <th>index_agg_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Graduate</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>None</td>\n",
       "      <td>Associate</td>\n",
       "      <td>2024-11-22</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>17.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Company DescriptionFascinated by the future an...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>VISA</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Data Science Graduate</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Xsolla</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>None</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>9.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Xsolla is looking for a Junior Data Scientist ...</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>XSOLLA</td>\n",
       "      <td>Xsolla</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1183]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Global Market Solutions - Germany</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>None</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>26.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>GMS is an operational consultancy with experti...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>GLOBAL MARKET SOLUTIONS   GERMANY</td>\n",
       "      <td>Global Market Solutions - Germany</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>MeloTech</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>None</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>313.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Your missionPropose innovative solutions by ex...</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>MELOTECH</td>\n",
       "      <td>MeloTech</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Intern</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>3</td>\n",
       "      <td>[3, 1105]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist (f/m/d)</td>\n",
       "      <td>vent.io</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>None</td>\n",
       "      <td>Associate</td>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>19.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>The target of vent.io is to accelerate the gro...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>VENT IO</td>\n",
       "      <td>vent.io</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>4</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title                            company   \n",
       "0   Data Science Graduate                               Visa  \\\n",
       "1   Junior Data Scientist                             Xsolla   \n",
       "2          Data Scientist  Global Market Solutions - Germany   \n",
       "3   Data Scientist Intern                           MeloTech   \n",
       "4  Data Scientist (f/m/d)                            vent.io   \n",
       "\n",
       "            location salary   seniority_level date_posted date_accessed   \n",
       "0             Berlin   None         Associate  2024-11-22    2024-12-09  \\\n",
       "1             Berlin   None       Entry level  2024-11-30    2024-12-09   \n",
       "2  Frankfurt am Main   None  Mid-Senior level  2024-11-13    2024-12-09   \n",
       "3             Berlin   None       Entry level  2024-01-31    2024-12-09   \n",
       "4  Frankfurt am Main   None         Associate  2024-11-20    2024-12-09   \n",
       "\n",
       "   days_online  number_applicants  job_type_Vollzeit  ...   \n",
       "0         17.0              200.0                  1  ...  \\\n",
       "1          9.0              200.0                  1  ...   \n",
       "2         26.0              200.0                  1  ...   \n",
       "3        313.0              200.0                  1  ...   \n",
       "4         19.0              200.0                  1  ...   \n",
       "\n",
       "                          job_description_anonymized  source_id   \n",
       "0  Company DescriptionFascinated by the future an...        [1]  \\\n",
       "1  Xsolla is looking for a Junior Data Scientist ...     [1, 2]   \n",
       "2  GMS is an operational consultancy with experti...     [1, 1]   \n",
       "3  Your missionPropose innovative solutions by ex...     [1, 2]   \n",
       "4  The target of vent.io is to accelerate the gro...        [1]   \n",
       "\n",
       "      location_clean                  company_clean_ish   \n",
       "0             Berlin                               VISA  \\\n",
       "1             Berlin                             XSOLLA   \n",
       "2  Frankfurt am Main  GLOBAL MARKET SOLUTIONS   GERMANY   \n",
       "3             Berlin                           MELOTECH   \n",
       "4  Frankfurt am Main                            VENT IO   \n",
       "\n",
       "                       company_clean            title_clean   \n",
       "0                               Visa  Data Science Graduate  \\\n",
       "1                             Xsolla  Junior Data Scientist   \n",
       "2  Global Market Solutions - Germany         Data Scientist   \n",
       "3                           MeloTech  Data Scientist Intern   \n",
       "4                            vent.io         Data Scientist   \n",
       "\n",
       "   seniority_level_new    seniority_level_5  index_pre_agg index_agg_list  \n",
       "0  Associate/Mid-Level  Associate/Mid-Level              0            [0]  \n",
       "1               Junior          Entry level              1      [1, 1183]  \n",
       "2  Associate/Mid-Level  Associate/Mid-Level              2        [2, 19]  \n",
       "3               Intern          Entry level              3      [3, 1105]  \n",
       "4  Associate/Mid-Level  Associate/Mid-Level              4            [4]  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_id\n",
       "[1]          683\n",
       "[2]          340\n",
       "[3]          306\n",
       "[1, 2]        70\n",
       "[2, 3]        29\n",
       "[2, 2]        13\n",
       "[1, 3]        11\n",
       "[1, 1]         9\n",
       "[1, 2, 3]      4\n",
       "[1, 2, 2]      2\n",
       "[2, 2, 3]      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform source into string again.\n",
    "df[\"source_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flag duplicates using job descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Levenshtein algorithm is used as it is recommended for comparing strings of different lenghts.\n",
    " Also, in a preceeding test run, the similarity ratios were calculated around 20 times faster\n",
    " compared to the SequenceMatcher ratio applied by the difflib package (Lev: 2.4 sec, difflib: 55.3 sec)\n",
    "\n",
    "Rows will be flagged if similarity score is larger than pre-defined thresholds, and location as well as seniority are not identical.\n",
    "(As mentioned before, one job could be listed targeting different seniority levels or locations)\n",
    "Store/concatenate indices in both listings to compare in later stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now comparing at index1: 100/1468\n",
      "Now comparing at index1: 200/1468\n",
      "Now comparing at index1: 300/1468\n",
      "Now comparing at index1: 400/1468\n",
      "Now comparing at index1: 500/1468\n",
      "Now comparing at index1: 600/1468\n",
      "Now comparing at index1: 700/1468\n",
      "Now comparing at index1: 800/1468\n",
      "Now comparing at index1: 900/1468\n",
      "Now comparing at index1: 1000/1468\n",
      "Now comparing at index1: 1100/1468\n",
      "Now comparing at index1: 1200/1468\n",
      "Now comparing at index1: 1300/1468\n",
      "Now comparing at index1: 1400/1468\n"
     ]
    }
   ],
   "source": [
    "df_indices = df.index.to_list()\n",
    "\n",
    "# Define thresholds to be flagged\n",
    "similarity_thresholds = [0.90, 0.93, 0.95, 0.97]\n",
    "\n",
    "# Initialize dictionary to store results in\n",
    "col_names_suffix = [str(f\"{s:.2f}\").replace(\".\", \"_\") for s in similarity_thresholds]\n",
    "col_names = [f\"similarity_results_{t}\" for t in col_names_suffix]\n",
    "\n",
    "similarity_results = pd.DataFrame(\n",
    "        {col: [[] for _ in range(len(df))] for col in col_names},\n",
    "        index=df_indices\n",
    "    )\n",
    "\n",
    "# Initialize iterator to be used to flag multiple listings \n",
    "merge_group_iterator = 0\n",
    "\n",
    "for ind_nr, index1 in enumerate(df_indices):\n",
    "    if ind_nr > 0 and ind_nr % 100 == 0:\n",
    "        print(f\"Now comparing at index1: {ind_nr}/{len(df)}\")\n",
    "    loc1 = df[\"location_clean\"][index1]\n",
    "    sen1 = df[\"seniority_level_new\"][index1]\n",
    "    str1 = df[\"job_description_anonymized\"][index1]\n",
    "\n",
    "    for index2 in df_indices:\n",
    "        # Skip comparison if rows have already been compared\n",
    "        if index1 >= index2:\n",
    "            continue\n",
    "        # Skip comparison if location is different.\n",
    "        loc2 = df[\"location_clean\"][index2]\n",
    "        if loc1 != loc2:\n",
    "            continue\n",
    "        # Skip comparison if seniority level is different.\n",
    "        sen2 = df[\"seniority_level_new\"][index2]\n",
    "        if sen1 != sen2:\n",
    "            continue\n",
    "        \n",
    "        # Compute similarity\n",
    "        str2 = df[\"job_description_anonymized\"][index2]\n",
    "        similarity = Levenshtein.ratio(str1, str2)\n",
    "        \n",
    "        # Check value against each threshold and store results in respective cells\n",
    "        for threshold_id, threshold in enumerate(similarity_thresholds):\n",
    "            if similarity >= threshold:\n",
    "                # print(f\"Similar results found at index1: {index1}, index2: {index2} (threshold: {threshold}).\")\n",
    "                col = col_names[threshold_id]\n",
    "                # Use merge_group if existing, otherwise grab from iterator\n",
    "                if len(similarity_results.loc[index1, col]) > 0:\n",
    "                    merge_group = similarity_results.loc[index1, col][-1][-1]\n",
    "                elif len(similarity_results.loc[index2, col]) > 0:\n",
    "                    merge_group = similarity_results.loc[index2, col][-1][-1]\n",
    "                else:\n",
    "                    merge_group = merge_group_iterator\n",
    "                    merge_group_iterator += 1\n",
    "                    \n",
    "                sim1 = tuple([index2, round(similarity, 3), merge_group])\n",
    "                sim2 = tuple([index1, round(similarity, 3), merge_group])\n",
    "                \n",
    "                similarity_results[col][index1].append(sim1)\n",
    "                similarity_results[col][index2].append(sim2)\n",
    "\n",
    "# this took 8:22 minutes\n",
    "# this took 0:38 minutes (with location check)\n",
    "# this took 0:18 minutes (with location and seniority check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "94\n",
      "86\n",
      "69\n"
     ]
    }
   ],
   "source": [
    "# similarity_results[\"similarity_results_0_90\"].map(lambda x: len(x)==0, pd.NA).isna().sum()\n",
    "print(similarity_results[\"similarity_results_0_90\"].map(lambda x: len(x)>0).sum())\n",
    "print(similarity_results[\"similarity_results_0_93\"].map(lambda x: len(x)>0).sum())\n",
    "print(similarity_results[\"similarity_results_0_95\"].map(lambda x: len(x)>0).sum())\n",
    "print(similarity_results[\"similarity_results_0_97\"].map(lambda x: len(x)>0).sum())\n",
    "\n",
    "# CHECKS                             0_90   0_93    0_95    0_97\n",
    "# Without location check:            315    -       265     229\n",
    "# With location check:               153    -       97      75\n",
    "# With location and seniority check: 125    94      86      69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>date_accessed</th>\n",
       "      <th>days_online</th>\n",
       "      <th>number_applicants</th>\n",
       "      <th>job_type_Vollzeit</th>\n",
       "      <th>...</th>\n",
       "      <th>company_clean</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>seniority_level_new</th>\n",
       "      <th>seniority_level_5</th>\n",
       "      <th>index_pre_agg</th>\n",
       "      <th>index_agg_list</th>\n",
       "      <th>similarity_results_0_90</th>\n",
       "      <th>similarity_results_0_93</th>\n",
       "      <th>similarity_results_0_95</th>\n",
       "      <th>similarity_results_0_97</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Graduate</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>None</td>\n",
       "      <td>Associate</td>\n",
       "      <td>2024-11-22</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>17.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Data Science Graduate</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Xsolla</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>None</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>9.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Xsolla</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1183]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Global Market Solutions - Germany</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>None</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>26.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Global Market Solutions - Germany</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 19]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>MeloTech</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>None</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>313.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>MeloTech</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Intern</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>3</td>\n",
       "      <td>[3, 1105]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist (f/m/d)</td>\n",
       "      <td>vent.io</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>None</td>\n",
       "      <td>Associate</td>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>19.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>vent.io</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>4</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title                            company   \n",
       "0   Data Science Graduate                               Visa  \\\n",
       "1   Junior Data Scientist                             Xsolla   \n",
       "2          Data Scientist  Global Market Solutions - Germany   \n",
       "3   Data Scientist Intern                           MeloTech   \n",
       "4  Data Scientist (f/m/d)                            vent.io   \n",
       "\n",
       "            location salary   seniority_level date_posted date_accessed   \n",
       "0             Berlin   None         Associate  2024-11-22    2024-12-09  \\\n",
       "1             Berlin   None       Entry level  2024-11-30    2024-12-09   \n",
       "2  Frankfurt am Main   None  Mid-Senior level  2024-11-13    2024-12-09   \n",
       "3             Berlin   None       Entry level  2024-01-31    2024-12-09   \n",
       "4  Frankfurt am Main   None         Associate  2024-11-20    2024-12-09   \n",
       "\n",
       "   days_online  number_applicants  job_type_Vollzeit  ...   \n",
       "0         17.0              200.0                  1  ...  \\\n",
       "1          9.0              200.0                  1  ...   \n",
       "2         26.0              200.0                  1  ...   \n",
       "3        313.0              200.0                  1  ...   \n",
       "4         19.0              200.0                  1  ...   \n",
       "\n",
       "                       company_clean            title_clean   \n",
       "0                               Visa  Data Science Graduate  \\\n",
       "1                             Xsolla  Junior Data Scientist   \n",
       "2  Global Market Solutions - Germany         Data Scientist   \n",
       "3                           MeloTech  Data Scientist Intern   \n",
       "4                            vent.io         Data Scientist   \n",
       "\n",
       "   seniority_level_new    seniority_level_5  index_pre_agg  index_agg_list   \n",
       "0  Associate/Mid-Level  Associate/Mid-Level              0             [0]  \\\n",
       "1               Junior          Entry level              1       [1, 1183]   \n",
       "2  Associate/Mid-Level  Associate/Mid-Level              2         [2, 19]   \n",
       "3               Intern          Entry level              3       [3, 1105]   \n",
       "4  Associate/Mid-Level  Associate/Mid-Level              4             [4]   \n",
       "\n",
       "   similarity_results_0_90  similarity_results_0_93  similarity_results_0_95   \n",
       "0                       []                       []                       []  \\\n",
       "1                       []                       []                       []   \n",
       "2                       []                       []                       []   \n",
       "3                       []                       []                       []   \n",
       "4                       []                       []                       []   \n",
       "\n",
       "  similarity_results_0_97  \n",
       "0                      []  \n",
       "1                      []  \n",
       "2                      []  \n",
       "3                      []  \n",
       "4                      []  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge results to dataframe\n",
    "df = df.merge(similarity_results, left_index=True, right_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1468\n",
      "125\n",
      "94\n",
      "86\n",
      "69\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(sum(df[\"similarity_results_0_90\"].apply(lambda x: len(x)>0)))\n",
    "print(sum(df[\"similarity_results_0_93\"].apply(lambda x: len(x)>0)))\n",
    "print(sum(df[\"similarity_results_0_95\"].apply(lambda x: len(x)>0)))\n",
    "print(sum(df[\"similarity_results_0_97\"].apply(lambda x: len(x)>0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract merge group from tuple\n",
    "def get_last_merge_group(x: tuple) -> int:\n",
    "    if len(x) > 0: \n",
    "        return x[-1][-1]\n",
    "    return pd.NA\n",
    "\n",
    "df[\"similarity_results_0_90_mgroup\"] = df[\"similarity_results_0_90\"].apply(get_last_merge_group)\n",
    "df[\"similarity_results_0_93_mgroup\"] = df[\"similarity_results_0_93\"].apply(get_last_merge_group)\n",
    "df[\"similarity_results_0_95_mgroup\"] = df[\"similarity_results_0_95\"].apply(get_last_merge_group)\n",
    "df[\"similarity_results_0_97_mgroup\"] = df[\"similarity_results_0_97\"].apply(get_last_merge_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity_results_0_90</th>\n",
       "      <th>similarity_results_0_93</th>\n",
       "      <th>similarity_results_0_95</th>\n",
       "      <th>similarity_results_0_97</th>\n",
       "      <th>similarity_results_0_90_mgroup</th>\n",
       "      <th>similarity_results_0_93_mgroup</th>\n",
       "      <th>similarity_results_0_95_mgroup</th>\n",
       "      <th>similarity_results_0_97_mgroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>[(1228, 0.987, 0)]</td>\n",
       "      <td>[(1228, 0.987, 1)]</td>\n",
       "      <td>[(1228, 0.987, 2)]</td>\n",
       "      <td>[(1228, 0.987, 3)]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>[(256, 0.981, 4)]</td>\n",
       "      <td>[(256, 0.981, 5)]</td>\n",
       "      <td>[(256, 0.981, 6)]</td>\n",
       "      <td>[(256, 0.981, 7)]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>[(744, 0.919, 8), (1142, 0.979, 8)]</td>\n",
       "      <td>[(1142, 0.979, 9)]</td>\n",
       "      <td>[(1142, 0.979, 10)]</td>\n",
       "      <td>[(1142, 0.979, 11)]</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>[(247, 1.0, 12), (424, 1.0, 12)]</td>\n",
       "      <td>[(247, 1.0, 13), (424, 1.0, 13)]</td>\n",
       "      <td>[(247, 1.0, 14), (424, 1.0, 14)]</td>\n",
       "      <td>[(247, 1.0, 15), (424, 1.0, 15)]</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>[(1089, 0.976, 16)]</td>\n",
       "      <td>[(1089, 0.976, 17)]</td>\n",
       "      <td>[(1089, 0.976, 18)]</td>\n",
       "      <td>[(1089, 0.976, 19)]</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                similarity_results_0_90           similarity_results_0_93   \n",
       "57                   [(1228, 0.987, 0)]                [(1228, 0.987, 1)]  \\\n",
       "59                    [(256, 0.981, 4)]                 [(256, 0.981, 5)]   \n",
       "78  [(744, 0.919, 8), (1142, 0.979, 8)]                [(1142, 0.979, 9)]   \n",
       "82     [(247, 1.0, 12), (424, 1.0, 12)]  [(247, 1.0, 13), (424, 1.0, 13)]   \n",
       "86                  [(1089, 0.976, 16)]               [(1089, 0.976, 17)]   \n",
       "\n",
       "             similarity_results_0_95           similarity_results_0_97   \n",
       "57                [(1228, 0.987, 2)]                [(1228, 0.987, 3)]  \\\n",
       "59                 [(256, 0.981, 6)]                 [(256, 0.981, 7)]   \n",
       "78               [(1142, 0.979, 10)]               [(1142, 0.979, 11)]   \n",
       "82  [(247, 1.0, 14), (424, 1.0, 14)]  [(247, 1.0, 15), (424, 1.0, 15)]   \n",
       "86               [(1089, 0.976, 18)]               [(1089, 0.976, 19)]   \n",
       "\n",
       "   similarity_results_0_90_mgroup similarity_results_0_93_mgroup   \n",
       "57                              0                              1  \\\n",
       "59                              4                              5   \n",
       "78                              8                              9   \n",
       "82                             12                             13   \n",
       "86                             16                             17   \n",
       "\n",
       "   similarity_results_0_95_mgroup similarity_results_0_97_mgroup  \n",
       "57                              2                              3  \n",
       "59                              6                              7  \n",
       "78                             10                             11  \n",
       "82                             14                             15  \n",
       "86                             18                             19  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"similarity_results_0_97_mgroup\"].isna() == False].filter(like=\"similarity_\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform manual checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_excel(\"TEMP_CHECK_CUPLIKATES_SAME_LOC_SAME_SEN_ALL4_MGROUPS2.xlsx\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>090</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>093</th>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>095</th>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>097</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FP  TN  FN  TP\n",
       "090  26   0   0  99\n",
       "093   9  17  14  85\n",
       "095   7  19  18  81\n",
       "097   0  26  30  69"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Having checked the data in excel, the performance of each threshold can be expressed in a confusion matrix.\n",
    "#  (This is a very simplified approach, as listing were only swiftly checked.)\n",
    "confusion_matrix = pd.DataFrame(\n",
    "    {\"090\": {\"FP\": 26, \"TN\":  0, \"FN\":  0, \"TP\": 30+69},\n",
    "     \"093\": {\"FP\":  9, \"TN\": 17, \"FN\": 14, \"TP\": 16+69},\n",
    "     \"095\": {\"FP\":  7, \"TN\": 19, \"FN\": 18, \"TP\": 12+69},\n",
    "     \"097\": {\"FP\":  0, \"TN\": 26, \"FN\": 30, \"TP\":  0+69}},\n",
    ").T\n",
    "\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is of no surprise that the more conservative threshold (0.97) does not falsely detect any duplicates, while the lowest threshold yields the most duplicates in absolute values, but also flags a lot of listings as duplicate which are in fact not duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>n</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>090</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>125</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>093</th>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>85</td>\n",
       "      <td>125</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>095</th>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>81</td>\n",
       "      <td>125</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>097</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>69</td>\n",
       "      <td>125</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FP  TN  FN  TP    n  precision  recall    f1  accuracy  specificity\n",
       "090  26   0   0  99  125       0.79    1.00  0.88      0.79         0.00\n",
       "093   9  17  14  85  125       0.90    0.86  0.88      0.82         0.65\n",
       "095   7  19  18  81  125       0.92    0.82  0.87      0.80         0.73\n",
       "097   0  26  30  69  125       1.00    0.70  0.82      0.76         1.00"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copmute performance metrices based on data in confusion matrix\n",
    "confusion_matrix[\"n\"] = confusion_matrix.sum(axis=1)\n",
    "\n",
    "confusion_matrix[\"precision\"] = confusion_matrix[\"TP\"] / (confusion_matrix[\"TP\"] + confusion_matrix[\"FP\"])\n",
    "confusion_matrix[\"recall\"] = confusion_matrix[\"TP\"] / (confusion_matrix[\"TP\"] + confusion_matrix[\"FN\"])\n",
    "confusion_matrix[\"f1\"] = (2 * confusion_matrix[\"precision\"] * confusion_matrix[\"recall\"]) / (confusion_matrix[\"precision\"] + confusion_matrix[\"recall\"])\n",
    "confusion_matrix[\"accuracy\"] = (confusion_matrix[\"TP\"] + confusion_matrix[\"TN\"]) / (confusion_matrix[\"n\"])\n",
    "confusion_matrix[\"specificity\"] = confusion_matrix[\"TN\"] / (confusion_matrix[\"TN\"] + confusion_matrix[\"FP\"])\n",
    "\n",
    "confusion_matrix.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach is not perfect. There are listings being flagged as duplicates albeit differing slightly in job title or job description. \n",
    "E.g. there are listings that have similarity scores of 1.0 but different job titles: Data Scientist/Data Analyst/Data Engineer. \n",
    "\n",
    "Some listings that are surely identical show similarity scores of only 0.93, potentially due to \"noise\" in the description originating from e.g. headlines provided on the different job platforms.\n",
    "\n",
    "With a threshold of 0.97, the comparison is therefore perhaps too strict. A threshold of 0.90 does however result in some listings beeing incorrectly flagged as duplicates.\n",
    "\n",
    "In this case, the individual datapoints are pretty valuable. The error of dropping unique job postings that might potentially be _the_ position for an applicant outweighs keeping 2 identical postings that ultimately would only marginally affect the percentage values of job statistics displayed.\n",
    "\n",
    "Hence, the most conservative threshold of 0.97 will be selected, which most reliably guarantees not dropping unique postings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. rows pre splitting: 1468\n",
      "No. rows in duplicates df: 69\n",
      "No. rows in non-duplicates df: 1399\n"
     ]
    }
   ],
   "source": [
    "# split df into rows without any flags, and those being flagged as duplicates.\n",
    "print(f\"No. rows pre splitting: {len(df)}\")\n",
    "df_duplicates = df[df[\"similarity_results_0_97_mgroup\"].isna() == False].copy()\n",
    "print(f\"No. rows in duplicates df: {len(df_duplicates)}\")\n",
    "df_no_duplicates = df[df[\"similarity_results_0_97_mgroup\"].isna()].copy()\n",
    "print(f\"No. rows in non-duplicates df: {len(df_no_duplicates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>date_accessed</th>\n",
       "      <th>days_online</th>\n",
       "      <th>number_applicants</th>\n",
       "      <th>job_type_Vollzeit</th>\n",
       "      <th>...</th>\n",
       "      <th>index_pre_agg</th>\n",
       "      <th>index_agg_list</th>\n",
       "      <th>similarity_results_0_90</th>\n",
       "      <th>similarity_results_0_93</th>\n",
       "      <th>similarity_results_0_95</th>\n",
       "      <th>similarity_results_0_97</th>\n",
       "      <th>similarity_results_0_90_mgroup</th>\n",
       "      <th>similarity_results_0_93_mgroup</th>\n",
       "      <th>similarity_results_0_95_mgroup</th>\n",
       "      <th>similarity_results_0_97_mgroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>Senior Scientist Machine Learning – Risikomode...</td>\n",
       "      <td>HUK-COBURG Versicherungsgruppe</td>\n",
       "      <td>Coburg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-12-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1014</td>\n",
       "      <td>[1014]</td>\n",
       "      <td>[(421, 0.903, 94), (571, 0.912, 94), (987, 0.9...</td>\n",
       "      <td>[(987, 0.983, 146), (1050, 0.99, 146)]</td>\n",
       "      <td>[(987, 0.983, 147), (1050, 0.99, 147)]</td>\n",
       "      <td>[(987, 0.983, 148), (1050, 0.99, 148)]</td>\n",
       "      <td>94</td>\n",
       "      <td>146</td>\n",
       "      <td>147</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>Senior Scientist Machine Learning – Causal Mac...</td>\n",
       "      <td>HUK-COBURG Versicherungsgruppe</td>\n",
       "      <td>Coburg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-12-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1050</td>\n",
       "      <td>[1050]</td>\n",
       "      <td>[(421, 0.912, 94), (571, 0.903, 94), (987, 0.9...</td>\n",
       "      <td>[(987, 0.982, 146), (1014, 0.99, 146)]</td>\n",
       "      <td>[(987, 0.982, 147), (1014, 0.99, 147)]</td>\n",
       "      <td>[(987, 0.982, 148), (1014, 0.99, 148)]</td>\n",
       "      <td>94</td>\n",
       "      <td>146</td>\n",
       "      <td>147</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>Data Analytics Consultant (m/w/d)</td>\n",
       "      <td>rheindata GmbH</td>\n",
       "      <td>Köln</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>2024-12-13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1596</td>\n",
       "      <td>[1596]</td>\n",
       "      <td>[(1597, 1.0, 167)]</td>\n",
       "      <td>[(1597, 1.0, 168)]</td>\n",
       "      <td>[(1597, 1.0, 169)]</td>\n",
       "      <td>[(1597, 1.0, 170)]</td>\n",
       "      <td>167</td>\n",
       "      <td>168</td>\n",
       "      <td>169</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>Data Analytics Consultant Frontend (m/w/d)</td>\n",
       "      <td>rheindata GmbH</td>\n",
       "      <td>Köln</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>2024-12-13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1597</td>\n",
       "      <td>[1597]</td>\n",
       "      <td>[(1596, 1.0, 167)]</td>\n",
       "      <td>[(1596, 1.0, 168)]</td>\n",
       "      <td>[(1596, 1.0, 169)]</td>\n",
       "      <td>[(1596, 1.0, 170)]</td>\n",
       "      <td>167</td>\n",
       "      <td>168</td>\n",
       "      <td>169</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>Principal, Same Day, Long-term planning</td>\n",
       "      <td>Amazon Europe Core</td>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-12-12</td>\n",
       "      <td>2024-12-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1611</td>\n",
       "      <td>[1611]</td>\n",
       "      <td>[(1612, 0.988, 171)]</td>\n",
       "      <td>[(1612, 0.988, 172)]</td>\n",
       "      <td>[(1612, 0.988, 173)]</td>\n",
       "      <td>[(1612, 0.988, 174)]</td>\n",
       "      <td>171</td>\n",
       "      <td>172</td>\n",
       "      <td>173</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>Principal, Same Day Long-Term Planning</td>\n",
       "      <td>Amazon Europe Core</td>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-12-12</td>\n",
       "      <td>2024-12-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1612</td>\n",
       "      <td>[1612]</td>\n",
       "      <td>[(1611, 0.988, 171)]</td>\n",
       "      <td>[(1611, 0.988, 172)]</td>\n",
       "      <td>[(1611, 0.988, 173)]</td>\n",
       "      <td>[(1611, 0.988, 174)]</td>\n",
       "      <td>171</td>\n",
       "      <td>172</td>\n",
       "      <td>173</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title   \n",
       "1014  Senior Scientist Machine Learning – Risikomode...  \\\n",
       "1050  Senior Scientist Machine Learning – Causal Mac...   \n",
       "1596                  Data Analytics Consultant (m/w/d)   \n",
       "1597         Data Analytics Consultant Frontend (m/w/d)   \n",
       "1611            Principal, Same Day, Long-term planning   \n",
       "1612             Principal, Same Day Long-Term Planning   \n",
       "\n",
       "                             company    location salary seniority_level   \n",
       "1014  HUK-COBURG Versicherungsgruppe      Coburg   None            None  \\\n",
       "1050  HUK-COBURG Versicherungsgruppe      Coburg   None            None   \n",
       "1596                  rheindata GmbH        Köln   None            None   \n",
       "1597                  rheindata GmbH        Köln   None            None   \n",
       "1611              Amazon Europe Core  Luxembourg   None            None   \n",
       "1612              Amazon Europe Core  Luxembourg   None            None   \n",
       "\n",
       "     date_posted date_accessed  days_online  number_applicants   \n",
       "1014        None    2024-12-12          NaN                NaN  \\\n",
       "1050        None    2024-12-12          NaN                NaN   \n",
       "1596  2024-12-05    2024-12-13          8.0                NaN   \n",
       "1597  2024-12-05    2024-12-13          8.0                NaN   \n",
       "1611  2024-12-12    2024-12-13          1.0                NaN   \n",
       "1612  2024-12-12    2024-12-13          1.0                NaN   \n",
       "\n",
       "      job_type_Vollzeit  ...  index_pre_agg  index_agg_list   \n",
       "1014                  1  ...           1014          [1014]  \\\n",
       "1050                  1  ...           1050          [1050]   \n",
       "1596                  1  ...           1596          [1596]   \n",
       "1597                  1  ...           1597          [1597]   \n",
       "1611                  1  ...           1611          [1611]   \n",
       "1612                  1  ...           1612          [1612]   \n",
       "\n",
       "                                similarity_results_0_90   \n",
       "1014  [(421, 0.903, 94), (571, 0.912, 94), (987, 0.9...  \\\n",
       "1050  [(421, 0.912, 94), (571, 0.903, 94), (987, 0.9...   \n",
       "1596                                 [(1597, 1.0, 167)]   \n",
       "1597                                 [(1596, 1.0, 167)]   \n",
       "1611                               [(1612, 0.988, 171)]   \n",
       "1612                               [(1611, 0.988, 171)]   \n",
       "\n",
       "                     similarity_results_0_93   \n",
       "1014  [(987, 0.983, 146), (1050, 0.99, 146)]  \\\n",
       "1050  [(987, 0.982, 146), (1014, 0.99, 146)]   \n",
       "1596                      [(1597, 1.0, 168)]   \n",
       "1597                      [(1596, 1.0, 168)]   \n",
       "1611                    [(1612, 0.988, 172)]   \n",
       "1612                    [(1611, 0.988, 172)]   \n",
       "\n",
       "                     similarity_results_0_95   \n",
       "1014  [(987, 0.983, 147), (1050, 0.99, 147)]  \\\n",
       "1050  [(987, 0.982, 147), (1014, 0.99, 147)]   \n",
       "1596                      [(1597, 1.0, 169)]   \n",
       "1597                      [(1596, 1.0, 169)]   \n",
       "1611                    [(1612, 0.988, 173)]   \n",
       "1612                    [(1611, 0.988, 173)]   \n",
       "\n",
       "                     similarity_results_0_97  similarity_results_0_90_mgroup   \n",
       "1014  [(987, 0.983, 148), (1050, 0.99, 148)]                              94  \\\n",
       "1050  [(987, 0.982, 148), (1014, 0.99, 148)]                              94   \n",
       "1596                      [(1597, 1.0, 170)]                             167   \n",
       "1597                      [(1596, 1.0, 170)]                             167   \n",
       "1611                    [(1612, 0.988, 174)]                             171   \n",
       "1612                    [(1611, 0.988, 174)]                             171   \n",
       "\n",
       "      similarity_results_0_93_mgroup  similarity_results_0_95_mgroup   \n",
       "1014                             146                             147  \\\n",
       "1050                             146                             147   \n",
       "1596                             168                             169   \n",
       "1597                             168                             169   \n",
       "1611                             172                             173   \n",
       "1612                             172                             173   \n",
       "\n",
       "     similarity_results_0_97_mgroup  \n",
       "1014                            148  \n",
       "1050                            148  \n",
       "1596                            170  \n",
       "1597                            170  \n",
       "1611                            174  \n",
       "1612                            174  \n",
       "\n",
       "[6 rows x 37 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_duplicates.sort_values(by=\"similarity_results_0_97_mgroup\").tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'first',\n",
       " 'company': 'first',\n",
       " 'location': 'first',\n",
       " 'salary': 'first',\n",
       " 'seniority_level': 'first',\n",
       " 'date_posted': 'first',\n",
       " 'date_accessed': 'first',\n",
       " 'days_online': 'max',\n",
       " 'number_applicants': 'max',\n",
       " 'job_type_Vollzeit': 'max',\n",
       " 'job_type_Teilzeit': 'max',\n",
       " 'job_type_Festanstellung': 'max',\n",
       " 'job_type_BefristeterVertrag': 'max',\n",
       " 'job_type_Homeoffice': 'max',\n",
       " 'job_type_FreieMitarbeit': 'max',\n",
       " 'job_type_Traineeprogramm': 'max',\n",
       " 'job_type_Berufsausbildung': 'max',\n",
       " 'job_type_Praktikum': 'max',\n",
       " 'job_type_Werkstudent': 'max',\n",
       " 'job_description_anonymized': 'first',\n",
       " 'source_id': <function sum(iterable, /, start=0)>,\n",
       " 'location_clean': 'first',\n",
       " 'company_clean_ish': 'first',\n",
       " 'company_clean': 'first',\n",
       " 'title_clean': 'first',\n",
       " 'seniority_level_new': 'first',\n",
       " 'seniority_level_5': 'first',\n",
       " 'index_pre_agg': <function min>,\n",
       " 'index_agg_list': <function sum(iterable, /, start=0)>,\n",
       " 'similarity_results_0_90': 'first',\n",
       " 'similarity_results_0_93': 'first',\n",
       " 'similarity_results_0_95': 'first',\n",
       " 'similarity_results_0_97': 'first',\n",
       " 'similarity_results_0_90_mgroup': 'first',\n",
       " 'similarity_results_0_93_mgroup': 'first',\n",
       " 'similarity_results_0_95_mgroup': 'first',\n",
       " 'similarity_results_0_97_mgroup': 'first'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep all original columns. Use similar aggregation functions as before.\n",
    "group_by_columns = [\"similarity_results_0_97_mgroup\"]\n",
    "\n",
    "# set aggregation to max for numeric values (except index), \n",
    "# and first for object types (except source, which will be concatenated)\n",
    "aggregation_functions = {col: \"first\" if df_duplicates[col].dtype == \"O\" else \"max\" for col in df_duplicates.columns}\n",
    "\n",
    "aggregation_functions.update(index_pre_agg = min)\n",
    "aggregation_functions.update(index_agg_list = sum)\n",
    "aggregation_functions.update(source_id = sum)\n",
    "\n",
    "aggregation_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows before aggregation: 69\n",
      "number of rows after aggregation: 33 (dif: 36)\n"
     ]
    }
   ],
   "source": [
    "df_len_pre = len(df_duplicates)\n",
    "print(\"number of rows before aggregation:\", df_len_pre)\n",
    "\n",
    "# Aggregate; Restore original index and order\n",
    "df_duplicates = df_duplicates.groupby(group_by_columns, as_index=False) \\\n",
    "    .agg(aggregation_functions).reset_index(drop=True)\n",
    "df_duplicates.index = df_duplicates[\"index_pre_agg\"].to_list()\n",
    "df_duplicates = df_duplicates.sort_index()\n",
    "\n",
    "print(f\"number of rows after aggregation: {len(df_duplicates)} (dif: {df_len_pre - len(df_duplicates)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>date_accessed</th>\n",
       "      <th>days_online</th>\n",
       "      <th>number_applicants</th>\n",
       "      <th>job_type_Vollzeit</th>\n",
       "      <th>...</th>\n",
       "      <th>index_pre_agg</th>\n",
       "      <th>index_agg_list</th>\n",
       "      <th>similarity_results_0_90</th>\n",
       "      <th>similarity_results_0_93</th>\n",
       "      <th>similarity_results_0_95</th>\n",
       "      <th>similarity_results_0_97</th>\n",
       "      <th>similarity_results_0_90_mgroup</th>\n",
       "      <th>similarity_results_0_93_mgroup</th>\n",
       "      <th>similarity_results_0_95_mgroup</th>\n",
       "      <th>similarity_results_0_97_mgroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Applied Scientist, Amazon Nova</td>\n",
       "      <td>Amazon Development Center Germany GmbH</td>\n",
       "      <td>Aachen</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-12-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>798</td>\n",
       "      <td>[798, 924]</td>\n",
       "      <td>[(924, 1.0, 131)]</td>\n",
       "      <td>[(924, 1.0, 132)]</td>\n",
       "      <td>[(924, 1.0, 133)]</td>\n",
       "      <td>[(924, 1.0, 134)]</td>\n",
       "      <td>131</td>\n",
       "      <td>132</td>\n",
       "      <td>133</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>(Senior) Data Scientist (m/w/d) – Schwerpunkt ...</td>\n",
       "      <td>Ausbildung.de</td>\n",
       "      <td>Bochum</td>\n",
       "      <td>55.000 € – 80.000 € pro Jahr</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-12-11</td>\n",
       "      <td>2024-12-12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>957</td>\n",
       "      <td>[957, 1314, 1171]</td>\n",
       "      <td>[(1171, 0.974, 142)]</td>\n",
       "      <td>[(1171, 0.974, 143)]</td>\n",
       "      <td>[(1171, 0.974, 144)]</td>\n",
       "      <td>[(1171, 0.974, 145)]</td>\n",
       "      <td>142</td>\n",
       "      <td>143</td>\n",
       "      <td>144</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>Senior Scientist Machine Learning / Deep Learn...</td>\n",
       "      <td>HUK-COBURG Versicherungsgruppe</td>\n",
       "      <td>Coburg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-12-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>987</td>\n",
       "      <td>[987, 1014, 1050]</td>\n",
       "      <td>[(1014, 0.983, 94), (1050, 0.982, 94)]</td>\n",
       "      <td>[(1014, 0.983, 146), (1050, 0.982, 146)]</td>\n",
       "      <td>[(1014, 0.983, 147), (1050, 0.982, 147)]</td>\n",
       "      <td>[(1014, 0.983, 148), (1050, 0.982, 148)]</td>\n",
       "      <td>94</td>\n",
       "      <td>146</td>\n",
       "      <td>147</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>Data Analytics Consultant (m/w/d)</td>\n",
       "      <td>rheindata GmbH</td>\n",
       "      <td>Köln</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>2024-12-13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1596</td>\n",
       "      <td>[1596, 1597]</td>\n",
       "      <td>[(1597, 1.0, 167)]</td>\n",
       "      <td>[(1597, 1.0, 168)]</td>\n",
       "      <td>[(1597, 1.0, 169)]</td>\n",
       "      <td>[(1597, 1.0, 170)]</td>\n",
       "      <td>167</td>\n",
       "      <td>168</td>\n",
       "      <td>169</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>Principal, Same Day, Long-term planning</td>\n",
       "      <td>Amazon Europe Core</td>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-12-12</td>\n",
       "      <td>2024-12-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1611</td>\n",
       "      <td>[1611, 1612]</td>\n",
       "      <td>[(1612, 0.988, 171)]</td>\n",
       "      <td>[(1612, 0.988, 172)]</td>\n",
       "      <td>[(1612, 0.988, 173)]</td>\n",
       "      <td>[(1612, 0.988, 174)]</td>\n",
       "      <td>171</td>\n",
       "      <td>172</td>\n",
       "      <td>173</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title   \n",
       "798                      Applied Scientist, Amazon Nova  \\\n",
       "957   (Senior) Data Scientist (m/w/d) – Schwerpunkt ...   \n",
       "987   Senior Scientist Machine Learning / Deep Learn...   \n",
       "1596                  Data Analytics Consultant (m/w/d)   \n",
       "1611            Principal, Same Day, Long-term planning   \n",
       "\n",
       "                                     company    location   \n",
       "798   Amazon Development Center Germany GmbH      Aachen  \\\n",
       "957                            Ausbildung.de      Bochum   \n",
       "987           HUK-COBURG Versicherungsgruppe      Coburg   \n",
       "1596                          rheindata GmbH        Köln   \n",
       "1611                      Amazon Europe Core  Luxembourg   \n",
       "\n",
       "                            salary seniority_level date_posted date_accessed   \n",
       "798                           None            None        None    2024-12-12  \\\n",
       "957   55.000 € – 80.000 € pro Jahr            None  2024-12-11    2024-12-12   \n",
       "987                           None            None        None    2024-12-12   \n",
       "1596                          None            None  2024-12-05    2024-12-13   \n",
       "1611                          None            None  2024-12-12    2024-12-13   \n",
       "\n",
       "      days_online  number_applicants  job_type_Vollzeit  ...  index_pre_agg   \n",
       "798           NaN                NaN                  1  ...            798  \\\n",
       "957           2.0                NaN                  1  ...            957   \n",
       "987           NaN                NaN                  1  ...            987   \n",
       "1596          8.0                NaN                  1  ...           1596   \n",
       "1611          1.0                NaN                  1  ...           1611   \n",
       "\n",
       "         index_agg_list                 similarity_results_0_90   \n",
       "798          [798, 924]                       [(924, 1.0, 131)]  \\\n",
       "957   [957, 1314, 1171]                    [(1171, 0.974, 142)]   \n",
       "987   [987, 1014, 1050]  [(1014, 0.983, 94), (1050, 0.982, 94)]   \n",
       "1596       [1596, 1597]                      [(1597, 1.0, 167)]   \n",
       "1611       [1611, 1612]                    [(1612, 0.988, 171)]   \n",
       "\n",
       "                       similarity_results_0_93   \n",
       "798                          [(924, 1.0, 132)]  \\\n",
       "957                       [(1171, 0.974, 143)]   \n",
       "987   [(1014, 0.983, 146), (1050, 0.982, 146)]   \n",
       "1596                        [(1597, 1.0, 168)]   \n",
       "1611                      [(1612, 0.988, 172)]   \n",
       "\n",
       "                       similarity_results_0_95   \n",
       "798                          [(924, 1.0, 133)]  \\\n",
       "957                       [(1171, 0.974, 144)]   \n",
       "987   [(1014, 0.983, 147), (1050, 0.982, 147)]   \n",
       "1596                        [(1597, 1.0, 169)]   \n",
       "1611                      [(1612, 0.988, 173)]   \n",
       "\n",
       "                       similarity_results_0_97   \n",
       "798                          [(924, 1.0, 134)]  \\\n",
       "957                       [(1171, 0.974, 145)]   \n",
       "987   [(1014, 0.983, 148), (1050, 0.982, 148)]   \n",
       "1596                        [(1597, 1.0, 170)]   \n",
       "1611                      [(1612, 0.988, 174)]   \n",
       "\n",
       "      similarity_results_0_90_mgroup  similarity_results_0_93_mgroup   \n",
       "798                              131                             132  \\\n",
       "957                              142                             143   \n",
       "987                               94                             146   \n",
       "1596                             167                             168   \n",
       "1611                             171                             172   \n",
       "\n",
       "      similarity_results_0_95_mgroup similarity_results_0_97_mgroup  \n",
       "798                              133                            134  \n",
       "957                              144                            145  \n",
       "987                              147                            148  \n",
       "1596                             169                            170  \n",
       "1611                             173                            174  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_duplicates.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1468\n",
      "1432\n"
     ]
    }
   ],
   "source": [
    "# Merge aggregated df_duplicate with df again\n",
    "print(len(df))\n",
    "df = pd.concat([df_no_duplicates, df_duplicates])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>date_accessed</th>\n",
       "      <th>days_online</th>\n",
       "      <th>number_applicants</th>\n",
       "      <th>job_type_Vollzeit</th>\n",
       "      <th>...</th>\n",
       "      <th>index_pre_agg</th>\n",
       "      <th>index_agg_list</th>\n",
       "      <th>similarity_results_0_90</th>\n",
       "      <th>similarity_results_0_93</th>\n",
       "      <th>similarity_results_0_95</th>\n",
       "      <th>similarity_results_0_97</th>\n",
       "      <th>similarity_results_0_90_mgroup</th>\n",
       "      <th>similarity_results_0_93_mgroup</th>\n",
       "      <th>similarity_results_0_95_mgroup</th>\n",
       "      <th>similarity_results_0_97_mgroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Graduate</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>None</td>\n",
       "      <td>Associate</td>\n",
       "      <td>2024-11-22</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>17.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Xsolla</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>None</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>9.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1183]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Global Market Solutions - Germany</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>None</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>26.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 19]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>MeloTech</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>None</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>313.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>[3, 1105]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist (f/m/d)</td>\n",
       "      <td>vent.io</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>None</td>\n",
       "      <td>Associate</td>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>19.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title                            company   \n",
       "0   Data Science Graduate                               Visa  \\\n",
       "1   Junior Data Scientist                             Xsolla   \n",
       "2          Data Scientist  Global Market Solutions - Germany   \n",
       "3   Data Scientist Intern                           MeloTech   \n",
       "4  Data Scientist (f/m/d)                            vent.io   \n",
       "\n",
       "            location salary   seniority_level date_posted date_accessed   \n",
       "0             Berlin   None         Associate  2024-11-22    2024-12-09  \\\n",
       "1             Berlin   None       Entry level  2024-11-30    2024-12-09   \n",
       "2  Frankfurt am Main   None  Mid-Senior level  2024-11-13    2024-12-09   \n",
       "3             Berlin   None       Entry level  2024-01-31    2024-12-09   \n",
       "4  Frankfurt am Main   None         Associate  2024-11-20    2024-12-09   \n",
       "\n",
       "   days_online  number_applicants  job_type_Vollzeit  ...  index_pre_agg   \n",
       "0         17.0              200.0                  1  ...              0  \\\n",
       "1          9.0              200.0                  1  ...              1   \n",
       "2         26.0              200.0                  1  ...              2   \n",
       "3        313.0              200.0                  1  ...              3   \n",
       "4         19.0              200.0                  1  ...              4   \n",
       "\n",
       "   index_agg_list  similarity_results_0_90  similarity_results_0_93   \n",
       "0             [0]                       []                       []  \\\n",
       "1       [1, 1183]                       []                       []   \n",
       "2         [2, 19]                       []                       []   \n",
       "3       [3, 1105]                       []                       []   \n",
       "4             [4]                       []                       []   \n",
       "\n",
       "   similarity_results_0_95  similarity_results_0_97   \n",
       "0                       []                       []  \\\n",
       "1                       []                       []   \n",
       "2                       []                       []   \n",
       "3                       []                       []   \n",
       "4                       []                       []   \n",
       "\n",
       "   similarity_results_0_90_mgroup  similarity_results_0_93_mgroup   \n",
       "0                            <NA>                            <NA>  \\\n",
       "1                            <NA>                            <NA>   \n",
       "2                            <NA>                            <NA>   \n",
       "3                            <NA>                            <NA>   \n",
       "4                            <NA>                            <NA>   \n",
       "\n",
       "   similarity_results_0_95_mgroup similarity_results_0_97_mgroup  \n",
       "0                            <NA>                           <NA>  \n",
       "1                            <NA>                           <NA>  \n",
       "2                            <NA>                           <NA>  \n",
       "3                            <NA>                           <NA>  \n",
       "4                            <NA>                           <NA>  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up source column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_id\n",
       "[1]          640\n",
       "[2]          319\n",
       "[3]          302\n",
       "[1, 2]        84\n",
       "[2, 3]        28\n",
       "[1, 1]        21\n",
       "[2, 2]        14\n",
       "[1, 3]        11\n",
       "[1, 2, 3]      4\n",
       "[1, 2, 2]      2\n",
       "[3, 3]         2\n",
       "[2, 2, 3]      1\n",
       "[1, 1, 1]      1\n",
       "[1, 1, 2]      1\n",
       "[2, 3, 2]      1\n",
       "[2, 2, 2]      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"source_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_id\n",
       "1          662\n",
       "2          334\n",
       "3          304\n",
       "1, 2        87\n",
       "2, 3        30\n",
       "1, 3        11\n",
       "1, 2, 3      4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"source_id\"] = df[\"source_id\"].apply(lambda x: \", \".join(map(str, set(x))))\n",
    "\n",
    "df[\"source_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Titles 2 - Categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use ChatGPT to categorize job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_clean\n",
       "Data Scientist                             85\n",
       "Senior Data Scientist                      44\n",
       "Data Analyst                               21\n",
       "Data Engineer                              21\n",
       "Machine Learning Engineer                  15\n",
       "                                           ..\n",
       "Data Engineer / Analyst                     1\n",
       "Head of / VP - Data Experience              1\n",
       "Trainee Analytics Engineer                  1\n",
       "Business Intelligence Workshop              1\n",
       "Principal, Same Day, Long-term planning     1\n",
       "Name: count, Length: 1062, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export pre-cleaned job title column where gender-specifications (e.g. \"m/w/d\") were removed.\n",
    "# This reduces redundant characters in the strings and potentially eases the categorization.\n",
    "df[\"title_clean\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = pd.Series(df[\"title_clean\"].unique(), name=\"job_titles\")\n",
    "#job_titles.to_csv(\"_ChatGPT/job_titles.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatGPT prompt: \n",
    "\"I will attach a csv file with around 1000 job titles associated with data focused work in the first column. \n",
    "I would like you to categorize these into 10 categories including a category \"other\", and store these in the second column of the attached csv file.\"\n",
    "\n",
    "**Response:**\n",
    "\n",
    "Understood! Please attach the CSV file, and I will process it for you. I’ll analyze the job titles, assign one of 10 categories to each (including \"Other\" for ambiguous or uncategorizable titles), and update the second column with the assigned category.\n",
    "The uploaded file contains a single column labeled **\"job_titles\"** with job titles related to data-focused work. I’ll proceed by categorizing these titles into 10 categories, including an \"Other\" category for uncategorizable titles. Here’s how I’ll organize it:\n",
    "\n",
    "Tentative Categories:\n",
    "- Data Scientist\n",
    "- Data Analyst\n",
    "- Machine Learning Engineer\n",
    "- Data Engineer\n",
    "- Business Intelligence (BI)\n",
    "- Research Scientist\n",
    "- Statistician\n",
    "- AI/ML Specialist\n",
    "- Data Consultant\n",
    "- Other\n",
    "\n",
    "Let me categorize them now. ​​\n",
    "\n",
    "The job titles have been categorized, and a new \"Category\" column has been added to the DataFrame. For example:\n",
    "- Junior Data Scientist → Data Scientist\n",
    "- Applied Scientist, Fintech (Fraud) → Other\n",
    "\n",
    "I’ll now save the updated CSV file with these categories. ​​\n",
    "\n",
    "The categorized job titles have been saved. You can download the updated file using the link below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles_with_categories = pd.read_csv(\"_ChatGPT/job_titles_with_categories.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Graduate</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Applied Scientist, Fintech (Fraud)</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           job_titles        Category\n",
       "0               Data Science Graduate           Other\n",
       "1               Junior Data Scientist  Data Scientist\n",
       "2                      Data Scientist  Data Scientist\n",
       "3               Data Scientist Intern  Data Scientist\n",
       "4  Applied Scientist, Fintech (Fraud)           Other"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore provided results\n",
    "job_titles_with_categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "Other                         342\n",
       "Data Scientist                200\n",
       "Data Engineer                 145\n",
       "Data Analyst                  128\n",
       "AI/ML Specialist               72\n",
       "Machine Learning Engineer      69\n",
       "Research Scientist             47\n",
       "Data Consultant                35\n",
       "Business Intelligence (BI)     24\n",
       "Statistician                    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles_with_categories[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect ChatGPT's analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Graduate</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Applied Scientist, Fintech (Fraud)</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           job_titles        Category\n",
       "0               Data Science Graduate           Other\n",
       "1               Junior Data Scientist  Data Scientist\n",
       "2                      Data Scientist  Data Scientist\n",
       "3               Data Scientist Intern  Data Scientist\n",
       "4  Applied Scientist, Fintech (Fraud)           Other"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the uploaded CSV file\n",
    "#job_titles_df = pd.read_csv(file_path)\n",
    "job_titles_df = pd.DataFrame(job_titles)\n",
    "\n",
    "# Define a function to categorize job titles\n",
    "def categorize_job_title(title):\n",
    "    title_lower = title.lower()\n",
    "    \n",
    "    if \"data scientist\" in title_lower:\n",
    "        return \"Data Scientist\"\n",
    "    elif \"analyst\" in title_lower:\n",
    "        return \"Data Analyst\"\n",
    "    elif \"machine learning\" in title_lower or \"ml engineer\" in title_lower:\n",
    "        return \"Machine Learning Engineer\"\n",
    "    elif \"data engineer\" in title_lower or \"engineer\" in title_lower:\n",
    "        return \"Data Engineer\"\n",
    "    elif \"business intelligence\" in title_lower or \"bi \" in title_lower:\n",
    "        return \"Business Intelligence (BI)\"\n",
    "    elif \"research scientist\" in title_lower or \"research\" in title_lower:\n",
    "        return \"Research Scientist\"\n",
    "    elif \"statistician\" in title_lower or \"statistics\" in title_lower:\n",
    "        return \"Statistician\"\n",
    "    elif \"ai\" in title_lower or \"artificial intelligence\" in title_lower:\n",
    "        return \"AI/ML Specialist\"\n",
    "    elif \"consultant\" in title_lower:\n",
    "        return \"Data Consultant\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "# Apply the categorization function to the job titles\n",
    "job_titles_df['Category'] = job_titles_df['job_titles'].apply(categorize_job_title)\n",
    "job_titles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply function to existing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use function to add new column to existing data frame\n",
    "df[\"title_short_ChatGPT\"] = df[\"title_clean\"].apply(categorize_job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>title_short_ChatGPT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Graduate</td>\n",
       "      <td>Data Science Graduate</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist (f/m/d)</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title            title_clean title_short_ChatGPT\n",
       "0   Data Science Graduate  Data Science Graduate               Other\n",
       "1   Junior Data Scientist  Junior Data Scientist      Data Scientist\n",
       "2          Data Scientist         Data Scientist      Data Scientist\n",
       "3   Data Scientist Intern  Data Scientist Intern      Data Scientist\n",
       "4  Data Scientist (f/m/d)         Data Scientist      Data Scientist"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(like=\"title\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_short_ChatGPT\n",
       "Data Scientist                394\n",
       "Other                         369\n",
       "Data Engineer                 205\n",
       "Data Analyst                  161\n",
       "Machine Learning Engineer      93\n",
       "AI/ML Specialist               84\n",
       "Research Scientist             50\n",
       "Data Consultant                50\n",
       "Business Intelligence (BI)     25\n",
       "Statistician                    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"title_short_ChatGPT\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-Tuning 1:\n",
    "\n",
    "Can you update your code such that e.g. \"Data Science Intern\" will also be categorized as \"Data Scientist\"? And can you please refine the condition for \"data analyst\", since \"analyst\" alone will also trigger e.g. \"Business Analyst\".\n",
    "\n",
    "**Response:**\n",
    "\n",
    "Got it! I'll refine the code to ensure more accurate categorization. Here's what I'll adjust:\n",
    "\n",
    "1. \"Data Science Intern\" and similar titles will be categorized as \"Data Scientist.\"\n",
    "2. Refined categorization for \"Data Analyst\":\n",
    "- Only match titles that explicitly mention \"Data Analyst\" instead of just \"analyst\" (to avoid misclassifications like \"Business Analyst\").\n",
    "\n",
    "Let me implement these refinements now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine the categorization function\n",
    "def refined_categorize_job_title(title):\n",
    "    title_lower = title.lower()\n",
    "    \n",
    "    if \"data scientist\" in title_lower or \"data science\" in title_lower:\n",
    "        return \"Data Scientist\"\n",
    "    elif \"data analyst\" in title_lower:\n",
    "        return \"Data Analyst\"\n",
    "    elif \"machine learning\" in title_lower or \"ml engineer\" in title_lower:\n",
    "        return \"Machine Learning Engineer\"\n",
    "    elif \"data engineer\" in title_lower:\n",
    "        return \"Data Engineer\"\n",
    "    elif \"business intelligence\" in title_lower or \"bi \" in title_lower:\n",
    "        return \"Business Intelligence (BI)\"\n",
    "    elif \"research scientist\" in title_lower or \"research\" in title_lower:\n",
    "        return \"Research Scientist\"\n",
    "    elif \"statistician\" in title_lower or \"statistics\" in title_lower:\n",
    "        return \"Statistician\"\n",
    "    elif \"ai\" in title_lower or \"artificial intelligence\" in title_lower:\n",
    "        return \"AI/ML Specialist\"\n",
    "    elif \"consultant\" in title_lower:\n",
    "        return \"Data Consultant\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "# Apply the refined categorization function to the job titles\n",
    "# updated_job_titles_df['Category'] = updated_job_titles_df['job_titles'].apply(refined_categorize_job_title)\n",
    "\n",
    "# Preview the updated DataFrame with refined categories\n",
    "# updated_job_titles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_short_ChatGPT2\"] = df[\"title_clean\"].apply(refined_categorize_job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>title_short_ChatGPT</th>\n",
       "      <th>title_short_ChatGPT2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Graduate</td>\n",
       "      <td>Data Science Graduate</td>\n",
       "      <td>Other</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Other</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AI&amp;Business Analyst / Consultant (Remote Inter...</td>\n",
       "      <td>AI&amp;Business Analyst / Consultant (Remote Inter...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AI Engineer (Intern)</td>\n",
       "      <td>AI Engineer (Intern)</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>Solutions Engineer</td>\n",
       "      <td>Solutions Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Bachelor of Science (m/w/d) Data Science und K...</td>\n",
       "      <td>Bachelor of Science  Data Science und Künstlic...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Research Associate for the Project “DASHH - Da...</td>\n",
       "      <td>Research Associate for the Project “DASHH - Da...</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Senior Software Engineer (Python)</td>\n",
       "      <td>Senior Software Engineer (Python)</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Praktikum: Data Science (w/m/d)</td>\n",
       "      <td>Praktikum: Data Science</td>\n",
       "      <td>Other</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title   \n",
       "0                                 Data Science Graduate  \\\n",
       "9                                           AI Engineer   \n",
       "13                                  Data Science Intern   \n",
       "24    AI&Business Analyst / Consultant (Remote Inter...   \n",
       "27                                 AI Engineer (Intern)   \n",
       "...                                                 ...   \n",
       "1613                                 Solutions Engineer   \n",
       "120   Bachelor of Science (m/w/d) Data Science und K...   \n",
       "213   Research Associate for the Project “DASHH - Da...   \n",
       "250                   Senior Software Engineer (Python)   \n",
       "293                     Praktikum: Data Science (w/m/d)   \n",
       "\n",
       "                                            title_clean title_short_ChatGPT   \n",
       "0                                 Data Science Graduate               Other  \\\n",
       "9                                           AI Engineer       Data Engineer   \n",
       "13                                  Data Science Intern               Other   \n",
       "24    AI&Business Analyst / Consultant (Remote Inter...        Data Analyst   \n",
       "27                                 AI Engineer (Intern)       Data Engineer   \n",
       "...                                                 ...                 ...   \n",
       "1613                                 Solutions Engineer       Data Engineer   \n",
       "120   Bachelor of Science  Data Science und Künstlic...               Other   \n",
       "213   Research Associate for the Project “DASHH - Da...  Research Scientist   \n",
       "250                   Senior Software Engineer (Python)       Data Engineer   \n",
       "293                             Praktikum: Data Science               Other   \n",
       "\n",
       "     title_short_ChatGPT2  \n",
       "0          Data Scientist  \n",
       "9        AI/ML Specialist  \n",
       "13         Data Scientist  \n",
       "24       AI/ML Specialist  \n",
       "27       AI/ML Specialist  \n",
       "...                   ...  \n",
       "1613                Other  \n",
       "120        Data Scientist  \n",
       "213        Data Scientist  \n",
       "250                 Other  \n",
       "293        Data Scientist  \n",
       "\n",
       "[297 rows x 4 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(like=\"title\")[(df[\"title_short_ChatGPT\"] != df[\"title_short_ChatGPT2\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_short_ChatGPT2\n",
       "Other                         113\n",
       "Data Scientist                106\n",
       "AI/ML Specialist               46\n",
       "Business Intelligence (BI)     23\n",
       "Research Scientist              7\n",
       "Data Engineer                   1\n",
       "Data Consultant                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df[\"title_short_ChatGPT\"] != df[\"title_short_ChatGPT2\"]), \"title_short_ChatGPT2\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_short_ChatGPT\n",
       "Data Engineer                 130\n",
       "Data Analyst                   74\n",
       "Other                          57\n",
       "AI/ML Specialist               21\n",
       "Data Consultant                 8\n",
       "Machine Learning Engineer       2\n",
       "Research Scientist              2\n",
       "Business Intelligence (BI)      2\n",
       "Statistician                    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df[\"title_short_ChatGPT\"] != df[\"title_short_ChatGPT2\"]), \"title_short_ChatGPT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['(Junior) AI Engineer (m/w/d)',\n",
       "       '(Junior) Consultant | Gen AI Finance (m/w/d)',\n",
       "       '(Senior) Consultant AI Specialist (m/w/d)',\n",
       "       '(Senior) Consultant Tech & AI Implementation (m/w/d)',\n",
       "       '(Senior) Data & AI PreSales Consultant (m/w/d)',\n",
       "       'AI & Data - Analyst',\n",
       "       'AI (Agent) Engineer (f/m/d) | Jobs at VisionAI - Jobs',\n",
       "       'AI Architect & Optimization Specialist (m/w/d)',\n",
       "       'AI Cloud Engineer', 'AI Consultant', 'AI Developer',\n",
       "       'AI Developer (m/w/d)', 'AI Engineer', 'AI Engineer (Intern)',\n",
       "       'AI Engineer (Senior)', 'AI Engineer (m/w/d)',\n",
       "       'AI Engineer - Germany (Remote)',\n",
       "       'AI Engineer / AI Developer (m/w/d) bei einem SaaS-Unternehmen aus Würzburg (Full-Remote oder vor Ort)',\n",
       "       'AI Engineer for AI Startup',\n",
       "       'AI Engineer mit Schwerpunkt NLP (m/w/d)', 'AI Lead',\n",
       "       'AI Platform Engineer (all genders)',\n",
       "       'AI Software Developer in Test (f/m/d)', 'AI Software Engineer',\n",
       "       'AI Software Engineer (w/m/x)', 'AI consultant  - Energy',\n",
       "       'AI&Business Analyst / Consultant (Remote Internship)',\n",
       "       'AI-Engineer/Vollzeit', \"Aignostics' Talent Community\",\n",
       "       'Applied Scientist II (L5), AFT AI, Amazon AFT AI',\n",
       "       'Artificial Intelligence Engineer',\n",
       "       'Artificial Intelligence Specialist',\n",
       "       'Artificial Intelligence Specialist (w/m/d)',\n",
       "       'Associate / (Senior) AI Technology Consultant (m/w/d)',\n",
       "       'Chief AI Engineer', 'Chief Commercial Officer - AI (Berlin)',\n",
       "       'Consultant AI & Analytics',\n",
       "       'Consultant Künstliche Intelligenz / Artificial Intelligence Energy (m/w/d)',\n",
       "       'Consultant im Bereich Energy, Transformation & Sustainability (m/w/x)',\n",
       "       'Controlling & Analytics Trainee (m/w/d)',\n",
       "       'Data & AI Business Consultant (m/w/d)', 'Data & AI Scientist',\n",
       "       'Data & AI Scientist Personalized Computational Genomics (all genders)',\n",
       "       'Data & AI Strategist (m/f/d)',\n",
       "       'Data Analytics Training & Internship',\n",
       "       'Data Architect AI/ML (m/w/d) | Jobs bei Pexon Consulting GmbH',\n",
       "       'Data and AI Director', 'Data and AI Partner',\n",
       "       'DevOps & Cloud Engineer - Data Analytics & AI',\n",
       "       'Director of AI Engineering', 'Engagement Manager (Data & AI)',\n",
       "       'Engineer AI (m/w/d)',\n",
       "       'Engineering Manager - Applied Generative AI (all genders) @ Babbel | NGP Capital Job Board',\n",
       "       'GOglobal Trainee Data & AI (all genders)',\n",
       "       'Generative AI Engineer',\n",
       "       'Generative AI Explorer (Stable Diffusion, ControlNet...)',\n",
       "       'Google Cloud AI/ML Consultant (m/w/d)',\n",
       "       'Government Affairs Specialist', 'Head of AI',\n",
       "       'Head of AI (all genders)', 'Head of AI (m / f / d)',\n",
       "       'Head of Artificial Intelligence',\n",
       "       'Innovation Cup 2025 - Team Neuroinspired AI inference acceleration (all genders)',\n",
       "       'Intern AI-based Recommender Systems (f/m/x)',\n",
       "       'Intern Artificial Intelligence (m/f/d)*',\n",
       "       'Junior AI Platform Engineer or Working Student (all genders)',\n",
       "       'Junior Techno-Economic & Sustainability Analyst',\n",
       "       'Lead AI Engineer | Jobs at ES-Tec GmbH',\n",
       "       'Lead Consultant AI (Ref:IgLWy)',\n",
       "       'ML / AI Engineer Intern (m/f/d)',\n",
       "       'Postdoctoral Scientist for Artificial Intelligence in Oncology',\n",
       "       'Product Analytics Associate (Based in Dubai)',\n",
       "       'Python Developer (m/f/d) in the field of ML and AI',\n",
       "       'Robotics and Autonomous Systems / Robotics and AI Engineer',\n",
       "       'Scientist Biotic Stress Trait Development (m/f/d)',\n",
       "       'Scientist at innoFSPEC, AIP Technology Transfer',\n",
       "       'Senior AI Developer f/m/d', 'Senior AI Engineer',\n",
       "       'Senior AI Engineer (m/f/d)',\n",
       "       'Senior AI Scientist (f/m/d): SAP Business AI - SAP Knowledge Graph',\n",
       "       'Senior ML / AI Engineer', 'Senior Staff AI Engineer',\n",
       "       'Software & AI Engineer in Health (all genders)',\n",
       "       'Sr Scientist I, AI / ML', 'Staff ML / AI Engineer',\n",
       "       'Supply- Chain- Daten Analyst:in (m/w/d) - unbefristet',\n",
       "       'Trainee AI Engineer (m/w/d) - 12 Monate',\n",
       "       'Trainee Analytics Engineer', 'Trainee Data Analytics (m/w/d)',\n",
       "       'Werkstudent AI & Digital Transformation (m/w/d)',\n",
       "       'Werkstudent AI Developer- Taktile Robot Skills (m/w/d)',\n",
       "       'Working Student (Sustainability)',\n",
       "       'Working Student - ML/AI Developer – Document Understanding (m/w/d)',\n",
       "       'Working Student AI (m/f/x)',\n",
       "       'Working Student AI/ML (all genders) - (Any location in Germany)',\n",
       "       'Working Student Artificial Intelligence (m/w/d)'], dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The provided category \"AI/ML Specialist\" seems a bit inflated and not too accurate.\n",
    "# -> There do exist many jobs titled \"AI Engineer\"\n",
    "df.loc[df[\"title_short_ChatGPT2\"] == \"AI/ML Specialist\", \"title\"].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_short_ChatGPT2\n",
       "Data Scientist                500\n",
       "Other                         425\n",
       "AI/ML Specialist              109\n",
       "Machine Learning Engineer      91\n",
       "Data Analyst                   87\n",
       "Data Engineer                  76\n",
       "Research Scientist             55\n",
       "Business Intelligence (BI)     46\n",
       "Data Consultant                43\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also, provided category \"Statistician\" does not appear anymore.\n",
    "df[\"title_short_ChatGPT2\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-Tuning 2:\n",
    "Can you drop the category \"Statistician\" and instead include the category \"AI Engineer\"?\n",
    "\n",
    "\n",
    "**Response:**\n",
    "\n",
    "Understood! I will update the code to:\n",
    "\n",
    "1. Remove the \"Statistician\" category.\n",
    "2. Add an \"AI Engineer\" category to classify relevant titles such as those mentioning \"AI Engineer\" or similar terms.\n",
    "Let me make these changes now.\n",
    "\n",
    "The categorization function has been updated:\n",
    "\n",
    "1. \"Statistician\" category removed.\n",
    "2. Added \"AI Engineer\" category for relevant titles like \"AI Engineer\" or \"AI\" with \"Engineer.\"\n",
    "\n",
    "The updated categories are now applied to the job titles. I’ll save this refined file for you. ​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the categorization function to remove \"Statistician\" and add \"AI Engineer\"\n",
    "def updated_categorize_job_title(title):\n",
    "    title_lower = title.lower()\n",
    "    \n",
    "    if \"data scientist\" in title_lower or \"data science\" in title_lower:\n",
    "        return \"Data Scientist\"\n",
    "    elif \"data analyst\" in title_lower:\n",
    "        return \"Data Analyst\"\n",
    "    elif \"machine learning\" in title_lower or \"ml engineer\" in title_lower:\n",
    "        return \"Machine Learning Engineer\"\n",
    "    elif \"data engineer\" in title_lower:\n",
    "        return \"Data Engineer\"\n",
    "    elif \"business intelligence\" in title_lower or \"bi \" in title_lower:\n",
    "        return \"Business Intelligence (BI)\"\n",
    "    elif \"research scientist\" in title_lower or \"research\" in title_lower:\n",
    "        return \"Research Scientist\"\n",
    "    elif \"ai engineer\" in title_lower or (\"ai\" in title_lower and \"engineer\" in title_lower):\n",
    "        return \"AI Engineer\"\n",
    "    elif \"ai\" in title_lower or \"artificial intelligence\" in title_lower:\n",
    "        return \"AI/ML Specialist\"\n",
    "    elif \"consultant\" in title_lower:\n",
    "        return \"Data Consultant\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "# Apply the updated categorization function to the job titles\n",
    "# updated_job_titles_df['Category'] = updated_job_titles_df['job_titles'].apply(updated_categorize_job_title)\n",
    "\n",
    "# # Preview the updated DataFrame\n",
    "# updated_job_titles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_short_ChatGPT3\"] = df[\"title_clean\"].apply(updated_categorize_job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>title_short_ChatGPT</th>\n",
       "      <th>title_short_ChatGPT2</th>\n",
       "      <th>title_short_ChatGPT3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AI Engineer (Intern)</td>\n",
       "      <td>AI Engineer (Intern)</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ML / AI Engineer Intern (m/f/d)</td>\n",
       "      <td>ML / AI Engineer Intern</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>AI Engineer for AI Startup</td>\n",
       "      <td>AI Engineer for AI Startup</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>(Junior) AI Engineer (m/w/d)</td>\n",
       "      <td>(Junior) AI Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>AI Engineer - Germany (Remote)</td>\n",
       "      <td>AI Engineer - Germany (Remote)</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Robotics and Autonomous Systems / Robotics and...</td>\n",
       "      <td>Robotics and Autonomous Systems / Robotics and...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>AI Engineer mit Schwerpunkt NLP (m/w/d)</td>\n",
       "      <td>AI Engineer mit Schwerpunkt NLP</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>AI Software Engineer</td>\n",
       "      <td>AI Software Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>AI Engineer (Senior)</td>\n",
       "      <td>AI Engineer (Senior)</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Junior AI Platform Engineer or Working Student...</td>\n",
       "      <td>Junior AI Platform Engineer or Working Student</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Chief AI Engineer</td>\n",
       "      <td>Chief AI Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Senior Staff AI Engineer</td>\n",
       "      <td>Senior Staff AI Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>Engineer AI (m/w/d)</td>\n",
       "      <td>Engineer AI</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Trainee AI Engineer (m/w/d) - 12 Monate</td>\n",
       "      <td>Trainee AI Engineer  - 12 Monate</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>AI-Engineer/Vollzeit</td>\n",
       "      <td>AI-Engineer/Vollzeit</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Senior AI Engineer (m/f/d)</td>\n",
       "      <td>Senior AI Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>Senior AI Engineer</td>\n",
       "      <td>Senior AI Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>Generative AI Engineer</td>\n",
       "      <td>Generative AI Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>AI Software Engineer (w/m/x)</td>\n",
       "      <td>AI Software Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>AI Engineer (m/w/d)</td>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>AI Platform Engineer (all genders)</td>\n",
       "      <td>AI Platform Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>Trainee Analytics Engineer</td>\n",
       "      <td>Trainee Analytics Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>AI Engineer (m/w/d)</td>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>Software &amp; AI Engineer in Health (all genders)</td>\n",
       "      <td>Software &amp; AI Engineer in Health</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>Director of AI Engineering</td>\n",
       "      <td>Director of AI Engineering</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>AI Engineer (m/w/d)</td>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>AI Engineer / AI Developer (m/w/d) bei einem S...</td>\n",
       "      <td>AI Engineer / AI Developer  bei einem SaaS-Unt...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>Senior ML / AI Engineer</td>\n",
       "      <td>Senior ML / AI Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>Staff ML / AI Engineer</td>\n",
       "      <td>Staff ML / AI Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>DevOps &amp; Cloud Engineer - Data Analytics &amp; AI</td>\n",
       "      <td>DevOps &amp; Cloud Engineer - Data Analytics &amp; AI</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>AI Cloud Engineer</td>\n",
       "      <td>AI Cloud Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>Lead AI Engineer | Jobs at ES-Tec GmbH</td>\n",
       "      <td>Lead AI Engineer | Jobs at ES-Tec GmbH</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>AI (Agent) Engineer (f/m/d) | Jobs at VisionAI...</td>\n",
       "      <td>AI (Agent) Engineer  | Jobs at VisionAI - Jobs</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>Engineering Manager - Applied Generative AI (a...</td>\n",
       "      <td>Engineering Manager - Applied Generative AI  @...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "      <td>AI Engineer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title   \n",
       "9                                           AI Engineer  \\\n",
       "27                                 AI Engineer (Intern)   \n",
       "31                      ML / AI Engineer Intern (m/f/d)   \n",
       "52                           AI Engineer for AI Startup   \n",
       "72                         (Junior) AI Engineer (m/w/d)   \n",
       "87                                          AI Engineer   \n",
       "105                      AI Engineer - Germany (Remote)   \n",
       "112   Robotics and Autonomous Systems / Robotics and...   \n",
       "117                                         AI Engineer   \n",
       "160             AI Engineer mit Schwerpunkt NLP (m/w/d)   \n",
       "164                                AI Software Engineer   \n",
       "179                                AI Engineer (Senior)   \n",
       "203   Junior AI Platform Engineer or Working Student...   \n",
       "294                                   Chief AI Engineer   \n",
       "302                            Senior Staff AI Engineer   \n",
       "349                                 Engineer AI (m/w/d)   \n",
       "351             Trainee AI Engineer (m/w/d) - 12 Monate   \n",
       "427                                AI-Engineer/Vollzeit   \n",
       "442                          Senior AI Engineer (m/f/d)   \n",
       "463                                  Senior AI Engineer   \n",
       "475                              Generative AI Engineer   \n",
       "478                        AI Software Engineer (w/m/x)   \n",
       "495                                 AI Engineer (m/w/d)   \n",
       "545                  AI Platform Engineer (all genders)   \n",
       "563                          Trainee Analytics Engineer   \n",
       "572                                 AI Engineer (m/w/d)   \n",
       "604      Software & AI Engineer in Health (all genders)   \n",
       "674                          Director of AI Engineering   \n",
       "712                                 AI Engineer (m/w/d)   \n",
       "760   AI Engineer / AI Developer (m/w/d) bei einem S...   \n",
       "762                             Senior ML / AI Engineer   \n",
       "766                                         AI Engineer   \n",
       "1048                             Staff ML / AI Engineer   \n",
       "1359      DevOps & Cloud Engineer - Data Analytics & AI   \n",
       "1377                                  AI Cloud Engineer   \n",
       "1409             Lead AI Engineer | Jobs at ES-Tec GmbH   \n",
       "1410  AI (Agent) Engineer (f/m/d) | Jobs at VisionAI...   \n",
       "1412  Engineering Manager - Applied Generative AI (a...   \n",
       "\n",
       "                                            title_clean title_short_ChatGPT   \n",
       "9                                           AI Engineer       Data Engineer  \\\n",
       "27                                 AI Engineer (Intern)       Data Engineer   \n",
       "31                              ML / AI Engineer Intern       Data Engineer   \n",
       "52                           AI Engineer for AI Startup       Data Engineer   \n",
       "72                                 (Junior) AI Engineer       Data Engineer   \n",
       "87                                          AI Engineer       Data Engineer   \n",
       "105                      AI Engineer - Germany (Remote)       Data Engineer   \n",
       "112   Robotics and Autonomous Systems / Robotics and...       Data Engineer   \n",
       "117                                         AI Engineer       Data Engineer   \n",
       "160                     AI Engineer mit Schwerpunkt NLP       Data Engineer   \n",
       "164                                AI Software Engineer       Data Engineer   \n",
       "179                                AI Engineer (Senior)       Data Engineer   \n",
       "203      Junior AI Platform Engineer or Working Student       Data Engineer   \n",
       "294                                   Chief AI Engineer       Data Engineer   \n",
       "302                            Senior Staff AI Engineer       Data Engineer   \n",
       "349                                         Engineer AI       Data Engineer   \n",
       "351                    Trainee AI Engineer  - 12 Monate       Data Engineer   \n",
       "427                                AI-Engineer/Vollzeit       Data Engineer   \n",
       "442                                  Senior AI Engineer       Data Engineer   \n",
       "463                                  Senior AI Engineer       Data Engineer   \n",
       "475                              Generative AI Engineer       Data Engineer   \n",
       "478                                AI Software Engineer       Data Engineer   \n",
       "495                                         AI Engineer       Data Engineer   \n",
       "545                                AI Platform Engineer       Data Engineer   \n",
       "563                          Trainee Analytics Engineer       Data Engineer   \n",
       "572                                         AI Engineer       Data Engineer   \n",
       "604                    Software & AI Engineer in Health       Data Engineer   \n",
       "674                          Director of AI Engineering       Data Engineer   \n",
       "712                                         AI Engineer       Data Engineer   \n",
       "760   AI Engineer / AI Developer  bei einem SaaS-Unt...       Data Engineer   \n",
       "762                             Senior ML / AI Engineer       Data Engineer   \n",
       "766                                         AI Engineer       Data Engineer   \n",
       "1048                             Staff ML / AI Engineer       Data Engineer   \n",
       "1359      DevOps & Cloud Engineer - Data Analytics & AI       Data Engineer   \n",
       "1377                                  AI Cloud Engineer       Data Engineer   \n",
       "1409             Lead AI Engineer | Jobs at ES-Tec GmbH       Data Engineer   \n",
       "1410     AI (Agent) Engineer  | Jobs at VisionAI - Jobs       Data Engineer   \n",
       "1412  Engineering Manager - Applied Generative AI  @...       Data Engineer   \n",
       "\n",
       "     title_short_ChatGPT2 title_short_ChatGPT3  \n",
       "9        AI/ML Specialist          AI Engineer  \n",
       "27       AI/ML Specialist          AI Engineer  \n",
       "31       AI/ML Specialist          AI Engineer  \n",
       "52       AI/ML Specialist          AI Engineer  \n",
       "72       AI/ML Specialist          AI Engineer  \n",
       "87       AI/ML Specialist          AI Engineer  \n",
       "105      AI/ML Specialist          AI Engineer  \n",
       "112      AI/ML Specialist          AI Engineer  \n",
       "117      AI/ML Specialist          AI Engineer  \n",
       "160      AI/ML Specialist          AI Engineer  \n",
       "164      AI/ML Specialist          AI Engineer  \n",
       "179      AI/ML Specialist          AI Engineer  \n",
       "203      AI/ML Specialist          AI Engineer  \n",
       "294      AI/ML Specialist          AI Engineer  \n",
       "302      AI/ML Specialist          AI Engineer  \n",
       "349      AI/ML Specialist          AI Engineer  \n",
       "351      AI/ML Specialist          AI Engineer  \n",
       "427      AI/ML Specialist          AI Engineer  \n",
       "442      AI/ML Specialist          AI Engineer  \n",
       "463      AI/ML Specialist          AI Engineer  \n",
       "475      AI/ML Specialist          AI Engineer  \n",
       "478      AI/ML Specialist          AI Engineer  \n",
       "495      AI/ML Specialist          AI Engineer  \n",
       "545      AI/ML Specialist          AI Engineer  \n",
       "563      AI/ML Specialist          AI Engineer  \n",
       "572      AI/ML Specialist          AI Engineer  \n",
       "604      AI/ML Specialist          AI Engineer  \n",
       "674      AI/ML Specialist          AI Engineer  \n",
       "712      AI/ML Specialist          AI Engineer  \n",
       "760      AI/ML Specialist          AI Engineer  \n",
       "762      AI/ML Specialist          AI Engineer  \n",
       "766      AI/ML Specialist          AI Engineer  \n",
       "1048     AI/ML Specialist          AI Engineer  \n",
       "1359     AI/ML Specialist          AI Engineer  \n",
       "1377     AI/ML Specialist          AI Engineer  \n",
       "1409     AI/ML Specialist          AI Engineer  \n",
       "1410     AI/ML Specialist          AI Engineer  \n",
       "1412     AI/ML Specialist          AI Engineer  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(like=\"title\")[(df[\"title_short_ChatGPT3\"] != df[\"title_short_ChatGPT2\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_short_ChatGPT3\n",
       "Data Scientist                500\n",
       "Other                         425\n",
       "Machine Learning Engineer      91\n",
       "Data Analyst                   87\n",
       "Data Engineer                  76\n",
       "AI/ML Specialist               71\n",
       "Research Scientist             55\n",
       "Business Intelligence (BI)     46\n",
       "Data Consultant                43\n",
       "AI Engineer                    38\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"title_short_ChatGPT3\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['(Advanced) Data Developer', '(Junior) Data Product Associate',\n",
       "       '(Junior) Digital Produktmanager  AurumCars',\n",
       "       '(Junior) Digital Produktmanager  Mietwagen',\n",
       "       '(Junior) Digital Produktmanager  Payment Mietwagen',\n",
       "       '(Junior) Online-Marketing Produktmanager  Mietwagen',\n",
       "       '(Junior) Product Manager Financial Services',\n",
       "       '(Junior) Produktmanager  Chatbot Mietwagen',\n",
       "       '(Junior) Produktmanager  Operations Analytics Mietwagen',\n",
       "       '(Junior) Produktmanager  SEO-Automatisierung Mietwagen',\n",
       "       '(Junior) Produktmanager / Operationsmanager  Automatisierung Mietwagen',\n",
       "       '(Junior) Specialist ESG Reporting',\n",
       "       '(Junior) Technischer Produktmanager  Partnermanagement Mietwagen',\n",
       "       '(Senior) Biochemist / Biopyhsicist',\n",
       "       '(Senior) Data & Survey Engineer , Quantitative Marktforschung',\n",
       "       '(Senior) DevOps Data Integration Engineer',\n",
       "       '(Senior) Scientist Primary Pharmacology of the Target Incubator Unit',\n",
       "       '(Senior-) Software Engineer', '1D/2D MATERIAL SCIENTIST',\n",
       "       '2025 Applied Scientist Internship, Amazon University Talent Acquisition',\n",
       "       'Abschlussarbeit im Bereich Datenstrategie und Künstliche Intelligenz',\n",
       "       'Abschlussarbeit im Bereich: KI basierte Generierung von Schiffsgeräuschen',\n",
       "       'Abschlussarbeit zum Thema: „Generative KI\"',\n",
       "       'Account Manager:in für Sound Branding, Podcasts und Audiospots',\n",
       "       'Analyst  Short Term Trading in Renewable Energies',\n",
       "       'Analyst & Marketing Technology Manager',\n",
       "       'Analytics & Insights Internship', 'Analytics Engineer',\n",
       "       'Analytics Engineer - Graduate (Hybrid;/d)',\n",
       "       'Analytics Engineering Lead',\n",
       "       'Analytics and Insight Professional, Amazon Advertising, Analytics and Insights',\n",
       "       'Applied Scientist, Amazon Nova',\n",
       "       'Applied Scientist, Amazon Robotics R&D',\n",
       "       'Applied Scientist, Artificial General Intelligence, AGI Information',\n",
       "       'Applied Scientist, Content Systems Science and Engineering, Amazon',\n",
       "       'Applied Scientist, Fintech (Fraud)',\n",
       "       'Assistant  Databases and Data Analysis',\n",
       "       'Associate - Index Operations',\n",
       "       'Associate Special Project, Esports',\n",
       "       'Atomic, Molecular, and Optical Physicist',\n",
       "       'Bachelor-/Master Thesis »Full-field Thermo-mechanical Characterization of Glass Materials«',\n",
       "       'Bachelor/ Master Thesis: Methane leak localization from ambient data',\n",
       "       'Backend Developer', 'Backend Software Engineer - Remote',\n",
       "       'Battery Scientist', 'Bench Scientist',\n",
       "       'Beschäftigte/r Qualitätsmanagement und Datenanalyse',\n",
       "       'Big Data Architect', 'Big Data DevOps Engineer  | (DSIDMG)',\n",
       "       'Bilanzmathematiker / Statistiker', 'Bioinformatician',\n",
       "       'Bioinformatician  Immunogenetics',\n",
       "       'Bioinformatician  in immunopeptidomics',\n",
       "       'Bloomwell - Working Student Data & Analytics *',\n",
       "       'Breeding Informatics Analyst  Full Time - in Tübingen',\n",
       "       'Business  Development Manger', 'Business Analyst',\n",
       "       'Business Analyst  – Data Analytics Vertriebsplanung | Banking',\n",
       "       'Business Analyst - Marketing Planning und Forecasting',\n",
       "       'Business Analyst / Controller',\n",
       "       'Business Analyst Data Management', 'Business Analyst Intern',\n",
       "       'Business Analyst – Data Quality',\n",
       "       'Business Process Analyst – Marketing & Sales',\n",
       "       'COMPUTATIONAL GENOMICS SCIENTIST , Referenz: „51004-24-05-WAPRO“',\n",
       "       'CRA/SCRA', 'CRM Data Specialist *', 'Carbon Project Risk Analyst',\n",
       "       'Certified Strength and Conditioning Specialist',\n",
       "       'Chemical Technical Assistant', 'Chief Data Officer',\n",
       "       'Chief Technology Officer',\n",
       "       'Chief Technology Officer - Must be based in Germany',\n",
       "       'Climate Risk Intern *', 'Cloud Engineer',\n",
       "       'Computational Biologist', 'Computational Chemist Lead',\n",
       "       'Computational Materials Scientist*',\n",
       "       'Computer Scientist | InformatikerIn | Software EntwicklerIn für klinische KI-Forschung und Anwendung',\n",
       "       'Computer Scientist – Mendel Verlag', 'Computer Vision Engineer',\n",
       "       'Consulting & Analytics Summer Intern',\n",
       "       'Create a DataCamp Course - Cloud (Part-Time, Freelance)',\n",
       "       'DWH Analyst', 'DWH-Entwickler', 'Data / Analytics Engineer',\n",
       "       'Data Analysis Expert Battery Test Field',\n",
       "       'Data Analysis, Modeling & Simulation Engineer',\n",
       "       'Data Analytics Architect', 'Data Analytics Engineer',\n",
       "       'Data Analytics Specialist', 'Data Architect', 'Data Architekt',\n",
       "       'Data Assimilation Scientist', 'Data Enthusiast',\n",
       "       'Data Integrity Specialist Pharma', 'Data Product Manager',\n",
       "       'Data Quality Manager', 'Data Reporting Analyst',\n",
       "       'Data Solutions Specialist', 'Data Specialist',\n",
       "       'Data Steward SAP S/4HANA - \"Business Partner\"',\n",
       "       'Data Team Manager', 'Data and Reporting Analyst', 'Data-Analyst',\n",
       "       'Data-Scientist/MLOps - KI-basiertes Recycling',\n",
       "       'Data/Software Engineer', 'Datenanalyst',\n",
       "       'Datenanalyst  im Bereich Energiewirtschaft',\n",
       "       'Datenanalyst  im Vertriebsmanagement',\n",
       "       'Datenanalyst für Logistikprozesse', 'Datenanalyst:in Metering',\n",
       "       'Datenanalysten/in  für Modelle in der konjunkturstatistischen Erhebung im Gastgewerbe',\n",
       "       'Datenarchitekt Versicherungsplattform', 'Decision Scientist',\n",
       "       'Detector Calibration and Characterisation Scientist',\n",
       "       'Deutsche Bank Graduate Programme  Technology, Data & Innovation 2025',\n",
       "       'Digital Marketing & Data Analytics Manager',\n",
       "       'Digital Trust and Safety Analyst with German',\n",
       "       'Director, Clinical Scientist',\n",
       "       'Doktorand für die Konzipierung und Implementierung von KI-gestützten Produktionssystemen',\n",
       "       'Dr. rer. nat. Physik / Chemie / Materialwissenschaften - Teamleitung & Projektmanagement',\n",
       "       'E-Commerce Analyst & Marketing Support Manager (Kaufmann/-frau - E-Commerce)',\n",
       "       'EMEA - Solutions Engineer',\n",
       "       'ERP Business Analyst, Microsoft Business Central  Digital Development',\n",
       "       'ERP Business Analyst, SAP  Digital Development',\n",
       "       'ETL-Entwickler  Azure Data Factory',\n",
       "       'Economic Modeller / Contract Role  Full Remote',\n",
       "       'Electrical Engineer or Computer Scientist  in Technical Support / Automation Technology',\n",
       "       'Enterprise Solutions Engineer, Germany',\n",
       "       'Experte für Fahrzeug Telematikdaten und Datenanalysen',\n",
       "       'Experte für Fahrzeug-Telematikdaten und Datenanalysen  - hybrides Arbeiten (Remote & Präsenz)',\n",
       "       'Fachkraft für den Bereich Einnahmeaufteilung & Statistik',\n",
       "       'Fachreferent/in für Künstliche Intelligenz A13/E13',\n",
       "       'Field Application Scientist, EMEA',\n",
       "       'Financial Analyst - Intern (Remote Internship - Finance)',\n",
       "       'Financial Analyst Intern',\n",
       "       'Financial Data Specialist  Corporate Actions Shares & Funds',\n",
       "       'Financial Data Specialist  – Masterdata Shares / Funds',\n",
       "       'Financial Data Specialist – Bonds / Wertpapiere',\n",
       "       'Financial Engineer', 'Financial Engineer Expert',\n",
       "       'Founding Software Engineer', 'Fraud Analyst',\n",
       "       'Fraud Fighter Wanted', 'Fraud Operations Specialist',\n",
       "       'Full Stack Entwickler',\n",
       "       'Global Engineer - Real World Evidence - Europe',\n",
       "       'Gruppenleiter  Sach-Firmen SF - Strategie, Steuerung, Pricing und Produktmanagement für das Geschäftsfeld Sach-Firmen',\n",
       "       'HR Analytics Specialist', 'HR Business Partner',\n",
       "       'HR Data Analytics  - Gigafactory Berlin-Brandenburg',\n",
       "       'Head Applied Data & Genetics Science – Seeds Field Crops Europe',\n",
       "       'Head of / VP - Data Experience',\n",
       "       'Head of Clinical Data Management & IT', 'Head of Data',\n",
       "       'Head of Data & Analytics',\n",
       "       'Head of Data & Analytics - Medical Cannabis Industry',\n",
       "       'Head of IoT', 'Head of ML Platform & Developer Productivity',\n",
       "       'Head of R&D', 'INTERDISCIPLINARY ENGINEER/SCIENTIST',\n",
       "       'IT Projektleiter / Projektmanager (mwd) DevOps',\n",
       "       'Informatiker*in  für den Bereich High Performance Computing (HPC) / Infrastruktur',\n",
       "       'Ingenieur  technische Integritätsbewertung und Datenanalyse',\n",
       "       'Ingenieur / Data-Scientist', 'Initiativbewerbung',\n",
       "       'Initiativbewerbung Graduates Consulting @ MHP – A Porsche Company',\n",
       "       'Initiativbewerbung: Wissenschaftliche Mitarbeitende',\n",
       "       'Insights Analyst',\n",
       "       'Instrument Scientist (Gamma Rays and UV) in Astroparticle Physics',\n",
       "       'Intern - Global Data and Analytics',\n",
       "       'Intern Business Analytics - Web & Commerce',\n",
       "       'Intern automation and computer vision in microscopy',\n",
       "       'Interns Epidemic Risk Solutions *',\n",
       "       'Internship - Credit Risk Analyst',\n",
       "       'Internship - Investment Product Analyst',\n",
       "       'Internship Battery Analytics', 'Internship Data Analytics',\n",
       "       'Internship Program Autumn 2025',\n",
       "       'Internship for Battery Data Analysis and Lab Automation',\n",
       "       'Internship in Customer Preferences & Vehicle Recommendations starting February/March 2025',\n",
       "       'Internship on Business and Data Analysis',\n",
       "       'Job Offer: Account Manager  * - Lipotype GmbH',\n",
       "       'Junior / Medior Model Validator – Credit Risk',\n",
       "       'Junior Business Analyst Risikomanagement',\n",
       "       'Junior Cloud Engineer', 'Junior Credit Analyst',\n",
       "       'Junior Data & Survey Engineer , Quantitative Marktforschung',\n",
       "       'Junior Data-Scientist', 'Junior KI-Entwickler',\n",
       "       'Junior Prozessmanager  InsurTech',\n",
       "       'Junior Quality Lab Scientist Microbiology',\n",
       "       'Junior Scientist (DEL), Bachelor/Master',\n",
       "       'KI-Entwickler/in - Mitarbeiter/in Künstliche Intelligenz',\n",
       "       'Lab Working Student', 'Laboratory management',\n",
       "       'Leitung  für den Sachbereich Personalmanagement und Zentralaufgaben',\n",
       "       'Life Scientist as Global Technical Support Specialist  French Speaking',\n",
       "       'ML Architect Engineer', 'ML Ops Engineer - Berlin',\n",
       "       'MLOps Engineer', 'MLOps Engineer  100% remote', 'MRI Scientist',\n",
       "       'MRI Working Student/Intern', 'Machine Vision Engineer (Halcon)',\n",
       "       'Master Data Assistant',\n",
       "       'Master Data Operator (Schwerpunkt: Liquor, Tobacco & Confectionary)',\n",
       "       'Master of Science (M.Sc.)  Start 2025 Location Berlin-Potsdam (VT/STAR)',\n",
       "       'Masterarbeit',\n",
       "       'Masterarbeit: Schnelleres Erkennen unbekannter Gegenstände unter Wasser dank Few Shot Learning',\n",
       "       'Material Development Engineer, Formulation Scientist',\n",
       "       'Mathematiker:in / Physiker:in Aktuarielles Controlling',\n",
       "       'Mitarbeiter Datenanalyse im HomeOffice',\n",
       "       'Mitarbeiter im Qualitätsmanagement  (Fachinformatiker/in - Daten- und Prozessanalyse)',\n",
       "       'Mitarbeiter/-in Projektmanagement digitaler Service / Datenanalyse',\n",
       "       'Mitarbeiterin/Mitarbeiter im Bereich Zahlen- und Datenanalyse',\n",
       "       'NLP Engineer', 'Network Engineers',\n",
       "       'Off-Cycle Analyst Intern - Hamburg',\n",
       "       'Operations & Marketing Associate',\n",
       "       'Performance Engineer - Laundry Care', 'PhD Candidate',\n",
       "       'PhD Candidate : Spatial Metabolomics',\n",
       "       'Physicist Dosimetry Expert',\n",
       "       'Planer*in  für das Sachgebiet -Räumliche Entwicklungsplanung- im Amt für Stadtentwicklung und Statistik',\n",
       "       'Portfolio Analyst',\n",
       "       'PostDoc in \"A system-wide view of processes driving recent observed Southern Ocean change\"',\n",
       "       'PostDoc in atmospheric physics on deep learning / foundational modelling of clouds',\n",
       "       'Postdoc',\n",
       "       'Postdoc for the investigation of biomaterial structural properties',\n",
       "       'Postdoctoral Scientist - Metabolomics Specialist for Drug Safety - all genders - (Fixed-term contract 24 months)',\n",
       "       'Postdoctoral Scientist Chemistry Innovations for Oligonucleotide Delivery',\n",
       "       'Postdoctoral Scientist Position',\n",
       "       'Postdoctoral Scientist, Amazon Robotics',\n",
       "       'Postdoctoral scientist, Atmospheric global observing system simulations',\n",
       "       'Postdoctural Scientist  for detector calibration and optimisation',\n",
       "       'Postdoktorand:in', 'Praktikum Data Analytics', 'Pricing Actuary',\n",
       "       'Principal Applied Scientist - Network Optimization',\n",
       "       'Principal Applied Scientist - Payments',\n",
       "       'Principal Applied Scientist - Transactions Risk Management',\n",
       "       'Principal Software Engineer',\n",
       "       'Principal, Same Day, Long-term planning',\n",
       "       'Process Development Engineer',\n",
       "       'Process Engineer (relocation to St. Gallen, Switzerland)',\n",
       "       'Product Analyst', 'Product Analyst - Shopping Experience',\n",
       "       'Product Analyst - Social Discovery app',\n",
       "       'Product Analyst – Business Data & Insights', 'Product Associate',\n",
       "       'Product Lead, Platform Products', 'Product Lead, Pricing',\n",
       "       'Product Lead, Search', 'Product Manager',\n",
       "       'Product Manager (DeFi / Earn) - Web3',\n",
       "       'Product Manager Pricing & Analytics', 'Product Manager, DashOps',\n",
       "       'Product Owner  - Buchhaltung & Berichte',\n",
       "       'Product Safety Specialist *', 'Production Technology Engineer',\n",
       "       'Produkt- und Datenanalyst/in  (Kaufmann/-frau - Versicherungen u. Finanzen - Versicherung)',\n",
       "       'Program/Product Manager Intern',\n",
       "       'Project Management Assistant (Real World Data)',\n",
       "       'Projektleiter:in Künstliche Intelligenz',\n",
       "       'Prozess-und Betriebsdatenspezialist  (Berufsspezialist/in - Datenanalyse)',\n",
       "       'Python Developer', 'Python Full Stack Developer',\n",
       "       'Quant Developer', 'Quantitative Power Trading Analyst',\n",
       "       'Quantum Scientist - Superconducting Qubits (remote-ish)',\n",
       "       'R&D Scientist', 'Referent Netzplanungsdatenmanagement',\n",
       "       'Robotics Software Engineer all levels', 'SAP Analytics Architect',\n",
       "       'SAP Analytics Expert', 'SAP Business Analyst  Data Migrations',\n",
       "       'Sales / Vertrieb Weiterbildung  - Jobchance für Remote-Workers (Teilzeit)',\n",
       "       'Sales Manager / Sales Development Representative',\n",
       "       'Scientific Data Architect / Senior Scientific Data Architect- EMEA Remote',\n",
       "       'Scientific Software Engineer',\n",
       "       'Scientist  Bioprocess Development RDI-Projects',\n",
       "       'Scientist  for the area Immunoassays (full-time)',\n",
       "       'Scientist  in vitro DMPK',\n",
       "       'Scientist (Postdoc) for Scanning Microprobe Endstation at Beamline P25, PETRA III',\n",
       "       'Scientist - In vivo Pharmacology',\n",
       "       'Scientist - LC-MS: Drug Product Characterization for Biopharmaceuticals',\n",
       "       'Scientist - Protein Analytics',\n",
       "       'Scientist / Postdoc : Analysis of Microscopic BIOMedical Images (AMBIOM)',\n",
       "       'Scientist / Postdoc in bioinformatics  Institute Molekularbiologie',\n",
       "       'Scientist / Study Director',\n",
       "       'Scientist Digital Imaging , Referenz: „51001-24-03-WAPRO“',\n",
       "       'Scientist III, Field Applications',\n",
       "       'Scientist Viral Vector Production',\n",
       "       'Scientist in the field of fiber drawing technology for active fibers',\n",
       "       'Scientist in the field of fiber drawing technology for active fluoride fibers',\n",
       "       'Scientist in the field of fiber preform development for active fibers',\n",
       "       'Scientist – DNA-, RNA- Oligonucleotide Synthesis',\n",
       "       'Scientist – Optical Design and Simulation',\n",
       "       'Scientist/DevOps Position in EScience Section',\n",
       "       'Scientist/DevOps in EScience Section', 'Semantics Engineer',\n",
       "       'Senior Analyst / Engineer  im Bereich IT Data Analytics & Integration',\n",
       "       'Senior Analytical Scientist', 'Senior Analytics Engineer',\n",
       "       'Senior Applied Scientist - Fulfilment Planning',\n",
       "       'Senior Applied Scientist, ATS Science and Technology',\n",
       "       'Senior Applied Scientist, Amazon Robotics R&D',\n",
       "       'Senior Applied Scientist, Artificial General Intelligence',\n",
       "       'Senior Applied Scientist, Logistics',\n",
       "       'Senior Applied Scientist- Network Optimization',\n",
       "       'Senior Associate Quantitative Analyse',\n",
       "       'Senior Backend Developer',\n",
       "       'Senior Controller Projektmanagement  [JR105408]',\n",
       "       'Senior Data / Machine-Learning Engineer', 'Senior Data Architect',\n",
       "       'Senior Manager, Safety Scientist', 'Senior Product Manager',\n",
       "       'Senior Product Manager - Fraud Prevention',\n",
       "       'Senior Python Developer (LLM-based applications, SME)',\n",
       "       'Senior Quant Developer', 'Senior Regional Marketing Manager',\n",
       "       'Senior Remote Sensing Scientist', 'Senior Scientist',\n",
       "       'Senior Scientist  Molecular Complex Development',\n",
       "       'Senior Scientist - Mass Spectrometry',\n",
       "       'Senior Scientist / Platform Lead  Process Cheese - Temporary contract until 28.02.2027',\n",
       "       'Senior Scientist R&D  Life Science MS',\n",
       "       'Senior Sensory Scientist', 'Senior Software Developer Data & ML',\n",
       "       'Senior Software Engineer', 'Senior Software Engineer (Python)',\n",
       "       'Senior/Principal Scientist Systems Pharmacology',\n",
       "       'Senior/Principal Scientist Systems Pharmacology PBPK /...',\n",
       "       'Software Engineer  – Data Lake Architect',\n",
       "       'Software Engineer (Data & Python)', 'Software Engineer (Python)',\n",
       "       'Softwareentwickler/Data-Scientist für MES Integration  im Bereich Li-Ion Large Cells',\n",
       "       'Solutions Engineer', 'Spezialist Customer Data Governance',\n",
       "       'Spezialist für Verkehrsdatenanalyse', 'Sports Scientist',\n",
       "       'Staff Scientist', 'Staff Scientist Cell Therapy-Type 1 Diabetes',\n",
       "       'Strategy Manager Life Science',\n",
       "       'TOP TECHNOLOGIES CONSULTING GmbH – Berater (Mensch) Data Lifecycle Management',\n",
       "       'Talent Day - Explore a Tech Career with Netlight', 'Talent Pool',\n",
       "       'Teamlead Data Intelligence',\n",
       "       'Technical Assistant - Biotechnology',\n",
       "       'Technical Solutions Engineer - Data (Remote)',\n",
       "       'Unsolicited Application / Initiativbewerbung',\n",
       "       'Unsolicited application (Full time)',\n",
       "       'Unterstützung im Bereich Einnahmeaufteilung & Statistik',\n",
       "       'VP of Data & Analytics', 'Venture Development Tech Analyst',\n",
       "       'Visiting Analyst (January 2025 and onwards)',\n",
       "       'Werkstudent  Data Analytics',\n",
       "       'Werkstudent  Data Management AurumCars',\n",
       "       'Werkstudent  Digital Produktmanagement AurumCars',\n",
       "       'Werkstudent  Digital Produktmanagement Mietwagen',\n",
       "       'Werkstudent  Digital Produktmanagement Web & App – Mietwagen Spanien',\n",
       "       'Werkstudent  Operations & Digital Project Management Mietwagen',\n",
       "       'Werkstudent  Technisches Produktmanagement / Partnermanagement Mietwagen',\n",
       "       'Werkstudent  im Bereich Datenmanagement',\n",
       "       'Werkstudent Analytics: Editorial Intelligence',\n",
       "       'Werkstudent Data Analytics',\n",
       "       'Werkstudent Insights / Analytics  ab Februar 2025',\n",
       "       'Werkstudent Java-Entwickler',\n",
       "       'Werkstudent Softwareentwicklung ML Computer Vision im KI Startup',\n",
       "       'Werkstudent:in / Studentische Hilfskraft im Bereich Energie, Verkehr und Infrastruktur',\n",
       "       'Werkstudent:in Datascience',\n",
       "       'Werkstudent:in – Business Analyst (Energy)',\n",
       "       'Wirtschaftsinformatiker für Demand Planning Diagnostics',\n",
       "       'Wissenschaftliche/r Mitarbeiter/in  | Thermomechanische Simulation',\n",
       "       'Wissenschaftlicher Mitarbeiter  Pharmakovigilanz',\n",
       "       'Working Student  Digital Product Management AurumCars',\n",
       "       'Working Student  Partner Management AurumCars',\n",
       "       'Working Student  – Customer Intelligence',\n",
       "       'Working Student (part-time) or Internship (full-time) QA and Testing',\n",
       "       'Working Student - Data Annotator',\n",
       "       'Working Student - Patient Insights',\n",
       "       'Working Student - Software Development',\n",
       "       'Working Student Data Analytics  SURU',\n",
       "       'Working Student PV Performance Engineering',\n",
       "       'Working student in Clinical Data Management',\n",
       "       'Working student software development',\n",
       "       '_Softwareentwicklung Jobs im Landkreis Bodenseekreis'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See if category \"Other\" could potentially be further classified (does not seem to be the case).\n",
    "df.loc[df[\"title_short_ChatGPT3\"] == \"Other\", \"title_clean\"].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['(Associate) Consultant (Gen) AI & Data Scientist | AI Garage',\n",
       "       '(Junior) Consultant Data Science & Artificial Intelligence',\n",
       "       '(Junior) Data Scientist', '(Sen.) Data Scientist',\n",
       "       '(Senior) Consultant Data Science & MLOp/m',\n",
       "       '(Senior) Consultant Data Science Time-Series & Forecasting  (Data Scientist)',\n",
       "       '(Senior) Data Analyst / Data Scientist  in Data Division',\n",
       "       '(Senior) Data Scientist',\n",
       "       '(Senior) Data Scientist  Internationales Team',\n",
       "       '(Senior) Data Scientist  in München',\n",
       "       '(Senior) Data Scientist  with Spanish language skills',\n",
       "       '(Senior) Data Scientist  – Schwerpunkt Predictive Modelling und GenAI ab 01.04.25',\n",
       "       '(Senior) Data Scientist (Analytics), Merchant',\n",
       "       '(Senior) Data Scientist - Document and Text Analytics',\n",
       "       '(Senior) Data Scientist / ML Engineer',\n",
       "       '(Senior) Data Scientist / Researcher',\n",
       "       '(Senior) Data Scientist Analytics',\n",
       "       '(Senior) Data Scientist Health Data Lab',\n",
       "       '(Senior) Data Scientist with focus Clinical Statistics - part/full-time)',\n",
       "       '(Senior) Data Scientist with focus SAS programming - part/full-time)',\n",
       "       '(Senior) Fraud Data Scientist / Data Analyst',\n",
       "       '(Senior) Machine Learning Data Scientist',\n",
       "       '(Senior)Machine Learning Data Scientist',\n",
       "       '(Senior-) Digital Transformation Engineer - Data Science',\n",
       "       '(Wirtschafts-)Mathematiker, Statistiker, Data Scientist für die Tarifentwicklung Komposit',\n",
       "       'ACTUARIAL DATA SCIENTIST', 'AI Engineer / Data Scientist',\n",
       "       'AI Engineer // Data Scientist',\n",
       "       'Aktuar (DAV)/Data Scientist  - Krankenversicherungen & Data Warehouse',\n",
       "       'Analyst - Fokus Data Science / AI',\n",
       "       'Associate Data Science & Management Consultant',\n",
       "       'BI Manager  Data Science/Data Analytics',\n",
       "       'Bachelor  of Science - Data Science und Künstliche Intelligenz - Start 01.09.2025',\n",
       "       'Bachelor  of Science - Wirtschaftsinformatik - Data Science - Start 01.09.2025',\n",
       "       'Bachelor of Science  - Data Science und Künstliche Intelligenz ab 01.09.2025',\n",
       "       'Bachelor of Science  Data Science und Künstliche Intelligenz, Start 2026',\n",
       "       'Bachelor of Science (DHBW) Data Science / Künstliche Intelligenz  am Standort Winnenden 2025',\n",
       "       'Bachelor of Science (DHBW) Wirtschaftsinformatik - Data Science am Standort Obersontheim 2025',\n",
       "       'Binance Accelarator Program - LLM Data Scientist',\n",
       "       'Business Analyst  - im Team Data Science Solutions',\n",
       "       'Business Relationship Manager BI and Data Science',\n",
       "       'CO-Data Scientist',\n",
       "       'Consultant AI & Data Analytics / Data Science',\n",
       "       'Consultant AI & Data Analytics / Data Science  in Berlin',\n",
       "       'Consultant AI & Data Analytics / Data Science  in Frankfurt (Main)',\n",
       "       'Consultant AI & Data Analytics / Data Science  in Hamburg',\n",
       "       'Consultant AI & Data Analytics / Data Science  in München',\n",
       "       'Consultant Data Science Credit Risk  in Berlin',\n",
       "       'Consultant | Senior Consultant  Data Scientist in Credit Risk Management',\n",
       "       'DATA SCIENCE MANAGER*', 'DATA SCIENTIST',\n",
       "       'DATA SCIENTIST  SMART PROCESS AUTOMATION',\n",
       "       'DATA SCIENTIST ENGINEER  DIGITAL SOLUTIONS – BRAUNSCHWEIG, BERLIN',\n",
       "       'DH-STUDIERENDE FÜR DATA SCIENCE & KÜNSTLICHE INTELLIGENZ 2025',\n",
       "       'Data Analysis / Data Engineering / Data Science',\n",
       "       'Data Analyst / Data Scientist',\n",
       "       'Data Architekt / Data Engineer / Data Scientist',\n",
       "       'Data Engineer / Data Scientist',\n",
       "       'Data Science & Engineering Lehrassistent:in (Pflichtpraktikum, Werkstudententätigkeit)',\n",
       "       'Data Science Analyst', 'Data Science Consultant',\n",
       "       'Data Science Consultant - QuantumBlack, AI by McKinsey',\n",
       "       'Data Science Graduate', 'Data Science Intern',\n",
       "       'Data Science Intern - Intelligence Automation (Remote)',\n",
       "       'Data Science Intern - Summer 2025, EMEA (Remote)',\n",
       "       'Data Science Lead - Credit Risk',\n",
       "       'Data Science and AI Mentor (Freelance, Remote)',\n",
       "       'Data Science und KI - Smart Operations Management',\n",
       "       'Data Scientist', 'Data Scientist  (Data Scientist)',\n",
       "       'Data Scientist  (Job-ID 2023061)', 'Data Scientist  (Junior)',\n",
       "       'Data Scientist  - Schwerpunkt Customer Intelligence',\n",
       "       'Data Scientist  - Sektion für Hämatologische Spezialdiagnostik',\n",
       "       'Data Scientist  Short-Term Asset Trading',\n",
       "       'Data Scientist  Smart Process Automation',\n",
       "       'Data Scientist  in Hamburg | EPROFESSIONAL',\n",
       "       'Data Scientist  in den Bereichen NLP und LLM (Entwicklung/ Betrieb, Kompetenzaufbau und Support)',\n",
       "       'Data Scientist  mit Fokus auf Big Data und KI',\n",
       "       'Data Scientist  zur Auswertung und Analyse von komplexen Messdaten',\n",
       "       'Data Scientist & Machine Learning Engineer',\n",
       "       'Data Scientist (Growth Team)',\n",
       "       'Data Scientist (alle Geschlechter)',\n",
       "       'Data Scientist (jun. / sen.)', 'Data Scientist (mwd)',\n",
       "       'Data Scientist - 24 month contract',\n",
       "       'Data Scientist - Consumer (Global Discovery)',\n",
       "       'Data Scientist - Customer Data Platform',\n",
       "       'Data Scientist - Customer Success Projects (ValueWorks)',\n",
       "       'Data Scientist - Data Engineering',\n",
       "       'Data Scientist - Datenmanagement - AOK Bayern - Die Gesundheitskasse',\n",
       "       'Data Scientist - LLM', 'Data Scientist - Lexware Office',\n",
       "       'Data Scientist - Portfolio Analyst & Product Owner *',\n",
       "       'Data Scientist - Process Mining', 'Data Scientist - Ranking',\n",
       "       'Data Scientist - Startup Berlin',\n",
       "       'Data Scientist - Supply Chain & Procurement',\n",
       "       'Data Scientist - Time Estimations, Logistics',\n",
       "       'Data Scientist / AI Developer', 'Data Scientist / Analyst',\n",
       "       'Data Scientist / Biostatistician',\n",
       "       'Data Scientist / Data Analyst',\n",
       "       'Data Scientist / Data Engineer (Python)',\n",
       "       'Data Scientist / Engineer',\n",
       "       'Data Scientist / Engineer mit LLM-Fokus',\n",
       "       'Data Scientist / ML Engineer',\n",
       "       'Data Scientist / Machine Learning Expert',\n",
       "       'Data Scientist / Softwareentwickler', 'Data Scientist 100%',\n",
       "       'Data Scientist Automotive', 'Data Scientist Consultant',\n",
       "       'Data Scientist Datenmanagement',\n",
       "       'Data Scientist Digital Health ‒ Strategie, Analyse & Infrastruktur',\n",
       "       'Data Scientist Intern',\n",
       "       'Data Scientist Lead and Team Lead \"Customer Intelligence Team\"',\n",
       "       'Data Scientist NLP and Text Mining',\n",
       "       'Data Scientist Natural Language Processing',\n",
       "       'Data Scientist Online Analytics',\n",
       "       'Data Scientist Optical Spectroscopy',\n",
       "       'Data Scientist Pathologisches Institut',\n",
       "       'Data Scientist Trainee Life and Health Reinsurance, 1792',\n",
       "       'Data Scientist als Modellentwickler Einsatzplanung Energiesysteme',\n",
       "       'Data Scientist and Process Mining Architect',\n",
       "       'Data Scientist für das Pathologische Institut',\n",
       "       'Data Scientist in Energy Tech Start Up - hybrid Berlin based',\n",
       "       'Data Scientist mit Fokus auf datengetriebenes Marketing',\n",
       "       'Data Scientist mit Schwerpunkt Datenarbeit',\n",
       "       'Data Scientist mit Schwerpunkt Operationalisierung',\n",
       "       'Data Scientist with focus Clinical Statistics - part/full-time)',\n",
       "       'Data Scientist – AI Engineer',\n",
       "       'Data Scientist – CRM / Kundenbeziehungsmanagement',\n",
       "       'Data Scientist – Supply & Demand Modelling', 'Data Scientist*in',\n",
       "       'Data Scientist*in  - remote oder Karlsruhe',\n",
       "       'Data Scientist*in/Data Analyst*in',\n",
       "       'Data Scientist, Germany - BCG X',\n",
       "       'Data Scientist, Internship, Germany - BCG X',\n",
       "       'Data Scientist, Mathematiker - Dateningenieur - AOK Bayern - Die Gesundheitskasse',\n",
       "       'Data Scientist/ AI-Architekt',\n",
       "       'Data Scientist/Analyst prüfungsnahe Beratung/Quants - Assurance (Financial Services)',\n",
       "       'Data Scientist/Bioinformatiker im Team Molekulargenetik',\n",
       "       'Data Scientist/ML Engineer', 'Digital Data Scientist',\n",
       "       'Director of Data Science',\n",
       "       'Doktorand:in – Untersuchung der Rolle zukünftiger Energietechnologien mit Hilfe von Natural Language Processing und Data Science',\n",
       "       'Duales Studium Bachelor of Science in Data Science und Künstlicher Intelligenz , ab 09/2025',\n",
       "       'Duales Studium – Data Science und Künstliche Intelligenz',\n",
       "       'Forecasting Data Scientist SCM',\n",
       "       'Full-Stack Data Analytics/Data Science Expert im Competence Center Digital Accelerator /x)',\n",
       "       'GenAI-Developer/Data Scientist', 'Genomics Data Scientist',\n",
       "       'Geospatial Data Scientist with focus on remote sensing',\n",
       "       'Gesundheitsökonom / Data Scientist im Gesundheitswesen',\n",
       "       'Head of Data Science', 'Head of Data Science and AI',\n",
       "       'IT Entwickler / Data Scientist  – Systembetrieb (befristet auf 2 Jahre)',\n",
       "       'Initiativbewerbung Data Science /BI',\n",
       "       'Intern  - Data Science in a Smart Energy Startup',\n",
       "       'Intern Consultant Data Science and AI *',\n",
       "       'Intern Data Science & AI',\n",
       "       'Intern Data Science - Digital Product Offering',\n",
       "       'Intern Data Science - Vehicle Testing Strategies',\n",
       "       'Intern Data Science - Web & Commerce Analytics',\n",
       "       'Intern/WS - Product Data Science',\n",
       "       'Internship Clinical Data Science with focus on Bayesian Statistics',\n",
       "       'Internship Data Science & Data Visualization',\n",
       "       'Junior Aktuar / Data Scientist für das Pricing Aktuariat',\n",
       "       'Junior Aktuar/Actuarial Data Scientist Non-Motor Köln',\n",
       "       'Junior Blockchain Data Scientist', 'Junior Data Scientist',\n",
       "       'Junior Data Scientist  - Tableau', 'Junior Data Scientist  Reise',\n",
       "       'Junior Data Scientist (Data Scientist)',\n",
       "       'Junior Data Scientist / AI Developer',\n",
       "       'Junior Data Scientist Controller',\n",
       "       'Junior Data Scientist Controller  [JR105592]',\n",
       "       'KI Data Scientist', 'Lead Data Scientist',\n",
       "       'Lead Data Scientist (Deep Learning)', 'Lead Data Scientist NLP',\n",
       "       'Lead Data Scientist, Insurance - BCG X',\n",
       "       'ML Software Engineer / Data Scientist',\n",
       "       'Masterarbeit im Bereich Data Science und AI Development ab Januar 2025',\n",
       "       'Masterprogramm Data Science & Business Analytics',\n",
       "       'PRAKTIKUM / PRAXISSEMESTER IM BEREICH DATA SCIENCE',\n",
       "       'Post Doc - Data Science in Drug Discovery',\n",
       "       'Praktikant  Data Science',\n",
       "       'Praktikant Data Science/Data Analytics',\n",
       "       'Praktikant*in Data Engineer / Data Scientist Cloud Analytics',\n",
       "       'Praktikant:in  im Bereich Data Science und Prozesssoptimierung',\n",
       "       'Praktikum Data Science (Schwerpunkt Machine Learning)',\n",
       "       'Praktikum Data Science / Analytics',\n",
       "       'Praktikum Data Science im Bereich Preis-, Immobilienmarkt- und Konjunkturstatistiken',\n",
       "       'Praktikum Data Scientist im Produktkomplexitätsmanagement',\n",
       "       'Praktikum im Bereich Data Science / Data Analytics',\n",
       "       'Praktikum: Data Science', 'Praktikum: Data Science und KI',\n",
       "       'Principal Data Scientist',\n",
       "       'Principal Data Scientist - Media Measurement',\n",
       "       'Principal Data Scientist \\\\u007C Pricing',\n",
       "       'Product Data Science Managers', 'Professor for Data Science',\n",
       "       'Projektingenieur - Data Scientist',\n",
       "       'Projektmanager AI & Data Science',\n",
       "       'Publicis Media - (Junior) Data Scientist',\n",
       "       'Python Developer / Data Scientist - Remote or Berlin based',\n",
       "       'R&D Internship – Data Science, ML and AI',\n",
       "       'Remote (Sr.) Python Data Scientist',\n",
       "       'Research Associate for the Project “DASHH - Data Science in Hamburg - Helmholtz Graduate School for the Structure of Matter, dAIbetes” § 28 Subsection 3 HmbHG',\n",
       "       'Research assistant  - Department of Mathematics and Natural Science - Mathematics of Data Science Group - ID 142/2024',\n",
       "       'SENIOR DATA SCIENTIST', 'Senior AI & Data Science Consultant',\n",
       "       'Senior Consultant / Manager (Gen) AI & Data Scientist | AI Garage',\n",
       "       'Senior Controlling Data Scientist',\n",
       "       'Senior Data Science Consultant', 'Senior Data Scientist',\n",
       "       'Senior Data Scientist  - Business Intelligence Application',\n",
       "       'Senior Data Scientist  - ID: 233',\n",
       "       'Senior Data Scientist  - Large-scale Machine Learning',\n",
       "       'Senior Data Scientist  NLP in München',\n",
       "       'Senior Data Scientist  im Automotive Bereich',\n",
       "       'Senior Data Scientist  | hybrid (office/remote)',\n",
       "       'Senior Data Scientist  – Risikomodelle',\n",
       "       'Senior Data Scientist (Recommendation Systems Expert)',\n",
       "       'Senior Data Scientist (SOC / carbon modelling)',\n",
       "       'Senior Data Scientist (mwd)',\n",
       "       'Senior Data Scientist * Generative AI',\n",
       "       'Senior Data Scientist - Conversational AI (German Speaking) - AI Teams',\n",
       "       'Senior Data Scientist - Data & AI',\n",
       "       'Senior Data Scientist - Fraud & Credit Risk',\n",
       "       'Senior Data Scientist - Operations Research',\n",
       "       'Senior Data Scientist - Remote from Germany',\n",
       "       'Senior Data Scientist - Time Estimations, Logistics',\n",
       "       'Senior Data Scientist / AI Developer',\n",
       "       'Senior Data Scientist / Senior Software Technology Engineer',\n",
       "       'Senior Data Scientist / Senior Software Technology Engineer*',\n",
       "       'Senior Data Scientist Generative AI',\n",
       "       'Senior Data Scientist NLP/GenAI',\n",
       "       'Senior Data Scientist for Innovative Digital Product',\n",
       "       'Senior Data Scientist mit Schwerpunkt Ökonometrie/ Predictive Analytics',\n",
       "       'Senior Data Scientist – Energy Storage / Li-ion / Battery Technologies',\n",
       "       'Senior Data Scientist – Supply & Demand Modelling',\n",
       "       'Senior Data Scientist, AI-Experte für Natural Language Processing',\n",
       "       'Senior Data Scientist, Campaigns',\n",
       "       'Senior Data Scientist, Payments Product',\n",
       "       'Senior Data Scientist, gTech Ads',\n",
       "       'Senior Data Scientist- Optimization',\n",
       "       'Senior Essential Adoption Service Consultant  - Data Science, Automation & Technology',\n",
       "       'Senior Full-Stack Data Analytics/Data Science Expert*in im Competence Center Digital Accelerator im Mercedes-Benz Management Consulting /x)',\n",
       "       'Senior Machine Learning Data Scientist',\n",
       "       'Senior People Data Scientist (All genders) - Global People Analytics team',\n",
       "       'Senior Specialist/Data Scientist OSS Analytics in Voll- und Teilzeit',\n",
       "       'Software Engineer mit Data Science Background',\n",
       "       'Spezialist  Data Engineering & Data Science',\n",
       "       'Spezialist Risikocontrolling CO2-Accounting / Data Scientist',\n",
       "       'Sr Data Scientist - LLM', 'Staff Data Scientist',\n",
       "       'Staff Data Scientist - Ad Tech',\n",
       "       'Staff Data Scientist - Consumer Insights & Marketing Technology (CIMT) ( All genders )',\n",
       "       'Staff Data Scientist, Investment Modelling',\n",
       "       'Student Data Scientist',\n",
       "       'Student Engineering, Natural Sciences, Data Science or similar',\n",
       "       'Team Lead Data Scientist',\n",
       "       'Teamlead Data Science und Data Engineering',\n",
       "       'Technical Investigator / Data Scientist - AI Safety',\n",
       "       'Trainee  - Data Analyst / Data Scientist',\n",
       "       'Trainee Data Science  - 12 Monate',\n",
       "       'Trainee Data Science  – Fokus NLP',\n",
       "       'Trainee Data Scientist Personen-Rückversicherung',\n",
       "       'Trainee Data Scientist Personen-Rückversicherung, 1792',\n",
       "       'VPP Modeling Engineer / Data Scientist',\n",
       "       'WERKSTUDENT*IN IM BEREICH DATA SCIENCE',\n",
       "       'Werkstudent  Data Science', 'Werkstudent Data Science',\n",
       "       'Werkstudent Data Science & Machine Learning - IIoT Projekte',\n",
       "       'Werkstudent Data Science / Data Engineering',\n",
       "       'Werkstudent Data Scientist',\n",
       "       'Werkstudent Fixed Income Data Scientist',\n",
       "       'Werkstudent Python im Bereich Data Science',\n",
       "       'Werkstudent/Praktikant im Bereich Data Science/Analytics & AI',\n",
       "       'Werkstudent:in  im Bereich Data Science und Prozesssoptimierung',\n",
       "       'Werkstudent:in Data Science',\n",
       "       'Werkstudententätigkeit als Business Data Scientist',\n",
       "       'Werkstudierende - Tutoring im Data Science',\n",
       "       'Working Student  Data Science',\n",
       "       'Working Student  Trading & Risk Management Data Scientist',\n",
       "       'Working Student - Data Scientist and Process Mining Architect',\n",
       "       'Working Student / Internship – Data Scientist',\n",
       "       'Working Student Aerospace Data Science',\n",
       "       'Working Student Data Science & Data Engineering',\n",
       "       'Working Student Data Science - Aerospace',\n",
       "       'Working Student Data Science and Data Engineering',\n",
       "       'Working Student: Data Science and Data Analytics',\n",
       "       'Working student in Data Science starting January 2025',\n",
       "       'eine/n Data Scientist/in'], dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if category \"Data Scientist\" is accurate (seems to be the case!)\n",
    "df.loc[df[\"title_short_ChatGPT3\"] == \"Data Scientist\", \"title_clean\"].sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "After refining the initial prompt twice, the resulting categorization seems satisfactory for my use-case. \n",
    "\n",
    "Hence, the final function *updated_categorize_job_title* will be used (results stored in df[\"title_short_ChatGPT3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of days online (grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "days_online_grouped\n",
       "0-7      389\n",
       "N/A      334\n",
       "8-14     233\n",
       "29+      204\n",
       "15-21    177\n",
       "22-28     95\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def days_online_grouping(x):\n",
    "    if x <= 7: return \"0-7\"\n",
    "    if x <= 14: return \"8-14\"\n",
    "    if x <= 21: return \"15-21\"\n",
    "    if x <= 28: return \"22-28\"\n",
    "    if x > 28: return \"29+\"\n",
    "    if pd.isna(x): return \"N/A\"\n",
    "\n",
    "df[\"days_online_grouped\"] = df[\"days_online\"].apply(days_online_grouping)\n",
    "df[\"days_online_grouped\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tech Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Company DescriptionFascinated by the future an...\n",
       "1    Xsolla is looking for a Junior Data Scientist ...\n",
       "2    GMS is an operational consultancy with experti...\n",
       "3    Your missionPropose innovative solutions by ex...\n",
       "4    The target of vent.io is to accelerate the gro...\n",
       "Name: job_description_anonymized, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"job_description_anonymized\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean white space characters (e.g. \"\\n\") and non-word characters (i.e. \"?/!/:/./...\")\n",
    "df[\"job_description_for_search\"] = df[\"job_description_anonymized\"].replace(r\"[\\s\\W]\", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Company DescriptionFascinated by the future an...\n",
       "1    Xsolla is looking for a Junior Data Scientist ...\n",
       "2    GMS is an operational consultancy with experti...\n",
       "3    Your missionPropose innovative solutions by ex...\n",
       "4    The target of vent io is to accelerate the gro...\n",
       "Name: job_description_for_search, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"job_description_for_search\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python            891\n",
      "julia             19\n",
      "spss              9\n",
      "stata             5\n",
      "javascript        52\n",
      "sql|postgre       548\n",
      "azure             236\n",
      "gcp|google cloud  160\n",
      "powerbi|power bi  199\n",
      "tableau           161\n",
      "qlik              59\n",
      "alteryx           11\n",
      "docker            110\n",
      "rust              11\n",
      "sas               42\n",
      "excel             148\n",
      "aws|amazon web    285\n",
      "git|github        157\n",
      "java              146\n",
      "R                 309\n"
     ]
    }
   ],
   "source": [
    "# Define search terms and create a dummy-variable for each tech stack.\n",
    "search_terms_clear = [\n",
    "    \"python\",\n",
    "    \"julia\",\n",
    "    \"spss\",\n",
    "    \"stata\",\n",
    "    \"javascript\",\n",
    "    \"sql|postgre\",\n",
    "    \"azure\",\n",
    "    \"gcp|google cloud\",\n",
    "    \"powerbi|power bi\",\n",
    "    \"tableau\",\n",
    "    \"qlik\",\n",
    "    \"alteryx\",\n",
    "    \"docker\",\n",
    "]\n",
    "\n",
    "# Some search terms are ambigous, i.e. undesired search results may appear.\n",
    "# These will be wrapped in blanks to ensure that the term matches exact.\n",
    "search_terms_ambiguous = [\n",
    "    \"rust\",             # e.g. \"trust\"\n",
    "    \"sas\",\n",
    "    \"excel\",            # e.g. \"excellent\"\n",
    "    \"aws|amazon web\",   # e.g. \"laws\"\n",
    "    \"git|github\",\n",
    "    \"java\",             # \"javascript\"\n",
    "]\n",
    "\n",
    "# combine all search terms, specify search mode\n",
    "search_terms = {search_term: \"clear\" for search_term in search_terms_clear}\n",
    "search_terms.update({search_term: \"ambigous\" for search_term in search_terms_ambiguous})\n",
    "\n",
    "\n",
    "# Run search / column creation:\n",
    "for search_term, search_mode in search_terms.items():\n",
    "    # determine column name; if multiple terms are listed, use first one\n",
    "    if len(search_term.split(\"|\")) > 0:\n",
    "        col_name = f\"tech_stack_{search_term.split('|')[0]}\"\n",
    "    else:\n",
    "        col_name = f\"tech_stack_{search_term}\"\n",
    "    # determine search mode; if ambigous, wrap searchterm in blanks\n",
    "    if search_mode == \"clear\":\n",
    "        search_string = f\"{search_term}\"\n",
    "    else:\n",
    "        search_string = f\" {search_term} \"\n",
    "\n",
    "    df[col_name] = df[\"job_description_for_search\"].str.lower().str.contains(search_string, regex=True).astype(int)\n",
    "\n",
    "    print(f\"{search_string.strip():18}{sum(df[col_name])}\")\n",
    "\n",
    "# R\n",
    "df[\"tech_stack_r\"] = df[\"job_description_for_search\"].str.contains(\" R \").astype(int)\n",
    "print(f'{\"R\":18}{sum(df[\"tech_stack_r\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tech_stack_python</th>\n",
       "      <td>891</td>\n",
       "      <td>0.622207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_julia</th>\n",
       "      <td>19</td>\n",
       "      <td>0.013268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_spss</th>\n",
       "      <td>9</td>\n",
       "      <td>0.006285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_stata</th>\n",
       "      <td>5</td>\n",
       "      <td>0.003492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_javascript</th>\n",
       "      <td>52</td>\n",
       "      <td>0.036313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_sql</th>\n",
       "      <td>548</td>\n",
       "      <td>0.382682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_azure</th>\n",
       "      <td>236</td>\n",
       "      <td>0.164804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_gcp</th>\n",
       "      <td>160</td>\n",
       "      <td>0.111732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_powerbi</th>\n",
       "      <td>199</td>\n",
       "      <td>0.138966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_tableau</th>\n",
       "      <td>161</td>\n",
       "      <td>0.112430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_qlik</th>\n",
       "      <td>59</td>\n",
       "      <td>0.041201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_alteryx</th>\n",
       "      <td>11</td>\n",
       "      <td>0.007682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_docker</th>\n",
       "      <td>110</td>\n",
       "      <td>0.076816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_rust</th>\n",
       "      <td>11</td>\n",
       "      <td>0.007682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_sas</th>\n",
       "      <td>42</td>\n",
       "      <td>0.029330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_excel</th>\n",
       "      <td>148</td>\n",
       "      <td>0.103352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_aws</th>\n",
       "      <td>285</td>\n",
       "      <td>0.199022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_git</th>\n",
       "      <td>157</td>\n",
       "      <td>0.109637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_java</th>\n",
       "      <td>146</td>\n",
       "      <td>0.101955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_stack_r</th>\n",
       "      <td>309</td>\n",
       "      <td>0.215782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         n         %\n",
       "tech_stack_python      891  0.622207\n",
       "tech_stack_julia        19  0.013268\n",
       "tech_stack_spss          9  0.006285\n",
       "tech_stack_stata         5  0.003492\n",
       "tech_stack_javascript   52  0.036313\n",
       "tech_stack_sql         548  0.382682\n",
       "tech_stack_azure       236  0.164804\n",
       "tech_stack_gcp         160  0.111732\n",
       "tech_stack_powerbi     199  0.138966\n",
       "tech_stack_tableau     161  0.112430\n",
       "tech_stack_qlik         59  0.041201\n",
       "tech_stack_alteryx      11  0.007682\n",
       "tech_stack_docker      110  0.076816\n",
       "tech_stack_rust         11  0.007682\n",
       "tech_stack_sas          42  0.029330\n",
       "tech_stack_excel       148  0.103352\n",
       "tech_stack_aws         285  0.199022\n",
       "tech_stack_git         157  0.109637\n",
       "tech_stack_java        146  0.101955\n",
       "tech_stack_r           309  0.215782"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"n\": df.filter(like=\"tech_stack\").sum(),\n",
    "              \"%\": df.filter(like=\"tech_stack\").mean()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods / Concepts (TBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include search words like \"pytorch\", \"random forest\", \"deep learning\", \"ML\", \"AI\", \"NLP\", ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location 2 - Geodata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get long and lat for locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIREMENTS (for using Nominatim)\n",
    "\n",
    "# No heavy uses (an absolute maximum of 1 request per second).\n",
    "# Provide a valid HTTP Referer or User-Agent identifying the application (stock User-Agents as set by http libraries will not do).\n",
    "# Clearly display attribution as suitable for your medium.\n",
    "# Data is provided under the ODbL license which requires to share alike (although small extractions are likely to be covered by fair usage / fair dealing).\n",
    "\n",
    "# Source: https://operations.osmfoundation.org/policies/nominatim/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To minimize requests, the following lines of code will be executed only once. Results will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geolocator = Nominatim(user_agent='job_detail_analysis')\n",
    "\n",
    "# locations = df[\"location\"].unique()\n",
    "\n",
    "# location_long_lat_dict = {loc: None for loc in locations}\n",
    "\n",
    "# for nr, loc in enumerate(locations):\n",
    "#     if nr % 10 == 0: print(f\"Grabbing geodata for location {nr}/{len(locations)}\")\n",
    "#     location = geolocator.geocode(loc)\n",
    "#     long_lat = tuple([location.latitude, location.longitude])\n",
    "#     location_long_lat_dict[loc] = long_lat\n",
    "#     time.sleep(1)\n",
    "\n",
    "# location_long_lat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store geodata as pkl in order to not have to run the geolocator above again\n",
    "\n",
    "# with open(f'location_long_lat_dict.pkl', 'wb') as f:\n",
    "#        pickle.dump(location_long_lat_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load geodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Berlin': (52.510885, 13.3989367),\n",
       " 'Frankfurt am Main': (50.1106444, 8.6820917),\n",
       " 'Bremen': (53.0758196, 8.8071646),\n",
       " 'Coburg': (50.2582226, 10.964561),\n",
       " 'Tübingen': (48.5203263, 9.053596),\n",
       " 'Hamburg': (53.550341, 10.000654),\n",
       " 'München': (48.1371079, 11.5753822),\n",
       " 'Deutschland': (51.1638175, 10.4478313),\n",
       " 'Freiburg': (47.9960901, 7.8494005),\n",
       " 'Leipzig': (51.3406321, 12.3747329),\n",
       " 'Heidelberg': (49.4093582, 8.694724),\n",
       " 'Hessen': (50.6080651, 9.0284647),\n",
       " 'Dresden': (51.0493286, 13.7381437),\n",
       " 'Heilbronn': (49.142291, 9.218655),\n",
       " 'Schwalbach': (50.1490109, 8.5357434),\n",
       " 'Eschborn': (50.1504737, 8.5607767),\n",
       " 'Kronberg': (50.1907271, 8.5194693),\n",
       " 'Hannover': (52.3744779, 9.7385532),\n",
       " 'Potsdam': (52.4009309, 13.0591397),\n",
       " 'Nordrhein-Westfalen': (51.4789205, 7.5543751),\n",
       " 'Düsseldorf': (51.2254018, 6.7763137),\n",
       " 'Hürth': (50.8807379, 6.876568),\n",
       " 'Aschheim': (48.1713481, 11.7160347),\n",
       " 'Köln': (50.938361, 6.959974),\n",
       " 'Karlsruhe': (49.0068705, 8.4034195),\n",
       " 'Essen': (51.4582235, 7.0158171),\n",
       " 'Weil am Rhein': (47.5932802, 7.6116133),\n",
       " 'Holm': (54.8333047, 8.8666675),\n",
       " 'Sulzbach': (48.0356915, 7.2011423),\n",
       " 'Weikersheim': (49.4806, 9.905),\n",
       " 'Ottobrunn': (48.0648406, 11.6647814),\n",
       " 'Baden-Württemberg': (48.53775, 9.041169),\n",
       " 'Stuttgart': (48.7784485, 9.1800132),\n",
       " 'Saarbrücken': (49.234362, 6.996379),\n",
       " 'Detmold': (51.936284, 8.8791526),\n",
       " 'Bad Salzuflen': (52.0771518, 8.7554739),\n",
       " 'Fürth': (49.488571050000004, 10.95872031326412),\n",
       " 'Darmstadt': (49.8851869, 8.6736295),\n",
       " 'Würzburg': (49.7780356, 9.943476907125579),\n",
       " 'Fellbach': (48.8181556, 9.278085),\n",
       " 'Dorsten': (51.6604071, 6.9647431),\n",
       " 'Wuppertal': (51.264018, 7.1780374),\n",
       " 'Dortmund': (51.5142273, 7.4652789),\n",
       " 'Aachen': (50.776351, 6.083862),\n",
       " 'Wesel': (51.6576909, 6.617087),\n",
       " 'Grünheide': (52.4262298, 13.8226458),\n",
       " 'Lampertheim': (48.6503574, 7.7003567),\n",
       " 'Kiel': (54.3227085, 10.135555),\n",
       " 'Mannheim': (49.4892913, 8.4673098),\n",
       " 'Winnenden': (48.8754571, 9.3978478),\n",
       " 'Bielefeld': (52.0191005, 8.531007),\n",
       " 'Bad Homburg': (50.2363508, 8.5980265),\n",
       " 'Neuenstadt am Kocher': (49.2361584, 9.3293362),\n",
       " 'Bonn': (50.7352621, 7.1024635),\n",
       " 'Lübbecke': (52.3027209, 8.6183054),\n",
       " 'Ludwigshafen': (49.4704113, 8.4381568),\n",
       " 'Schrobenhausen': (48.5613407, 11.2654488),\n",
       " 'Arnstorf': (48.5635093, 12.8173993),\n",
       " 'Lübeck': (53.866444, 10.684738),\n",
       " 'Ilmenau': (50.6867695, 10.9142385),\n",
       " 'Nürnberg': (49.453872, 11.077298),\n",
       " 'Krailling': (48.0992621, 11.4050891),\n",
       " 'Neuried': (48.466604, 7.817298),\n",
       " 'Salzgitter': (52.1503721, 10.3593147),\n",
       " 'Erlangen': (49.589157099999994, 10.98120719922546),\n",
       " 'Augsburg': (48.3690341, 10.8979522),\n",
       " 'Clausthal-Zellerfeld': (51.8070405, 10.3364483),\n",
       " 'Verl': (51.8830037, 8.5093149),\n",
       " 'Weeze': (51.6267298, 6.2011559),\n",
       " 'Weinheim': (49.5462349, 8.6717458),\n",
       " 'Neuwied': (50.4302393, 7.466302),\n",
       " 'Mülheim an der Ruhr': (51.4272925, 6.8829192),\n",
       " 'Bergisch Gladbach': (50.9929303, 7.1277379),\n",
       " 'Esch': (49.8975651, 6.8502714),\n",
       " 'Bayreuth': (49.9427202, 11.5763079),\n",
       " 'Konstanz': (47.659216, 9.1750718),\n",
       " 'Bremerhaven': (53.5505392, 8.5851945),\n",
       " 'Mailand': (45.4641943, 9.1896346),\n",
       " 'Kassel': (51.3157833, 9.4978479),\n",
       " 'Ulm': (48.3984968, 9.9912458),\n",
       " 'Münster': (51.9625101, 7.6251879),\n",
       " 'Straubing': (48.8839157, 12.595577296431395),\n",
       " 'Zweibrücken': (49.248655, 7.3641981),\n",
       " 'Obersontheim': (49.057508, 9.8981122),\n",
       " 'Mainz': (49.9995205, 8.2736253),\n",
       " 'Immenstadt': (47.55911, 10.2137986),\n",
       " 'Attenkirchen': (48.5057366, 11.7601946),\n",
       " 'Oldenburg': (53.1389753, 8.2146017),\n",
       " 'Braunschweig': (52.2646577, 10.5236066),\n",
       " 'Gütersloh': (51.9063997, 8.3782078),\n",
       " 'Sankt Augustin': (50.7752776, 7.1895507),\n",
       " 'Ingelfingen': (49.3014449, 9.6513353),\n",
       " 'Kempten': (47.7267063, 10.3168835),\n",
       " 'Offingen': (48.482932, 10.3639517),\n",
       " 'Garching': (48.2513878, 11.6509662),\n",
       " 'Gerlingen': (48.7983947, 9.0624386),\n",
       " 'Hechingen': (48.3525529, 8.9642047),\n",
       " 'Regensburg': (49.0195333, 12.0974869),\n",
       " 'Ebermannstadt': (49.7802113, 11.1875112),\n",
       " 'Ingolstadt': (48.7630165, 11.4250395),\n",
       " 'Gunzenhausen': (49.1147095, 10.7545933),\n",
       " 'Duisburg': (51.434999, 6.759562),\n",
       " 'Biberach an der Riß': (48.0984413, 9.7899938),\n",
       " 'Burgdorf': (47.0571316, 7.6237466),\n",
       " 'Vallendar': (50.4001381, 7.6142479),\n",
       " 'Urbar': (50.1309049, 7.7197143),\n",
       " 'Buch': (50.2051609, 7.8759628),\n",
       " 'Gießen': (50.5862066, 8.6742306),\n",
       " 'Büren': (51.5525333, 8.5591919),\n",
       " 'Penzberg': (47.7518502, 11.3763014),\n",
       " 'Neuherberg': (48.221767, 11.5876284),\n",
       " 'Norderstedt': (53.7089898, 9.9891914),\n",
       " 'Gotha': (50.9494849, 10.7014435),\n",
       " 'Siegen': (50.8751175, 8.0256131),\n",
       " 'Königstein im Taunus': (50.195133, 8.4628165),\n",
       " 'Schwäbisch Gmünd': (48.7999036, 9.7977584),\n",
       " 'Bayern': (48.9467562, 11.4038717),\n",
       " 'Wiesbaden': (50.0820384, 8.2416556),\n",
       " 'Lingen': (52.5224659, 7.316584),\n",
       " 'Starnberg': (47.9986851, 11.3410791),\n",
       " 'Ilsenburg': (51.8667349, 10.6831785),\n",
       " 'Damme': (51.2514978, 3.281482),\n",
       " 'Jena': (50.9281717, 11.5879359),\n",
       " 'Marburg an der Lahn': (50.8008565, 8.763151908261287),\n",
       " 'Siegburg': (50.7928332, 7.2070774),\n",
       " 'Rosenberg': (49.0815718, 19.3034168),\n",
       " 'Böblingen': (48.684969, 9.0113444),\n",
       " 'Koblenz': (50.3533278, 7.5943951),\n",
       " 'Homeoffice': (47.4137417, 8.5605328),\n",
       " 'Zeuthen': (52.3507952, 13.629328),\n",
       " 'Bad Berleburg': (51.0478493, 8.3917759),\n",
       " 'Stephanskirchen': (47.8594257, 12.158035),\n",
       " 'Hameln': (52.1039941, 9.3561569),\n",
       " 'Grünwald': (48.0486558, 11.5300727),\n",
       " 'Paderborn': (51.7177044, 8.752653),\n",
       " 'Oberschleißheim': (48.2549383, 11.5546058),\n",
       " 'Harsewinkel': (51.9617153, 8.2252425),\n",
       " 'Schenefeld': (54.0484989, 9.4703368),\n",
       " 'Minden': (52.2881045, 8.9168852),\n",
       " 'Martinsried': (48.10882, 11.4508007),\n",
       " 'Kirchentellinsfurt': (48.5337887, 9.1507197),\n",
       " 'Bochum': (51.4818111, 7.2196635),\n",
       " 'Einbeck': (51.8185067, 9.8678465),\n",
       " 'Grafing bei München': (48.0453808, 11.966071),\n",
       " 'Bad Homburg vor der Höhe': (50.2363508, 8.5980265),\n",
       " 'Straße': (50.8705357, 7.4943548),\n",
       " 'Planegg': (48.103742, 11.4220029),\n",
       " 'Rust': (47.8037042, 16.689014287384975),\n",
       " 'Künsebeck': (52.0366241, 8.3845242),\n",
       " 'Oberkochen': (48.7840324, 10.1060512),\n",
       " 'Trittau': (53.6117462, 10.4043947),\n",
       " 'Coesfeld': (51.9458943, 7.1691108),\n",
       " 'Schwarzenbruck': (49.3554558, 11.2410609),\n",
       " 'Bad Nauheim': (50.3681107, 8.7473608),\n",
       " 'Großwallstadt': (49.8778629, 9.1588408),\n",
       " 'Göttingen': (51.5328328, 9.9351811),\n",
       " 'Obertshausen': (50.0731304, 8.8732839),\n",
       " 'Kulmbach': (50.1008448, 11.4479149),\n",
       " 'Bad Gandersheim': (51.8704732, 10.0297839),\n",
       " 'Hanau': (50.132881, 8.9169797),\n",
       " 'Offenburg': (48.4695984, 7.9429235),\n",
       " 'Nördlingen': (48.8516578, 10.4885873),\n",
       " 'Görlitz': (51.1563185, 14.991018),\n",
       " 'Saterland': (53.0845859, 7.6937446),\n",
       " 'Offenbach': (50.1055002, 8.7610698),\n",
       " 'Ostseebad Kühlungsborn': (54.1483764, 11.7441876),\n",
       " 'Aalen': (48.8375607, 10.0929593),\n",
       " 'Langenselbold': (50.1780814, 9.04333),\n",
       " 'Maintal': (50.1438711, 8.8371266),\n",
       " 'Rosenheim': (47.8539273, 12.127262),\n",
       " 'Puchheim': (48.1704908, 11.3526351),\n",
       " 'Mühlheim am Main': (50.1080582, 8.8467138),\n",
       " 'Rodgau': (50.0176771, 8.8853392),\n",
       " 'Krefeld': (51.3331205, 6.5623343),\n",
       " 'Unterföhring': (48.1950385, 11.6449251),\n",
       " 'Coesfeld-Lette': (51.8986559, 7.1919384),\n",
       " 'Remscheid': (51.1798706, 7.1943544),\n",
       " 'Osnabrück': (52.2719595, 8.047635),\n",
       " 'Frankfurt': (50.1106444, 8.6820917),\n",
       " 'Ettlingen': (48.9414188, 8.4076347),\n",
       " 'Luxembourg': (49.6112768, 6.129799),\n",
       " 'Ahrensburg': (53.6736529, 10.2358999),\n",
       " 'St. Leon-Rot': (49.2671326, 8.6142616),\n",
       " 'Freiburg im Breisgau': (47.9960901, 7.8494005),\n",
       " 'Tettnang': (47.6716558, 9.5891158),\n",
       " 'Wolfsburg': (52.4205588, 10.7861682),\n",
       " 'Jülich': (50.9220931, 6.3611015),\n",
       " 'Schweinfurt': (50.051855200000006, 10.222092114223383),\n",
       " 'Leimen': (49.3491417, 8.6909951),\n",
       " 'Sindelfingen': (48.7084162, 9.0035455),\n",
       " 'Lüneburg': (53.248706, 10.407855),\n",
       " 'Bad Ems': (50.3352062, 7.7128538),\n",
       " 'Neuss': (51.1981778, 6.6916476),\n",
       " 'Innsbruck': (47.2654296, 11.3927685),\n",
       " 'Bensheim': (49.6977, 8.6288),\n",
       " 'Burghausen': (48.1588645, 12.8329419),\n",
       " 'Solingen': (51.1721629, 7.0845893),\n",
       " 'Langenhagen': (52.443118, 9.738994),\n",
       " 'Schwabmünchen': (48.1805562, 10.7578121),\n",
       " 'Kornwestheim': (48.8611498, 9.1873875),\n",
       " 'Gladbeck': (51.5718665, 6.9877343),\n",
       " 'Fischach': (48.2902043, 10.6554555),\n",
       " 'Heidenheim': (48.6767637, 10.152923),\n",
       " 'Hoisdorf': (53.6530061, 10.3186485),\n",
       " 'Monheim am Rhein': (51.0909476, 6.8812387),\n",
       " 'Rheda-Wiedenbrück': (51.8428202, 8.2985615),\n",
       " 'Unterschleißheim': (48.2730686, 11.5702716),\n",
       " 'Traunreut': (47.9623271, 12.5924162),\n",
       " 'Bargteheide': (53.7279671, 10.2618075),\n",
       " 'Westerstede': (53.2575197, 7.9273367),\n",
       " 'Taufkirchen': (48.0459958, 11.6151899),\n",
       " 'Seligenstadt': (50.0347055, 8.9593719),\n",
       " 'Großenlüder': (50.5753618, 9.5502218),\n",
       " 'Münchberg': (50.1911369, 11.7913908)}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open geodata\n",
    "with open(f'location_long_lat_dict.pkl', 'rb') as f:\n",
    "    location_long_lat_dict = pickle.load(f)\n",
    "\n",
    "location_long_lat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"location_lat_long\"] = df[\"location_clean\"].map(location_long_lat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>location_clean</th>\n",
       "      <th>location_lat_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>(52.510885, 13.3989367)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>(52.510885, 13.3989367)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>(50.1106444, 8.6820917)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>(52.510885, 13.3989367)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>(50.1106444, 8.6820917)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Aachen</td>\n",
       "      <td>Aachen</td>\n",
       "      <td>(50.776351, 6.083862)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>Bochum</td>\n",
       "      <td>Bochum</td>\n",
       "      <td>(51.4818111, 7.2196635)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>Coburg</td>\n",
       "      <td>Coburg</td>\n",
       "      <td>(50.2582226, 10.964561)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>Köln</td>\n",
       "      <td>Köln</td>\n",
       "      <td>(50.938361, 6.959974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>(49.6112768, 6.129799)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1432 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               location     location_clean        location_lat_long\n",
       "0                Berlin             Berlin  (52.510885, 13.3989367)\n",
       "1                Berlin             Berlin  (52.510885, 13.3989367)\n",
       "2     Frankfurt am Main  Frankfurt am Main  (50.1106444, 8.6820917)\n",
       "3                Berlin             Berlin  (52.510885, 13.3989367)\n",
       "4     Frankfurt am Main  Frankfurt am Main  (50.1106444, 8.6820917)\n",
       "...                 ...                ...                      ...\n",
       "798              Aachen             Aachen    (50.776351, 6.083862)\n",
       "957              Bochum             Bochum  (51.4818111, 7.2196635)\n",
       "987              Coburg             Coburg  (50.2582226, 10.964561)\n",
       "1596               Köln               Köln    (50.938361, 6.959974)\n",
       "1611         Luxembourg         Luxembourg   (49.6112768, 6.129799)\n",
       "\n",
       "[1432 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(like=\"location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split columns into lat and long\n",
    "df[\"location_lat\"] = df[\"location_lat_long\"].map(lambda x: x[0])\n",
    "df[\"location_long\"] = df[\"location_lat_long\"].map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>location_clean</th>\n",
       "      <th>location_lat_long</th>\n",
       "      <th>location_lat</th>\n",
       "      <th>location_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>(51.1638175, 10.4478313)</td>\n",
       "      <td>51.163818</td>\n",
       "      <td>10.447831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>Tettnang</td>\n",
       "      <td>Tettnang</td>\n",
       "      <td>(47.6716558, 9.5891158)</td>\n",
       "      <td>47.671656</td>\n",
       "      <td>9.589116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>München</td>\n",
       "      <td>München</td>\n",
       "      <td>(48.1371079, 11.5753822)</td>\n",
       "      <td>48.137108</td>\n",
       "      <td>11.575382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Köln</td>\n",
       "      <td>Köln</td>\n",
       "      <td>(50.938361, 6.959974)</td>\n",
       "      <td>50.938361</td>\n",
       "      <td>6.959974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>(52.510885, 13.3989367)</td>\n",
       "      <td>52.510885</td>\n",
       "      <td>13.398937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         location location_clean         location_lat_long  location_lat   \n",
       "133   Deutschland    Deutschland  (51.1638175, 10.4478313)     51.163818  \\\n",
       "1408     Tettnang       Tettnang   (47.6716558, 9.5891158)     47.671656   \n",
       "498       München        München  (48.1371079, 11.5753822)     48.137108   \n",
       "378          Köln           Köln     (50.938361, 6.959974)     50.938361   \n",
       "1205       Berlin         Berlin   (52.510885, 13.3989367)     52.510885   \n",
       "\n",
       "      location_long  \n",
       "133       10.447831  \n",
       "1408       9.589116  \n",
       "498       11.575382  \n",
       "378        6.959974  \n",
       "1205      13.398937  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(like=\"location\").sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'company', 'location', 'salary', 'seniority_level',\n",
       "       'date_posted', 'date_accessed', 'days_online', 'number_applicants',\n",
       "       'job_type_Vollzeit', 'job_type_Teilzeit', 'job_type_Festanstellung',\n",
       "       'job_type_BefristeterVertrag', 'job_type_Homeoffice',\n",
       "       'job_type_FreieMitarbeit', 'job_type_Traineeprogramm',\n",
       "       'job_type_Berufsausbildung', 'job_type_Praktikum',\n",
       "       'job_type_Werkstudent', 'job_description_anonymized', 'source_id',\n",
       "       'location_clean', 'company_clean_ish', 'company_clean', 'title_clean',\n",
       "       'seniority_level_new', 'seniority_level_5', 'index_pre_agg',\n",
       "       'index_agg_list', 'similarity_results_0_90', 'similarity_results_0_93',\n",
       "       'similarity_results_0_95', 'similarity_results_0_97',\n",
       "       'similarity_results_0_90_mgroup', 'similarity_results_0_93_mgroup',\n",
       "       'similarity_results_0_95_mgroup', 'similarity_results_0_97_mgroup',\n",
       "       'title_short_ChatGPT', 'title_short_ChatGPT2', 'title_short_ChatGPT3',\n",
       "       'days_online_grouped', 'job_description_for_search',\n",
       "       'tech_stack_python', 'tech_stack_julia', 'tech_stack_spss',\n",
       "       'tech_stack_stata', 'tech_stack_javascript', 'tech_stack_sql',\n",
       "       'tech_stack_azure', 'tech_stack_gcp', 'tech_stack_powerbi',\n",
       "       'tech_stack_tableau', 'tech_stack_qlik', 'tech_stack_alteryx',\n",
       "       'tech_stack_docker', 'tech_stack_rust', 'tech_stack_sas',\n",
       "       'tech_stack_excel', 'tech_stack_aws', 'tech_stack_git',\n",
       "       'tech_stack_java', 'tech_stack_r', 'location_lat_long', 'location_lat',\n",
       "       'location_long'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_selected = [\n",
    "    'title', 'title_short_ChatGPT3',\n",
    "    'company', 'company_clean', \n",
    "    'location_clean', 'location_lat', 'location_long',\n",
    "    'salary', 'seniority_level_new', 'seniority_level_5',\n",
    "    'days_online', 'days_online_grouped', 'number_applicants', \n",
    "    'source_id', 'date_posted', 'date_accessed',\n",
    "    \n",
    "    'job_description_anonymized',\n",
    "    \n",
    "    'job_type_Vollzeit', 'job_type_Teilzeit', 'job_type_Festanstellung',\n",
    "    'job_type_BefristeterVertrag', 'job_type_Homeoffice',\n",
    "    'job_type_FreieMitarbeit', 'job_type_Traineeprogramm',\n",
    "    'job_type_Berufsausbildung', 'job_type_Praktikum',\n",
    "    'job_type_Werkstudent',\n",
    "\n",
    "    'tech_stack_python', 'tech_stack_julia',\n",
    "    'tech_stack_spss', 'tech_stack_stata', 'tech_stack_javascript',\n",
    "    'tech_stack_sql', 'tech_stack_azure', 'tech_stack_gcp',\n",
    "    'tech_stack_powerbi', 'tech_stack_tableau', 'tech_stack_qlik',\n",
    "    'tech_stack_alteryx', 'tech_stack_docker', 'tech_stack_rust',\n",
    "    'tech_stack_sas', 'tech_stack_excel', 'tech_stack_aws',\n",
    "    'tech_stack_git', 'tech_stack_java', 'tech_stack_r', \n",
    "\n",
    "    'index_agg_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df.filter(columns_selected).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if all selected columns are present in export df\n",
    "set(columns_selected) - set(df_out.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_out.rename(columns={\"seniority_level_new\": \"seniority_level_8\",\n",
    "                                \"title_short_ChatGPT3\": \"title_cat_ChatGPT\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_cat_ChatGPT</th>\n",
       "      <th>company</th>\n",
       "      <th>company_clean</th>\n",
       "      <th>location_clean</th>\n",
       "      <th>location_lat</th>\n",
       "      <th>location_long</th>\n",
       "      <th>salary</th>\n",
       "      <th>seniority_level_8</th>\n",
       "      <th>seniority_level_5</th>\n",
       "      <th>...</th>\n",
       "      <th>tech_stack_alteryx</th>\n",
       "      <th>tech_stack_docker</th>\n",
       "      <th>tech_stack_rust</th>\n",
       "      <th>tech_stack_sas</th>\n",
       "      <th>tech_stack_excel</th>\n",
       "      <th>tech_stack_aws</th>\n",
       "      <th>tech_stack_git</th>\n",
       "      <th>tech_stack_java</th>\n",
       "      <th>tech_stack_r</th>\n",
       "      <th>index_agg_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Graduate</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>52.510885</td>\n",
       "      <td>13.398937</td>\n",
       "      <td>None</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Xsolla</td>\n",
       "      <td>Xsolla</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>52.510885</td>\n",
       "      <td>13.398937</td>\n",
       "      <td>None</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1183]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Global Market Solutions - Germany</td>\n",
       "      <td>Global Market Solutions - Germany</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>50.110644</td>\n",
       "      <td>8.682092</td>\n",
       "      <td>None</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MeloTech</td>\n",
       "      <td>MeloTech</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>52.510885</td>\n",
       "      <td>13.398937</td>\n",
       "      <td>None</td>\n",
       "      <td>Intern</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, 1105]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist (f/m/d)</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>vent.io</td>\n",
       "      <td>vent.io</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>50.110644</td>\n",
       "      <td>8.682092</td>\n",
       "      <td>None</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title title_cat_ChatGPT   \n",
       "0   Data Science Graduate    Data Scientist  \\\n",
       "1   Junior Data Scientist    Data Scientist   \n",
       "2          Data Scientist    Data Scientist   \n",
       "3   Data Scientist Intern    Data Scientist   \n",
       "4  Data Scientist (f/m/d)    Data Scientist   \n",
       "\n",
       "                             company                      company_clean   \n",
       "0                               Visa                               Visa  \\\n",
       "1                             Xsolla                             Xsolla   \n",
       "2  Global Market Solutions - Germany  Global Market Solutions - Germany   \n",
       "3                           MeloTech                           MeloTech   \n",
       "4                            vent.io                            vent.io   \n",
       "\n",
       "      location_clean  location_lat  location_long salary    seniority_level_8   \n",
       "0             Berlin     52.510885      13.398937   None  Associate/Mid-Level  \\\n",
       "1             Berlin     52.510885      13.398937   None               Junior   \n",
       "2  Frankfurt am Main     50.110644       8.682092   None  Associate/Mid-Level   \n",
       "3             Berlin     52.510885      13.398937   None               Intern   \n",
       "4  Frankfurt am Main     50.110644       8.682092   None  Associate/Mid-Level   \n",
       "\n",
       "     seniority_level_5  ...  tech_stack_alteryx tech_stack_docker   \n",
       "0  Associate/Mid-Level  ...                   0                 0  \\\n",
       "1          Entry level  ...                   0                 0   \n",
       "2  Associate/Mid-Level  ...                   0                 0   \n",
       "3          Entry level  ...                   0                 0   \n",
       "4  Associate/Mid-Level  ...                   0                 0   \n",
       "\n",
       "   tech_stack_rust tech_stack_sas tech_stack_excel tech_stack_aws   \n",
       "0                0              0                0              0  \\\n",
       "1                0              0                0              1   \n",
       "2                0              0                0              0   \n",
       "3                0              0                0              0   \n",
       "4                0              0                0              0   \n",
       "\n",
       "  tech_stack_git  tech_stack_java  tech_stack_r  index_agg_list  \n",
       "0              0                0             0             [0]  \n",
       "1              0                0             1       [1, 1183]  \n",
       "2              0                0             0         [2, 19]  \n",
       "3              0                0             0       [3, 1105]  \n",
       "4              0                0             0             [4]  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                             0\n",
       "title_cat_ChatGPT                 0\n",
       "company                           0\n",
       "company_clean                     0\n",
       "location_clean                    0\n",
       "location_lat                      0\n",
       "location_long                     0\n",
       "salary                         1410\n",
       "seniority_level_8                 0\n",
       "seniority_level_5                 0\n",
       "days_online                     334\n",
       "days_online_grouped               0\n",
       "number_applicants               668\n",
       "source_id                         0\n",
       "date_posted                     334\n",
       "date_accessed                     0\n",
       "job_description_anonymized        0\n",
       "job_type_Vollzeit                 0\n",
       "job_type_Teilzeit                 0\n",
       "job_type_Festanstellung           0\n",
       "job_type_BefristeterVertrag       0\n",
       "job_type_Homeoffice               0\n",
       "job_type_FreieMitarbeit           0\n",
       "job_type_Traineeprogramm          0\n",
       "job_type_Berufsausbildung         0\n",
       "job_type_Praktikum                0\n",
       "job_type_Werkstudent              0\n",
       "tech_stack_python                 0\n",
       "tech_stack_julia                  0\n",
       "tech_stack_spss                   0\n",
       "tech_stack_stata                  0\n",
       "tech_stack_javascript             0\n",
       "tech_stack_sql                    0\n",
       "tech_stack_azure                  0\n",
       "tech_stack_gcp                    0\n",
       "tech_stack_powerbi                0\n",
       "tech_stack_tableau                0\n",
       "tech_stack_qlik                   0\n",
       "tech_stack_alteryx                0\n",
       "tech_stack_docker                 0\n",
       "tech_stack_rust                   0\n",
       "tech_stack_sas                    0\n",
       "tech_stack_excel                  0\n",
       "tech_stack_aws                    0\n",
       "tech_stack_git                    0\n",
       "tech_stack_java                   0\n",
       "tech_stack_r                      0\n",
       "index_agg_list                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store as xlsx and csv\n",
    "df_out.to_csv(\"../job_data.csv\", index=True, header=True)\n",
    "df_out.to_excel(\"job_data.xlsx\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data into Long-Format for Streamlit Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_cat_ChatGPT</th>\n",
       "      <th>company</th>\n",
       "      <th>company_clean</th>\n",
       "      <th>location_clean</th>\n",
       "      <th>location_lat</th>\n",
       "      <th>location_long</th>\n",
       "      <th>salary</th>\n",
       "      <th>seniority_level_8</th>\n",
       "      <th>seniority_level_5</th>\n",
       "      <th>...</th>\n",
       "      <th>tech_stack_alteryx</th>\n",
       "      <th>tech_stack_docker</th>\n",
       "      <th>tech_stack_rust</th>\n",
       "      <th>tech_stack_sas</th>\n",
       "      <th>tech_stack_excel</th>\n",
       "      <th>tech_stack_aws</th>\n",
       "      <th>tech_stack_git</th>\n",
       "      <th>tech_stack_java</th>\n",
       "      <th>tech_stack_r</th>\n",
       "      <th>index_agg_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Graduate</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>52.510885</td>\n",
       "      <td>13.398937</td>\n",
       "      <td>None</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Xsolla</td>\n",
       "      <td>Xsolla</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>52.510885</td>\n",
       "      <td>13.398937</td>\n",
       "      <td>None</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1183]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Global Market Solutions - Germany</td>\n",
       "      <td>Global Market Solutions - Germany</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>50.110644</td>\n",
       "      <td>8.682092</td>\n",
       "      <td>None</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MeloTech</td>\n",
       "      <td>MeloTech</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>52.510885</td>\n",
       "      <td>13.398937</td>\n",
       "      <td>None</td>\n",
       "      <td>Intern</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, 1105]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist (f/m/d)</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>vent.io</td>\n",
       "      <td>vent.io</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>50.110644</td>\n",
       "      <td>8.682092</td>\n",
       "      <td>None</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title title_cat_ChatGPT   \n",
       "0   Data Science Graduate    Data Scientist  \\\n",
       "1   Junior Data Scientist    Data Scientist   \n",
       "2          Data Scientist    Data Scientist   \n",
       "3   Data Scientist Intern    Data Scientist   \n",
       "4  Data Scientist (f/m/d)    Data Scientist   \n",
       "\n",
       "                             company                      company_clean   \n",
       "0                               Visa                               Visa  \\\n",
       "1                             Xsolla                             Xsolla   \n",
       "2  Global Market Solutions - Germany  Global Market Solutions - Germany   \n",
       "3                           MeloTech                           MeloTech   \n",
       "4                            vent.io                            vent.io   \n",
       "\n",
       "      location_clean  location_lat  location_long salary    seniority_level_8   \n",
       "0             Berlin     52.510885      13.398937   None  Associate/Mid-Level  \\\n",
       "1             Berlin     52.510885      13.398937   None               Junior   \n",
       "2  Frankfurt am Main     50.110644       8.682092   None  Associate/Mid-Level   \n",
       "3             Berlin     52.510885      13.398937   None               Intern   \n",
       "4  Frankfurt am Main     50.110644       8.682092   None  Associate/Mid-Level   \n",
       "\n",
       "     seniority_level_5  ...  tech_stack_alteryx tech_stack_docker   \n",
       "0  Associate/Mid-Level  ...                   0                 0  \\\n",
       "1          Entry level  ...                   0                 0   \n",
       "2  Associate/Mid-Level  ...                   0                 0   \n",
       "3          Entry level  ...                   0                 0   \n",
       "4  Associate/Mid-Level  ...                   0                 0   \n",
       "\n",
       "   tech_stack_rust tech_stack_sas tech_stack_excel tech_stack_aws   \n",
       "0                0              0                0              0  \\\n",
       "1                0              0                0              1   \n",
       "2                0              0                0              0   \n",
       "3                0              0                0              0   \n",
       "4                0              0                0              0   \n",
       "\n",
       "  tech_stack_git  tech_stack_java  tech_stack_r  index_agg_list  \n",
       "0              0                0             0             [0]  \n",
       "1              0                0             1       [1, 1183]  \n",
       "2              0                0             0         [2, 19]  \n",
       "3              0                0             0       [3, 1105]  \n",
       "4              0                0             0             [4]  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melt df seperately for job_type and tech_stack, then merge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>location_clean</th>\n",
       "      <th>title_cat_ChatGPT</th>\n",
       "      <th>seniority_level_5</th>\n",
       "      <th>days_online_grouped</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_type_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>15-21</td>\n",
       "      <td>job_type_Vollzeit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11456</th>\n",
       "      <td>0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>15-21</td>\n",
       "      <td>job_type_Praktikum</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>15-21</td>\n",
       "      <td>job_type_Festanstellung</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10024</th>\n",
       "      <td>0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>15-21</td>\n",
       "      <td>job_type_Berufsausbildung</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12888</th>\n",
       "      <td>0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>15-21</td>\n",
       "      <td>job_type_Werkstudent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8558</th>\n",
       "      <td>1624</td>\n",
       "      <td>München</td>\n",
       "      <td>Other</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0-7</td>\n",
       "      <td>job_type_FreieMitarbeit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>1624</td>\n",
       "      <td>München</td>\n",
       "      <td>Other</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0-7</td>\n",
       "      <td>job_type_Traineeprogramm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11422</th>\n",
       "      <td>1624</td>\n",
       "      <td>München</td>\n",
       "      <td>Other</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0-7</td>\n",
       "      <td>job_type_Berufsausbildung</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>1624</td>\n",
       "      <td>München</td>\n",
       "      <td>Other</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0-7</td>\n",
       "      <td>job_type_Vollzeit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5694</th>\n",
       "      <td>1624</td>\n",
       "      <td>München</td>\n",
       "      <td>Other</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0-7</td>\n",
       "      <td>job_type_BefristeterVertrag</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14320 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id location_clean title_cat_ChatGPT    seniority_level_5   \n",
       "0         0         Berlin    Data Scientist  Associate/Mid-Level  \\\n",
       "11456     0         Berlin    Data Scientist  Associate/Mid-Level   \n",
       "2864      0         Berlin    Data Scientist  Associate/Mid-Level   \n",
       "10024     0         Berlin    Data Scientist  Associate/Mid-Level   \n",
       "12888     0         Berlin    Data Scientist  Associate/Mid-Level   \n",
       "...     ...            ...               ...                  ...   \n",
       "8558   1624        München             Other               Senior   \n",
       "9990   1624        München             Other               Senior   \n",
       "11422  1624        München             Other               Senior   \n",
       "1398   1624        München             Other               Senior   \n",
       "5694   1624        München             Other               Senior   \n",
       "\n",
       "      days_online_grouped                     job_type  job_type_value  \n",
       "0                   15-21            job_type_Vollzeit               1  \n",
       "11456               15-21           job_type_Praktikum               0  \n",
       "2864                15-21      job_type_Festanstellung               0  \n",
       "10024               15-21    job_type_Berufsausbildung               0  \n",
       "12888               15-21         job_type_Werkstudent               0  \n",
       "...                   ...                          ...             ...  \n",
       "8558                  0-7      job_type_FreieMitarbeit               0  \n",
       "9990                  0-7     job_type_Traineeprogramm               0  \n",
       "11422                 0-7    job_type_Berufsausbildung               0  \n",
       "1398                  0-7            job_type_Vollzeit               1  \n",
       "5694                  0-7  job_type_BefristeterVertrag               0  \n",
       "\n",
       "[14320 rows x 7 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Job Type\n",
    "cols_for_long_df_job_type = [\"location_clean\", \"title_cat_ChatGPT\", \"seniority_level_5\", \"days_online_grouped\"]\n",
    "cols_for_long_df_job_type.extend(df_out.filter(like=\"job_type_\").columns.to_list())\n",
    "\n",
    "df_for_long_format_job_type = df_out.filter(cols_for_long_df_job_type)\n",
    "df_for_long_format_job_type[\"id\"] = df_for_long_format_job_type.index\n",
    "\n",
    "id_vars = [\"id\", \"location_clean\", \"title_cat_ChatGPT\", \"seniority_level_5\", \"days_online_grouped\"]\n",
    "value_vars = df_out.filter(like=\"job_type_\").columns.to_list()\n",
    "\n",
    "df_for_long_format_job_type = pd.melt(df_for_long_format_job_type, \n",
    "                                      id_vars=id_vars, \n",
    "                                      value_vars=value_vars, \n",
    "                                      var_name=\"job_type\",\n",
    "                                      value_name=\"job_type_value\").sort_values(by=\"id\")\n",
    "df_for_long_format_job_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#rows: 1432 * #vars: 10 should yield: 14320 rows\n",
      "#rows in melted df: 14320\n",
      "sum of all value columns = 2045\n",
      "#rows in df if only 1s are kept = 2045\n"
     ]
    }
   ],
   "source": [
    "print(\"#rows:\", len(df), \"* #vars:\", len(value_vars), \"should yield:\", len(df)*len(value_vars), \"rows\")\n",
    "print(\"#rows in melted df:\", len(df_for_long_format_job_type))\n",
    "\n",
    "print(\"sum of all value columns =\", df.filter(value_vars).sum().sum())\n",
    "print(\"#rows in df if only 1s are kept =\", sum(df_for_long_format_job_type[\"job_type_value\"] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>location_clean</th>\n",
       "      <th>title_cat_ChatGPT</th>\n",
       "      <th>seniority_level_5</th>\n",
       "      <th>days_online_grouped</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_type_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>15-21</td>\n",
       "      <td>job_type_Vollzeit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>8-14</td>\n",
       "      <td>job_type_Vollzeit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>22-28</td>\n",
       "      <td>job_type_Vollzeit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11459</th>\n",
       "      <td>3</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>29+</td>\n",
       "      <td>job_type_Praktikum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>29+</td>\n",
       "      <td>job_type_Vollzeit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4261</th>\n",
       "      <td>1623</td>\n",
       "      <td>München</td>\n",
       "      <td>Other</td>\n",
       "      <td>Senior</td>\n",
       "      <td>8-14</td>\n",
       "      <td>job_type_Festanstellung</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>1623</td>\n",
       "      <td>München</td>\n",
       "      <td>Other</td>\n",
       "      <td>Senior</td>\n",
       "      <td>8-14</td>\n",
       "      <td>job_type_Vollzeit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4262</th>\n",
       "      <td>1624</td>\n",
       "      <td>München</td>\n",
       "      <td>Other</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0-7</td>\n",
       "      <td>job_type_Festanstellung</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7126</th>\n",
       "      <td>1624</td>\n",
       "      <td>München</td>\n",
       "      <td>Other</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0-7</td>\n",
       "      <td>job_type_Homeoffice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>1624</td>\n",
       "      <td>München</td>\n",
       "      <td>Other</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0-7</td>\n",
       "      <td>job_type_Vollzeit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2045 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     location_clean title_cat_ChatGPT    seniority_level_5   \n",
       "0         0             Berlin    Data Scientist  Associate/Mid-Level  \\\n",
       "1         1             Berlin    Data Scientist          Entry level   \n",
       "2         2  Frankfurt am Main    Data Scientist  Associate/Mid-Level   \n",
       "11459     3             Berlin    Data Scientist          Entry level   \n",
       "3         3             Berlin    Data Scientist          Entry level   \n",
       "...     ...                ...               ...                  ...   \n",
       "4261   1623            München             Other               Senior   \n",
       "1397   1623            München             Other               Senior   \n",
       "4262   1624            München             Other               Senior   \n",
       "7126   1624            München             Other               Senior   \n",
       "1398   1624            München             Other               Senior   \n",
       "\n",
       "      days_online_grouped                 job_type  job_type_value  \n",
       "0                   15-21        job_type_Vollzeit               1  \n",
       "1                    8-14        job_type_Vollzeit               1  \n",
       "2                   22-28        job_type_Vollzeit               1  \n",
       "11459                 29+       job_type_Praktikum               1  \n",
       "3                     29+        job_type_Vollzeit               1  \n",
       "...                   ...                      ...             ...  \n",
       "4261                 8-14  job_type_Festanstellung               1  \n",
       "1397                 8-14        job_type_Vollzeit               1  \n",
       "4262                  0-7  job_type_Festanstellung               1  \n",
       "7126                  0-7      job_type_Homeoffice               1  \n",
       "1398                  0-7        job_type_Vollzeit               1  \n",
       "\n",
       "[2045 rows x 7 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_long_format_job_type = df_for_long_format_job_type[df_for_long_format_job_type[\"job_type_value\"] == 1]\n",
    "df_for_long_format_job_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tech Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>location_clean</th>\n",
       "      <th>title_cat_ChatGPT</th>\n",
       "      <th>seniority_level_5</th>\n",
       "      <th>days_online_grouped</th>\n",
       "      <th>tech_stack</th>\n",
       "      <th>tech_stack_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>15-21</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25776</th>\n",
       "      <td>0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>15-21</td>\n",
       "      <td>tech_stack_java</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17184</th>\n",
       "      <td>0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>15-21</td>\n",
       "      <td>tech_stack_docker</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>15-21</td>\n",
       "      <td>tech_stack_spss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8592</th>\n",
       "      <td>0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>15-21</td>\n",
       "      <td>tech_stack_azure</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7126</th>\n",
       "      <td>1624</td>\n",
       "      <td>München</td>\n",
       "      <td>Other</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0-7</td>\n",
       "      <td>tech_stack_javascript</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5694</th>\n",
       "      <td>1624</td>\n",
       "      <td>München</td>\n",
       "      <td>Other</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0-7</td>\n",
       "      <td>tech_stack_stata</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4262</th>\n",
       "      <td>1624</td>\n",
       "      <td>München</td>\n",
       "      <td>Other</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0-7</td>\n",
       "      <td>tech_stack_spss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>1624</td>\n",
       "      <td>München</td>\n",
       "      <td>Other</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0-7</td>\n",
       "      <td>tech_stack_julia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12854</th>\n",
       "      <td>1624</td>\n",
       "      <td>München</td>\n",
       "      <td>Other</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0-7</td>\n",
       "      <td>tech_stack_powerbi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28640 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id location_clean title_cat_ChatGPT    seniority_level_5   \n",
       "0         0         Berlin    Data Scientist  Associate/Mid-Level  \\\n",
       "25776     0         Berlin    Data Scientist  Associate/Mid-Level   \n",
       "17184     0         Berlin    Data Scientist  Associate/Mid-Level   \n",
       "2864      0         Berlin    Data Scientist  Associate/Mid-Level   \n",
       "8592      0         Berlin    Data Scientist  Associate/Mid-Level   \n",
       "...     ...            ...               ...                  ...   \n",
       "7126   1624        München             Other               Senior   \n",
       "5694   1624        München             Other               Senior   \n",
       "4262   1624        München             Other               Senior   \n",
       "2830   1624        München             Other               Senior   \n",
       "12854  1624        München             Other               Senior   \n",
       "\n",
       "      days_online_grouped             tech_stack  tech_stack_value  \n",
       "0                   15-21      tech_stack_python                 1  \n",
       "25776               15-21        tech_stack_java                 0  \n",
       "17184               15-21      tech_stack_docker                 0  \n",
       "2864                15-21        tech_stack_spss                 0  \n",
       "8592                15-21       tech_stack_azure                 0  \n",
       "...                   ...                    ...               ...  \n",
       "7126                  0-7  tech_stack_javascript                 0  \n",
       "5694                  0-7       tech_stack_stata                 0  \n",
       "4262                  0-7        tech_stack_spss                 0  \n",
       "2830                  0-7       tech_stack_julia                 0  \n",
       "12854                 0-7     tech_stack_powerbi                 0  \n",
       "\n",
       "[28640 rows x 7 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tech Stack\n",
    "cols_for_long_df_tech_stack = [\"location_clean\", \"title_cat_ChatGPT\", \"seniority_level_5\", \"days_online_grouped\"]\n",
    "cols_for_long_df_tech_stack.extend(df_out.filter(like=\"tech_stack_\").columns.to_list())\n",
    "\n",
    "df_for_long_format_tech_stack = df_out.filter(cols_for_long_df_tech_stack)\n",
    "df_for_long_format_tech_stack[\"id\"] = df_for_long_format_tech_stack.index\n",
    "\n",
    "id_vars = [\"id\", \"location_clean\", \"title_cat_ChatGPT\", \"seniority_level_5\", \"days_online_grouped\"]\n",
    "value_vars = df_out.filter(like=\"tech_stack_\").columns.to_list()\n",
    "\n",
    "df_for_long_format_tech_stack = pd.melt(df_for_long_format_tech_stack, \n",
    "                                        id_vars=id_vars, \n",
    "                                        value_vars=value_vars, \n",
    "                                        var_name=\"tech_stack\",\n",
    "                                        value_name=\"tech_stack_value\").sort_values(by=\"id\")\n",
    "df_for_long_format_tech_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#rows: 1432 * #vars: 20 should yield: 28640 rows\n",
      "#rows in melted df: 28640\n",
      "sum of all value columns = 3558\n",
      "#rows in df if only 1s are kept = 3558\n"
     ]
    }
   ],
   "source": [
    "print(\"#rows:\", len(df), \"* #vars:\", len(value_vars), \"should yield:\", len(df)*len(value_vars), \"rows\")\n",
    "print(\"#rows in melted df:\", len(df_for_long_format_tech_stack))\n",
    "\n",
    "print(\"sum of all value columns =\", df.filter(value_vars).sum().sum())\n",
    "print(\"#rows in df if only 1s are kept =\", sum(df_for_long_format_tech_stack[\"tech_stack_value\"] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>location_clean</th>\n",
       "      <th>title_cat_ChatGPT</th>\n",
       "      <th>seniority_level_5</th>\n",
       "      <th>days_online_grouped</th>\n",
       "      <th>tech_stack</th>\n",
       "      <th>tech_stack_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>15-21</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>15-21</td>\n",
       "      <td>tech_stack_sql</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8593</th>\n",
       "      <td>1</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>8-14</td>\n",
       "      <td>tech_stack_azure</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22913</th>\n",
       "      <td>1</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>8-14</td>\n",
       "      <td>tech_stack_aws</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>1</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>8-14</td>\n",
       "      <td>tech_stack_sql</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>1618</td>\n",
       "      <td>Großenlüder</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Senior</td>\n",
       "      <td>8-14</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>1618</td>\n",
       "      <td>Großenlüder</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Senior</td>\n",
       "      <td>8-14</td>\n",
       "      <td>tech_stack_azure</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>1619</td>\n",
       "      <td>Münchberg</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Senior</td>\n",
       "      <td>8-14</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22875</th>\n",
       "      <td>1621</td>\n",
       "      <td>München</td>\n",
       "      <td>Other</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>0-7</td>\n",
       "      <td>tech_stack_excel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>1623</td>\n",
       "      <td>München</td>\n",
       "      <td>Other</td>\n",
       "      <td>Senior</td>\n",
       "      <td>8-14</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3558 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id location_clean title_cat_ChatGPT    seniority_level_5   \n",
       "0         0         Berlin    Data Scientist  Associate/Mid-Level  \\\n",
       "7160      0         Berlin    Data Scientist  Associate/Mid-Level   \n",
       "8593      1         Berlin    Data Scientist          Entry level   \n",
       "22913     1         Berlin    Data Scientist          Entry level   \n",
       "7161      1         Berlin    Data Scientist          Entry level   \n",
       "...     ...            ...               ...                  ...   \n",
       "1392   1618    Großenlüder     Data Engineer               Senior   \n",
       "9984   1618    Großenlüder     Data Engineer               Senior   \n",
       "1393   1619      Münchberg     Data Engineer               Senior   \n",
       "22875  1621        München             Other  Associate/Mid-Level   \n",
       "1397   1623        München             Other               Senior   \n",
       "\n",
       "      days_online_grouped         tech_stack  tech_stack_value  \n",
       "0                   15-21  tech_stack_python                 1  \n",
       "7160                15-21     tech_stack_sql                 1  \n",
       "8593                 8-14   tech_stack_azure                 1  \n",
       "22913                8-14     tech_stack_aws                 1  \n",
       "7161                 8-14     tech_stack_sql                 1  \n",
       "...                   ...                ...               ...  \n",
       "1392                 8-14  tech_stack_python                 1  \n",
       "9984                 8-14   tech_stack_azure                 1  \n",
       "1393                 8-14  tech_stack_python                 1  \n",
       "22875                 0-7   tech_stack_excel                 1  \n",
       "1397                 8-14  tech_stack_python                 1  \n",
       "\n",
       "[3558 rows x 7 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_long_format_tech_stack = df_for_long_format_tech_stack[df_for_long_format_tech_stack[\"tech_stack_value\"] == 1]\n",
    "df_for_long_format_tech_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days_online_grouped</th>\n",
       "      <th>id</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_type_value</th>\n",
       "      <th>location_clean</th>\n",
       "      <th>seniority_level_5</th>\n",
       "      <th>tech_stack</th>\n",
       "      <th>tech_stack_value</th>\n",
       "      <th>title_cat_ChatGPT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15-21</td>\n",
       "      <td>0</td>\n",
       "      <td>job_type_Vollzeit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8-14</td>\n",
       "      <td>1</td>\n",
       "      <td>job_type_Vollzeit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22-28</td>\n",
       "      <td>2</td>\n",
       "      <td>job_type_Vollzeit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29+</td>\n",
       "      <td>3</td>\n",
       "      <td>job_type_Vollzeit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-21</td>\n",
       "      <td>4</td>\n",
       "      <td>job_type_Vollzeit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28614</th>\n",
       "      <td>8-14</td>\n",
       "      <td>191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>tech_stack_r</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28617</th>\n",
       "      <td>29+</td>\n",
       "      <td>293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>tech_stack_r</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28629</th>\n",
       "      <td>15-21</td>\n",
       "      <td>549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>Director</td>\n",
       "      <td>tech_stack_r</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28632</th>\n",
       "      <td>29+</td>\n",
       "      <td>638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Darmstadt</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>tech_stack_r</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AI/ML Specialist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28636</th>\n",
       "      <td>0-7</td>\n",
       "      <td>957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bochum</td>\n",
       "      <td>Senior</td>\n",
       "      <td>tech_stack_r</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4835 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      days_online_grouped   id           job_type  job_type_value   \n",
       "0                   15-21    0  job_type_Vollzeit             1.0  \\\n",
       "1                    8-14    1  job_type_Vollzeit             1.0   \n",
       "2                   22-28    2  job_type_Vollzeit             1.0   \n",
       "3                     29+    3  job_type_Vollzeit             1.0   \n",
       "4                   15-21    4  job_type_Vollzeit             1.0   \n",
       "...                   ...  ...                ...             ...   \n",
       "28614                8-14  191                NaN             NaN   \n",
       "28617                 29+  293                NaN             NaN   \n",
       "28629               15-21  549                NaN             NaN   \n",
       "28632                 29+  638                NaN             NaN   \n",
       "28636                 0-7  957                NaN             NaN   \n",
       "\n",
       "          location_clean    seniority_level_5         tech_stack   \n",
       "0                 Berlin  Associate/Mid-Level  tech_stack_python  \\\n",
       "1                 Berlin          Entry level  tech_stack_python   \n",
       "2      Frankfurt am Main  Associate/Mid-Level  tech_stack_python   \n",
       "3                 Berlin          Entry level  tech_stack_python   \n",
       "4      Frankfurt am Main  Associate/Mid-Level  tech_stack_python   \n",
       "...                  ...                  ...                ...   \n",
       "28614             Berlin  Associate/Mid-Level       tech_stack_r   \n",
       "28617            Hamburg          Entry level       tech_stack_r   \n",
       "28629            Hamburg             Director       tech_stack_r   \n",
       "28632          Darmstadt  Associate/Mid-Level       tech_stack_r   \n",
       "28636             Bochum               Senior       tech_stack_r   \n",
       "\n",
       "       tech_stack_value title_cat_ChatGPT  \n",
       "0                   1.0    Data Scientist  \n",
       "1                   1.0    Data Scientist  \n",
       "2                   1.0    Data Scientist  \n",
       "3                   1.0    Data Scientist  \n",
       "4                   1.0    Data Scientist  \n",
       "...                 ...               ...  \n",
       "28614               1.0      Data Analyst  \n",
       "28617               1.0    Data Scientist  \n",
       "28629               1.0    Data Scientist  \n",
       "28632               1.0  AI/ML Specialist  \n",
       "28636               1.0    Data Scientist  \n",
       "\n",
       "[4835 rows x 9 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out_long_merged = df_for_long_format_job_type.combine_first(df_for_long_format_tech_stack)\n",
    "df_out_long_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_type\n",
       "job_type_Vollzeit              1162\n",
       "job_type_Festanstellung         363\n",
       "job_type_Homeoffice             216\n",
       "job_type_Teilzeit               151\n",
       "job_type_Praktikum               75\n",
       "job_type_Werkstudent             33\n",
       "job_type_BefristeterVertrag      20\n",
       "job_type_FreieMitarbeit          19\n",
       "job_type_Traineeprogramm          3\n",
       "job_type_Berufsausbildung         3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out_long_merged[\"job_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_type_Vollzeit              1162\n",
       "job_type_Teilzeit               151\n",
       "job_type_Festanstellung         363\n",
       "job_type_BefristeterVertrag      20\n",
       "job_type_Homeoffice             216\n",
       "job_type_FreieMitarbeit          19\n",
       "job_type_Traineeprogramm          3\n",
       "job_type_Berufsausbildung         3\n",
       "job_type_Praktikum               75\n",
       "job_type_Werkstudent             33\n",
       "dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(like=\"job_type\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tech Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tech_stack\n",
       "tech_stack_python        891\n",
       "tech_stack_sql           548\n",
       "tech_stack_r             309\n",
       "tech_stack_aws           285\n",
       "tech_stack_azure         236\n",
       "tech_stack_powerbi       199\n",
       "tech_stack_tableau       161\n",
       "tech_stack_gcp           160\n",
       "tech_stack_git           157\n",
       "tech_stack_excel         148\n",
       "tech_stack_java          146\n",
       "tech_stack_docker        110\n",
       "tech_stack_qlik           59\n",
       "tech_stack_javascript     52\n",
       "tech_stack_sas            42\n",
       "tech_stack_julia          19\n",
       "tech_stack_alteryx        11\n",
       "tech_stack_rust           11\n",
       "tech_stack_spss            9\n",
       "tech_stack_stata           5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out_long_merged[\"tech_stack\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tech_stack_python        891\n",
       "tech_stack_julia          19\n",
       "tech_stack_spss            9\n",
       "tech_stack_stata           5\n",
       "tech_stack_javascript     52\n",
       "tech_stack_sql           548\n",
       "tech_stack_azure         236\n",
       "tech_stack_gcp           160\n",
       "tech_stack_powerbi       199\n",
       "tech_stack_tableau       161\n",
       "tech_stack_qlik           59\n",
       "tech_stack_alteryx        11\n",
       "tech_stack_docker        110\n",
       "tech_stack_rust           11\n",
       "tech_stack_sas            42\n",
       "tech_stack_excel         148\n",
       "tech_stack_aws           285\n",
       "tech_stack_git           157\n",
       "tech_stack_java          146\n",
       "tech_stack_r             309\n",
       "dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(like=\"tech_stack\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_cat_ChatGPT         \n",
       "Data Scientist                495\n",
       "Other                         412\n",
       "Machine Learning Engineer      91\n",
       "Data Analyst                   87\n",
       "Data Engineer                  76\n",
       "AI/ML Specialist               71\n",
       "Research Scientist             53\n",
       "Business Intelligence (BI)     46\n",
       "Data Consultant                43\n",
       "AI Engineer                    38\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out_long_merged.groupby(\"id\").agg({\"title_cat_ChatGPT\": \"first\"}).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_cat_ChatGPT\n",
       "Data Scientist                500\n",
       "Other                         425\n",
       "Machine Learning Engineer      91\n",
       "Data Analyst                   87\n",
       "Data Engineer                  76\n",
       "AI/ML Specialist               71\n",
       "Research Scientist             55\n",
       "Business Intelligence (BI)     46\n",
       "Data Consultant                43\n",
       "AI Engineer                    38\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out[\"title_cat_ChatGPT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There n=20 ads without any job type or tech stack match..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#ids in long df: 1412\n",
      "#ids in wide df: 1432\n"
     ]
    }
   ],
   "source": [
    "df_out_long_merged_ids = set(df_out_long_merged[\"id\"])\n",
    "df_out_ids = set(df_out.index)\n",
    "\n",
    "print(\"#ids in long df:\", len(df_out_long_merged_ids))\n",
    "print(\"#ids in wide df:\", len(df_out_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[590,\n",
       " 930,\n",
       " 997,\n",
       " 1000,\n",
       " 1004,\n",
       " 1020,\n",
       " 1023,\n",
       " 1044,\n",
       " 1055,\n",
       " 1059,\n",
       " 1100,\n",
       " 1124,\n",
       " 1136,\n",
       " 1169,\n",
       " 1179,\n",
       " 1182,\n",
       " 1204,\n",
       " 1211,\n",
       " 1227,\n",
       " 1272]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_not_in_long = sorted(list(df_out_ids - df_out_long_merged_ids))\n",
    "ids_not_in_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tech_stack_python        0\n",
       "tech_stack_julia         0\n",
       "tech_stack_spss          0\n",
       "tech_stack_stata         0\n",
       "tech_stack_javascript    0\n",
       "tech_stack_sql           0\n",
       "tech_stack_azure         0\n",
       "tech_stack_gcp           0\n",
       "tech_stack_powerbi       0\n",
       "tech_stack_tableau       0\n",
       "tech_stack_qlik          0\n",
       "tech_stack_alteryx       0\n",
       "tech_stack_docker        0\n",
       "tech_stack_rust          0\n",
       "tech_stack_sas           0\n",
       "tech_stack_excel         0\n",
       "tech_stack_aws           0\n",
       "tech_stack_git           0\n",
       "tech_stack_java          0\n",
       "tech_stack_r             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(like=\"tech_stack\").loc[ids_not_in_long].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_type_Vollzeit              0\n",
       "job_type_Teilzeit              0\n",
       "job_type_Festanstellung        0\n",
       "job_type_BefristeterVertrag    0\n",
       "job_type_Homeoffice            0\n",
       "job_type_FreieMitarbeit        0\n",
       "job_type_Traineeprogramm       0\n",
       "job_type_Berufsausbildung      0\n",
       "job_type_Praktikum             0\n",
       "job_type_Werkstudent           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(like=\"job_type\").loc[ids_not_in_long].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, those IDs do not show any positive value in any of these columns and were therefore filtered out.\n",
    "\n",
    "They will be added to the long-format dataframe again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vars = [\"location_clean\", \"title_cat_ChatGPT\", \"seniority_level_5\", \"days_online_grouped\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_clean</th>\n",
       "      <th>title_cat_ChatGPT</th>\n",
       "      <th>seniority_level_5</th>\n",
       "      <th>days_online_grouped</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>Karlsruhe</td>\n",
       "      <td>Other</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>Göttingen</td>\n",
       "      <td>Other</td>\n",
       "      <td>Postdoc</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>Other</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>Other</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>Hamburg</td>\n",
       "      <td>Other</td>\n",
       "      <td>Senior</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     location_clean title_cat_ChatGPT    seniority_level_5   \n",
       "1182      Karlsruhe             Other  Associate/Mid-Level  \\\n",
       "1204      Göttingen             Other              Postdoc   \n",
       "1211         Berlin             Other  Associate/Mid-Level   \n",
       "1227         Berlin             Other  Associate/Mid-Level   \n",
       "1272        Hamburg             Other               Senior   \n",
       "\n",
       "     days_online_grouped    id  \n",
       "1182                 N/A  1182  \n",
       "1204                 N/A  1204  \n",
       "1211                 N/A  1211  \n",
       "1227                 N/A  1227  \n",
       "1272                 N/A  1272  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out_long_merged_add_ids = df_out.loc[ids_not_in_long, id_vars]\n",
    "df_out_long_merged_add_ids[\"id\"] = df_out_long_merged_add_ids.index\n",
    "df_out_long_merged_add_ids.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days_online_grouped</th>\n",
       "      <th>id</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_type_value</th>\n",
       "      <th>location_clean</th>\n",
       "      <th>seniority_level_5</th>\n",
       "      <th>tech_stack</th>\n",
       "      <th>tech_stack_value</th>\n",
       "      <th>title_cat_ChatGPT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>N/A</td>\n",
       "      <td>1182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Karlsruhe</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>N/A</td>\n",
       "      <td>1204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Göttingen</td>\n",
       "      <td>Postdoc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>N/A</td>\n",
       "      <td>1211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>N/A</td>\n",
       "      <td>1227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>N/A</td>\n",
       "      <td>1272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>Senior</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     days_online_grouped    id job_type  job_type_value location_clean   \n",
       "1182                 N/A  1182      NaN             NaN      Karlsruhe  \\\n",
       "1204                 N/A  1204      NaN             NaN      Göttingen   \n",
       "1211                 N/A  1211      NaN             NaN         Berlin   \n",
       "1227                 N/A  1227      NaN             NaN         Berlin   \n",
       "1272                 N/A  1272      NaN             NaN        Hamburg   \n",
       "\n",
       "        seniority_level_5 tech_stack  tech_stack_value title_cat_ChatGPT  \n",
       "1182  Associate/Mid-Level        NaN               NaN             Other  \n",
       "1204              Postdoc        NaN               NaN             Other  \n",
       "1211  Associate/Mid-Level        NaN               NaN             Other  \n",
       "1227  Associate/Mid-Level        NaN               NaN             Other  \n",
       "1272               Senior        NaN               NaN             Other  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out_long_merged_all_ids = pd.concat([df_out_long_merged, df_out_long_merged_add_ids])\n",
    "df_out_long_merged_all_ids.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1432\n"
     ]
    }
   ],
   "source": [
    "print(len(set(df_out_long_merged_all_ids[\"id\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_cat_ChatGPT         \n",
       "Data Scientist                500\n",
       "Other                         425\n",
       "Machine Learning Engineer      91\n",
       "Data Analyst                   87\n",
       "Data Engineer                  76\n",
       "AI/ML Specialist               71\n",
       "Research Scientist             55\n",
       "Business Intelligence (BI)     46\n",
       "Data Consultant                43\n",
       "AI Engineer                    38\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out_long_merged_all_ids.groupby(by=\"id\").agg({\"title_cat_ChatGPT\": \"first\"}).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_cat_ChatGPT\n",
       "Data Scientist                500\n",
       "Other                         425\n",
       "Machine Learning Engineer      91\n",
       "Data Analyst                   87\n",
       "Data Engineer                  76\n",
       "AI/ML Specialist               71\n",
       "Research Scientist             55\n",
       "Business Intelligence (BI)     46\n",
       "Data Consultant                43\n",
       "AI Engineer                    38\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out[\"title_cat_ChatGPT\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...Looks better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean job_type and tech_stack columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days_online_grouped</th>\n",
       "      <th>id</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_type_value</th>\n",
       "      <th>location_clean</th>\n",
       "      <th>seniority_level_5</th>\n",
       "      <th>tech_stack</th>\n",
       "      <th>tech_stack_value</th>\n",
       "      <th>title_cat_ChatGPT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15-21</td>\n",
       "      <td>0</td>\n",
       "      <td>job_type_Vollzeit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8-14</td>\n",
       "      <td>1</td>\n",
       "      <td>job_type_Vollzeit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22-28</td>\n",
       "      <td>2</td>\n",
       "      <td>job_type_Vollzeit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29+</td>\n",
       "      <td>3</td>\n",
       "      <td>job_type_Vollzeit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-21</td>\n",
       "      <td>4</td>\n",
       "      <td>job_type_Vollzeit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  days_online_grouped  id           job_type  job_type_value   \n",
       "0               15-21   0  job_type_Vollzeit             1.0  \\\n",
       "1                8-14   1  job_type_Vollzeit             1.0   \n",
       "2               22-28   2  job_type_Vollzeit             1.0   \n",
       "3                 29+   3  job_type_Vollzeit             1.0   \n",
       "4               15-21   4  job_type_Vollzeit             1.0   \n",
       "\n",
       "      location_clean    seniority_level_5         tech_stack   \n",
       "0             Berlin  Associate/Mid-Level  tech_stack_python  \\\n",
       "1             Berlin          Entry level  tech_stack_python   \n",
       "2  Frankfurt am Main  Associate/Mid-Level  tech_stack_python   \n",
       "3             Berlin          Entry level  tech_stack_python   \n",
       "4  Frankfurt am Main  Associate/Mid-Level  tech_stack_python   \n",
       "\n",
       "   tech_stack_value title_cat_ChatGPT  \n",
       "0               1.0    Data Scientist  \n",
       "1               1.0    Data Scientist  \n",
       "2               1.0    Data Scientist  \n",
       "3               1.0    Data Scientist  \n",
       "4               1.0    Data Scientist  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out_long_merged_all_ids.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out_long_merged_all_ids[\"job_type\"] = df_out_long_merged_all_ids[\"job_type\"].str.replace(\"job_type_\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_type\n",
       "NaN                   2810\n",
       "Vollzeit              1162\n",
       "Festanstellung         363\n",
       "Homeoffice             216\n",
       "Teilzeit               151\n",
       "Praktikum               75\n",
       "Werkstudent             33\n",
       "BefristeterVertrag      20\n",
       "FreieMitarbeit          19\n",
       "Traineeprogramm          3\n",
       "Berufsausbildung         3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out_long_merged_all_ids[\"job_type\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_type_dict = {\n",
    "    \"Vollzeit\"           : \"Full-time\",     \n",
    "    \"Festanstellung\"     : \"Permanent\",    \n",
    "    \"Homeoffice\"         : \"Homeoffice\",        \n",
    "    \"Teilzeit\"           : \"Part-time\",          \n",
    "    \"Praktikum\"          : \"Internship\",         \n",
    "    \"Werkstudent\"        : \"Working student\",       \n",
    "    \"BefristeterVertrag\" : \"Fixed-term\",\n",
    "    \"FreieMitarbeit\"     : \"Freelance\",    \n",
    "    \"Traineeprogramm\"    : \"Traineeprogram\", \n",
    "    \"Berufsausbildung\"   : \"Vocational training\", \n",
    "}\n",
    "\n",
    "df_out_long_merged_all_ids[\"job_type\"] = df_out_long_merged_all_ids[\"job_type\"].map(job_type_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days_online_grouped</th>\n",
       "      <th>id</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_type_value</th>\n",
       "      <th>location_clean</th>\n",
       "      <th>seniority_level_5</th>\n",
       "      <th>tech_stack</th>\n",
       "      <th>tech_stack_value</th>\n",
       "      <th>title_cat_ChatGPT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15-21</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8-14</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22-28</td>\n",
       "      <td>2</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29+</td>\n",
       "      <td>3</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-21</td>\n",
       "      <td>4</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>tech_stack_python</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  days_online_grouped  id   job_type  job_type_value     location_clean   \n",
       "0               15-21   0  Full-time             1.0             Berlin  \\\n",
       "1                8-14   1  Full-time             1.0             Berlin   \n",
       "2               22-28   2  Full-time             1.0  Frankfurt am Main   \n",
       "3                 29+   3  Full-time             1.0             Berlin   \n",
       "4               15-21   4  Full-time             1.0  Frankfurt am Main   \n",
       "\n",
       "     seniority_level_5         tech_stack  tech_stack_value title_cat_ChatGPT  \n",
       "0  Associate/Mid-Level  tech_stack_python               1.0    Data Scientist  \n",
       "1          Entry level  tech_stack_python               1.0    Data Scientist  \n",
       "2  Associate/Mid-Level  tech_stack_python               1.0    Data Scientist  \n",
       "3          Entry level  tech_stack_python               1.0    Data Scientist  \n",
       "4  Associate/Mid-Level  tech_stack_python               1.0    Data Scientist  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out_long_merged_all_ids.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tech Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out_long_merged_all_ids[\"tech_stack\"] = df_out_long_merged_all_ids[\"tech_stack\"].str.replace(\"tech_stack_\", \"\").str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tech_stack\n",
       "Python        891\n",
       "Sql           548\n",
       "R             309\n",
       "Aws           285\n",
       "Azure         236\n",
       "Powerbi       199\n",
       "Tableau       161\n",
       "Gcp           160\n",
       "Git           157\n",
       "Excel         148\n",
       "Java          146\n",
       "Docker        110\n",
       "Qlik           59\n",
       "Javascript     52\n",
       "Sas            42\n",
       "Julia          19\n",
       "Alteryx        11\n",
       "Rust           11\n",
       "Spss            9\n",
       "Stata           5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out_long_merged_all_ids[\"tech_stack\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tech_stack\n",
       "Python        891\n",
       "SQL           548\n",
       "R             309\n",
       "AWS           285\n",
       "Azure         236\n",
       "Power BI      199\n",
       "Tableau       161\n",
       "GCP           160\n",
       "Git           157\n",
       "Excel         148\n",
       "Java          146\n",
       "Docker        110\n",
       "Qlik           59\n",
       "JavaScript     52\n",
       "SAS            42\n",
       "Julia          19\n",
       "Alteryx        11\n",
       "Rust           11\n",
       "SPSS            9\n",
       "Stata           5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_stack_dict = {\n",
    "    \"Sql\"       : \"SQL\",\n",
    "    \"Aws\"       : \"AWS\",\n",
    "    \"Powerbi\"   : \"Power BI\",\n",
    "    \"Gcp\"       : \"GCP\",\n",
    "    \"Javascript\": \"JavaScript\",\n",
    "    \"Sas\"       : \"SAS\",\n",
    "    \"Spss\"      : \"SPSS\",\n",
    "}\n",
    "\n",
    "def clean_tech_stack(x):\n",
    "    if x in tech_stack_dict:\n",
    "        return tech_stack_dict[x]\n",
    "    return x\n",
    "\n",
    "df_out_long_merged_all_ids[\"tech_stack\"] = df_out_long_merged_all_ids[\"tech_stack\"].apply(clean_tech_stack)\n",
    "df_out_long_merged_all_ids[\"tech_stack\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store final long-format dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>location_clean</th>\n",
       "      <th>title_cat_ChatGPT</th>\n",
       "      <th>seniority_level_5</th>\n",
       "      <th>days_online_grouped</th>\n",
       "      <th>job_type</th>\n",
       "      <th>tech_stack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24428</th>\n",
       "      <td>92</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>29+</td>\n",
       "      <td>-</td>\n",
       "      <td>Git</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>1586</td>\n",
       "      <td>Köln</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>0-7</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27245</th>\n",
       "      <td>38</td>\n",
       "      <td>Schwalbach</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>15-21</td>\n",
       "      <td>-</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>1583</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>Other</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>0-7</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>1348</td>\n",
       "      <td>Rosenheim</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>8-14</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24389</th>\n",
       "      <td>46</td>\n",
       "      <td>Hannover</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>0-7</td>\n",
       "      <td>-</td>\n",
       "      <td>Git</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22875</th>\n",
       "      <td>1621</td>\n",
       "      <td>München</td>\n",
       "      <td>Other</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>0-7</td>\n",
       "      <td>-</td>\n",
       "      <td>Excel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>1604</td>\n",
       "      <td>Mannheim</td>\n",
       "      <td>Other</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>8-14</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23005</th>\n",
       "      <td>101</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>Other</td>\n",
       "      <td>Director</td>\n",
       "      <td>0-7</td>\n",
       "      <td>-</td>\n",
       "      <td>AWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>1445</td>\n",
       "      <td>Rosenheim</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Associate/Mid-Level</td>\n",
       "      <td>15-21</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     location_clean          title_cat_ChatGPT   \n",
       "24428    92            Hamburg  Machine Learning Engineer  \\\n",
       "4231   1586               Köln  Machine Learning Engineer   \n",
       "27245    38         Schwalbach             Data Scientist   \n",
       "1364   1583          Stuttgart                      Other   \n",
       "4003   1348          Rosenheim             Data Scientist   \n",
       "24389    46           Hannover             Data Scientist   \n",
       "22875  1621            München                      Other   \n",
       "1381   1604           Mannheim                      Other   \n",
       "23005   101  Frankfurt am Main                      Other   \n",
       "4093   1445          Rosenheim              Data Engineer   \n",
       "\n",
       "         seniority_level_5 days_online_grouped   job_type tech_stack  \n",
       "24428  Associate/Mid-Level                 29+          -        Git  \n",
       "4231   Associate/Mid-Level                 0-7  Permanent          -  \n",
       "27245          Entry level               15-21          -          R  \n",
       "1364   Associate/Mid-Level                 0-7  Full-time          -  \n",
       "4003           Entry level                8-14  Permanent          -  \n",
       "24389  Associate/Mid-Level                 0-7          -        Git  \n",
       "22875  Associate/Mid-Level                 0-7          -      Excel  \n",
       "1381   Associate/Mid-Level                8-14  Full-time          -  \n",
       "23005             Director                 0-7          -        AWS  \n",
       "4093   Associate/Mid-Level               15-21  Permanent          -  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_cols = [\"id\", \"location_clean\", \"title_cat_ChatGPT\", \"seniority_level_5\", \"days_online_grouped\", \"job_type\", \"tech_stack\"]\n",
    "\n",
    "df_out_long_merged_all_ids_out = df_out_long_merged_all_ids.filter(keep_cols)\n",
    "df_out_long_merged_all_ids_out = df_out_long_merged_all_ids_out.fillna(\"-\")\n",
    "df_out_long_merged_all_ids_out.sample(10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4855 entries, 0 to 1272\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   id                   4855 non-null   int64 \n",
      " 1   location_clean       4855 non-null   object\n",
      " 2   title_cat_ChatGPT    4855 non-null   object\n",
      " 3   seniority_level_5    4855 non-null   object\n",
      " 4   days_online_grouped  4855 non-null   object\n",
      " 5   job_type             4855 non-null   object\n",
      " 6   tech_stack           4855 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 303.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_out_long_merged_all_ids_out.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as csv\n",
    "df_out_long_merged_all_ids_out.to_csv(\"../job_data_long.csv\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
